# Repository contents
## .editorconfig
```
root = true

[*]
indent_style = space
indent_size = 4
end_of_line = lf
charset = utf-8
trim_trailing_whitespace = true
insert_final_newline = true
```
## .gdbinit
```
file target/kernel/debug/kernel
set confirm off
set history save on
set print pretty on
set pagination off
set disassemble-next-line auto
set architecture riscv:rv32
set riscv use-compressed-breakpoints yes
target remote 127.0.0.1:7778
```
## .gitignore
```
/target
/build
node_modules
.gdb_history
*.DS_Store
*.img
*.tmp
*.log
*.elf
*.map
*.pcap
*.bin
```
## .rustfmt.toml
```
edition = "2024"

# My personal preferences. Don't even try to convince me ;)
force_multiline_blocks = true
hex_literal_case = "Lower"

# This option causes lengthy import headers but is very useful for mitigating
# merge conflicts.
imports_granularity = "Item"
group_imports = "StdExternalCrate"
```
## .vscode/settings.json
```
{
    "editor.formatOnSave": true,
    "rust-analyzer.cargo.target": "riscv64gc-unknown-none-elf",
    "rust-analyzer.cargo.allTargets": false,
    "rust-analyzer.server.extraEnv": {
        "CARGO_TARGET_DIR": "${workspaceFolder}/build/rust-analyzer"
    },
}
```
## Cargo.lock
```
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 4

[[package]]
name = "allocator-api2"
version = "0.2.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "683d7910e743518b0e34f1186f92494becacb047c7b6bf616c96772180fef923"

[[package]]
name = "arrayvec"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7c02d123df017efcdfbd739ef81735b36c5ba83ec3c59c80a9d7ecc718f92e50"

[[package]]
name = "autocfg"
version = "1.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ace50bade8e6234aa140d9a2f552bbee1db4d353f69b8217bc503490fc1a9f26"

[[package]]
name = "bitflags"
version = "1.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"

[[package]]
name = "byteorder"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fd0f2584146f6f2ef48085050886acf353beff7305ebd1ae69500e27c67f64b"

[[package]]
name = "cfg-if"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"

[[package]]
name = "defmt"
version = "0.3.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f0963443817029b2024136fc4dd07a5107eb8f977eaf18fcd1fdeb11306b64ad"
dependencies = [
 "defmt 1.0.1",
]

[[package]]
name = "defmt"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "548d977b6da32fa1d1fda2876453da1e7df63ad0304c8b3dae4dbe7b96f39b78"
dependencies = [
 "bitflags",
 "defmt-macros",
]

[[package]]
name = "defmt-macros"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3d4fc12a85bcf441cfe44344c4b72d58493178ce635338a3f3b78943aceb258e"
dependencies = [
 "defmt-parser",
 "proc-macro-error2",
 "proc-macro2",
 "quote",
 "syn 2.0.100",
]

[[package]]
name = "defmt-parser"
version = "1.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "10d60334b3b2e7c9d91ef8150abfb6fa4c1c39ebbcf4a81c2e346aad939fee3e"
dependencies = [
 "thiserror",
]

[[package]]
name = "endian-type-rs"
version = "0.1.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6419a5c75e40011b9fe0174db3fe24006ab122fbe1b7e9cc5974b338a755c76"

[[package]]
name = "equivalent"
version = "1.0.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "877a4ace8713b0bcf2a4e7eec82529c029f1d0619886d18145fea96c3ffe5c0f"

[[package]]
name = "fallible-iterator"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4443176a9f2c162692bd3d352d745ef9413eec5782a80d8fd6f8a1ac692a07f7"

[[package]]
name = "fdt-rs"
version = "0.4.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "581d3afdd654deb68c19fcbe4bc411910cc64067d4a13d8637bda7722cb9c2ea"
dependencies = [
 "endian-type-rs",
 "fallible-iterator",
 "memoffset",
 "num-derive",
 "num-traits",
 "rustc_version",
 "static_assertions",
 "unsafe_unwrap",
]

[[package]]
name = "foldhash"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d9c4f5dac5e15c24eb999c26181a6ca40b39fe946cbe4c263c7209467bc83af2"

[[package]]
name = "hash32"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "47d60b12902ba28e2730cd37e95b8c9223af2808df9e902d4df49588d1470606"
dependencies = [
 "byteorder",
]

[[package]]
name = "hashbrown"
version = "0.15.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bf151400ff0baff5465007dd2f3e717f3fe502074ca563069ce3a6629d07b289"
dependencies = [
 "allocator-api2",
 "equivalent",
 "foldhash",
 "serde",
]

[[package]]
name = "heapless"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0bfb9eb618601c89945a70e254898da93b13be0388091d42117462b265bb3fad"
dependencies = [
 "hash32",
 "stable_deref_trait",
]

[[package]]
name = "http_server"
version = "0.0.0"
dependencies = [
 "serde",
 "spin",
 "starina",
]

[[package]]
name = "itoa"
version = "1.0.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4a5f13b858c8d314ee3e8f639011f7ccefe71f97f96e50151fb991f267928e2c"

[[package]]
name = "kernel"
version = "0.0.0"
dependencies = [
 "arrayvec",
 "fdt-rs",
 "hashbrown",
 "http_server",
 "rustc-hash",
 "serde_json",
 "spin",
 "starina",
 "starina_types",
 "starina_utils",
 "tcpip",
 "virtio_net",
]

[[package]]
name = "lock_api"
version = "0.4.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "07af8b9cdd281b7915f413fa73f29ebd5d55d0d3f0155584dade1ff18cea1b17"
dependencies = [
 "autocfg",
 "scopeguard",
]

[[package]]
name = "log"
version = "0.4.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "13dc2df351e3202783a1fe0d44375f7295ffb4049267b0f3018346dc122a1d94"

[[package]]
name = "managed"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0ca88d725a0a943b096803bd34e73a4437208b6077654cc4ecb2947a5f91618d"

[[package]]
name = "memchr"
version = "2.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "78ca9ab1a0babb1e7d5695e3530886289c18cf2f87ec19a575a0abdce112e3a3"

[[package]]
name = "memoffset"
version = "0.5.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "043175f069eda7b85febe4a74abbaeff828d9f8b448515d3151a14a3542811aa"
dependencies = [
 "autocfg",
]

[[package]]
name = "num-derive"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "876a53fff98e03a936a674b29568b0e605f06b29372c2489ff4de23f1949743d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 1.0.109",
]

[[package]]
name = "num-traits"
version = "0.2.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "071dfc062690e90b734c0b2273ce72ad0ffa95f0c74596bc250dcfd960262841"
dependencies = [
 "autocfg",
]

[[package]]
name = "proc-macro-error-attr2"
version = "2.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "96de42df36bb9bba5542fe9f1a054b8cc87e172759a1868aa05c1f3acc89dfc5"
dependencies = [
 "proc-macro2",
 "quote",
]

[[package]]
name = "proc-macro-error2"
version = "2.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "11ec05c52be0a07b08061f7dd003e7d7092e0472bc731b4af7bb1ef876109802"
dependencies = [
 "proc-macro-error-attr2",
 "proc-macro2",
 "quote",
 "syn 2.0.100",
]

[[package]]
name = "proc-macro2"
version = "1.0.94"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a31971752e70b8b2686d7e46ec17fb38dad4051d94024c88df49b667caea9c84"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "quote"
version = "1.0.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1885c039570dc00dcb4ff087a89e185fd56bae234ddc7f056a945bf36467248d"
dependencies = [
 "proc-macro2",
]

[[package]]
name = "rustc-hash"
version = "2.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "357703d41365b4b27c590e3ed91eabb1b663f07c4c084095e60cbed4362dff0d"

[[package]]
name = "rustc_version"
version = "0.2.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "138e3e0acb6c9fb258b19b67cb8abd63c00679d2851805ea151465464fe9030a"
dependencies = [
 "semver",
]

[[package]]
name = "ryu"
version = "1.0.20"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "28d3b2b1366ec20994f1fd18c3c594f05c5dd4bc44d8bb0c1c632c8d6829481f"

[[package]]
name = "scopeguard"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "94143f37725109f92c262ed2cf5e59bce7498c01bcc1502d7b9afe439a4e9f49"

[[package]]
name = "semver"
version = "0.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1d7eb9ef2c18661902cc47e535f9bc51b78acd254da71d375c2f6720d9a40403"
dependencies = [
 "semver-parser",
]

[[package]]
name = "semver-parser"
version = "0.7.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "388a1df253eca08550bef6c72392cfe7c30914bf41df5269b68cbd6ff8f570a3"

[[package]]
name = "serde"
version = "1.0.219"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5f0e2c6ed6606019b4e29e69dbaba95b11854410e5347d525002456dbbb786b6"
dependencies = [
 "serde_derive",
]

[[package]]
name = "serde_bytes"
version = "0.11.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8437fd221bde2d4ca316d61b90e337e9e702b3820b87d63caa9ba6c02bd06d96"
dependencies = [
 "serde",
]

[[package]]
name = "serde_derive"
version = "1.0.219"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b0276cf7f2c73365f7157c8123c21cd9a50fbbd844757af28ca1f5925fc2a00"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.100",
]

[[package]]
name = "serde_json"
version = "1.0.140"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "20068b6e96dc6c9bd23e01df8827e6c7e1f2fddd43c21810382803c136b99373"
dependencies = [
 "itoa",
 "memchr",
 "ryu",
 "serde",
]

[[package]]
name = "smoltcp"
version = "0.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dad095989c1533c1c266d9b1e8d70a1329dd3723c3edac6d03bbd67e7bf6f4bb"
dependencies = [
 "bitflags",
 "byteorder",
 "cfg-if",
 "defmt 0.3.100",
 "heapless",
 "log",
 "managed",
]

[[package]]
name = "spin"
version = "0.9.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6980e8d7511241f8acf4aebddbb1ff938df5eebe98691418c4468d0b72a96a67"
dependencies = [
 "lock_api",
]

[[package]]
name = "stable_deref_trait"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8f112729512f8e442d81f95a8a7ddf2b7c6b8a1a6f509a95864142b30cab2d3"

[[package]]
name = "starina"
version = "0.0.0"
dependencies = [
 "hashbrown",
 "serde",
 "serde_json",
 "spin",
 "starina_types",
 "starina_utils",
]

[[package]]
name = "starina_driver_sdk"
version = "0.0.0"
dependencies = [
 "starina",
 "starina_utils",
]

[[package]]
name = "starina_types"
version = "0.0.0"
dependencies = [
 "hashbrown",
 "serde",
 "serde_bytes",
]

[[package]]
name = "starina_utils"
version = "0.0.0"

[[package]]
name = "static_assertions"
version = "1.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a2eb9349b6444b326872e140eb1cf5e7c522154d69e7a0ffb0fb81c06b37543f"

[[package]]
name = "syn"
version = "1.0.109"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72b64191b275b66ffe2469e8af2c1cfe3bafa67b529ead792a6d0160888b4237"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "syn"
version = "2.0.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b09a44accad81e1ba1cd74a32461ba89dee89095ba17b32f5d03683b1b1fc2a0"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "tcpip"
version = "0.0.0"
dependencies = [
 "log",
 "serde",
 "smoltcp",
 "spin",
 "starina",
]

[[package]]
name = "thiserror"
version = "2.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "567b8a2dae586314f7be2a752ec7474332959c6460e02bde30d702a66d488708"
dependencies = [
 "thiserror-impl",
]

[[package]]
name = "thiserror-impl"
version = "2.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7f7cf42b4507d8ea322120659672cf1b9dbb93f8f2d4ecfd6e51350ff5b17a1d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn 2.0.100",
]

[[package]]
name = "unicode-ident"
version = "1.0.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5a5f39404a5da50712a4c1eecf25e90dd62b613502b7e925fd4e4d19b5c96512"

[[package]]
name = "unsafe_unwrap"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1230ec65f13e0f9b28d789da20d2d419511893ea9dac2c1f4ef67b8b14e5da80"

[[package]]
name = "virtio"
version = "0.0.0"
dependencies = [
 "starina",
 "starina_driver_sdk",
 "starina_utils",
]

[[package]]
name = "virtio_net"
version = "0.0.0"
dependencies = [
 "serde",
 "spin",
 "starina",
 "starina_driver_sdk",
 "virtio",
]
```
## Cargo.toml
```
[workspace]
resolver = "2"
members = [
    "kernel",
    "libs/rust/*",
    "apps/drivers/virtio_net",
    "apps/servers/tcpip",
    "apps/bin/http_server",
]

[workspace.package]
version = "0.0.0"
authors = ["Seiya Nuta <nuta@seiya.me>"]
edition = "2024"

[workspace.dependencies]
arrayvec = { version = "0.7.6", default-features = false }
hashbrown = "0.15.2"
rustc-hash = { version = "2.1.1", default-features = false }
spin = "0.9.8"
serde = { version = "1", default-features = false }
serde_json = { version = "1", default-features = false, features = ["alloc"] }
serde_bytes = { version = "0.11.17", default-features = false }
fdt-rs = { version = "0", default-features = false }

kernel = { path = "kernel" }
starina = { path = "libs/rust/starina" }
starina_types = { path = "libs/rust/starina_types" }
starina_utils = { path = "libs/rust/starina_utils" }
starina_driver_sdk = { path = "libs/rust/driver_sdk" }
virtio = { path = "libs/rust/virtio" }

virtio_net = { path = "apps/drivers/virtio_net" }
tcpip = { path = "apps/servers/tcpip" }
http_server = { path = "apps/bin/http_server" }
```
## README.md
```
# Starina

Starina (named after [stellina](https://en.wiktionary.org/wiki/stellina)), is a general-purpose, microkernel-based, modern operating system designed for developers. It aims to be a production-ready OS, and more importantly, a fun and easy-to-understand OS where you can enjoy the development as if you are writing a Web application.

## Goals

The ultimate goal of this project is to create a production-ready OS to be a good alternative to real-world OSes. To make this happen, Starina values the following principles:

- **Userspace-first approach:** Make OS development approachable and fun for everyone. Prioritize developer experience in the userspace, where the most OS components reside. The microkernel is just a runtime for applications.
- **Simplicity over perfection:** Emphasize a straightforward design which covers the most common use cases. Make it work first. Make it better later.
- **Incrementally adoptable:** Facilitate easy adoption of Starina by providing a seamless integration with existing systems.

## Roadmap for 2025

This year, we focus on cloud computing domain, where Starina will be used as a tiny runtime for Linux containers.

- [x] Prototyping an microkernel-based OS in Rust: [https://starina.dev](https://starina.dev) is served by Starina on Linux/QEMU hypervisor!
- [x] Redesign the OS based on lessons learned
- [x] Rewrite from scratch
- [x] Rust-based almost-zero-cost isolation ([Unikernel](https://en.wikipedia.org/wiki/Unikernel) style)
- [x] TCP/IP server
- [ ] Wrap up APIs **(work in progress)**
- [ ] WSL2-like Linux compatibility layer
- [ ] File system server
- [ ] TypeScript API + language-based isolation (akin to WebAssembly)
- [ ] Usermode isolation (traditional microkernel style)
- [ ] Shell
- [ ] Streamlined observability and debugging experience

## How to run

```bash
# Install dependencies
brew install qemu riscv64-elf-gdb # Ubuntu: apt install qemu gdb-multiarch
rustup override set nightly
rustup target add riscv64gc-unknown-none-elf
rustup component add rust-src llvm-tools

# Build and run (with GDB server enabled)
./run.sh

# Attach GDB to QEMU and start debugging
riscv64-elf-gdb -ex bt
```

## Is it Linux or POSIX compatible?

No. Starina provides completely original APIs and fresh new development experiences. However, to make it easier to adapt to Starina, We plan to implement a [WSL2-like](https://learn.microsoft.com/en-us/windows/wsl/about#what-is-wsl-2) seamless Linux environment based on real Linux microVM + lightweight integration layer (akin to [LWK](https://en.wikipedia.org/wiki/Lightweight_kernel_operating_system) in [supercomputing](https://link.springer.com/book/10.1007/978-981-13-6624-6)).

## Why Rust?

We (and perhaps you too) love to debate the best text editor and programming language, sometimes very seriously and passionately.

Starina is entirely written in Rust because it is *"C++ with seatbelts"*, which is suitable for building a robust yet high-performance OS. Seatbelts are sometimes annoying indeed, but we know it saved us from countless bugs by enforcing good practices. Notably, I don't need address sanitizer when writing Rust. That's a huge factor for me.

That said, it's crystal clear that Rust (or any other language) is not the best language for everything. That's why Starina is designed to be language-agnostic, and I plan to add seamless support for other languages such as TypeScript. What if you can prototype OS components such as device drivers, as if you are writing a Web app? Isn't that cool?
```
## ai/main.ts
```
import { tool, streamText } from 'ai';
import { z } from 'zod';
import { google } from "@ai-sdk/google"
import cp from "node:child_process";
import fs from "node:fs/promises";
import path from "node:path";
import { createWriteStream } from 'node:fs';

const MAX_STEPS_PER_ITERATION = 10;

const SYSTEM_PROMPT = `
You are a super duper intelligent AI programmer who is an expert in Starina OS,
a modern general-purpose microkernel-based operating system.

You will be given an assignment from me, your friendly colleague. You will
understand the requirements, read the codebase, edit the code, try it out using
given tools, fix build errors, run-time errors, and logical errors, and anything
that is not working.  You will keep iterating until the assignment is done.

You don't need to apologize at all for anything. I am not your boss, I am your
long-time colleague who knows you're good at making things work and at joking around.
`.trim();

class PrettyLogger {
    endsWithNewline: boolean | null = null;
    constructor() { }

    chat(chunk: string) {
        process.stdout.write(chunk);
        this.endsWithNewline = chunk.endsWith("\n");
    }

    end() {
        if (this.endsWithNewline === false) {
            process.stdout.write("\n");
        }
    }
}

async function repo2markdown(repoDir: string, destPath: string) {
    const lsFiles = await cp.execSync("git ls-files", { encoding: "utf-8", cwd: repoDir });
    const files = lsFiles.trimEnd().split("\n");

    const stream = createWriteStream(destPath);
    stream.write(`# Repository contents\n`);
    for (const file of files) {
        const filePath = path.join(repoDir, file);
        const fileStat = await fs.stat(filePath);
        if (fileStat.isFile()) {
            const ext = path.extname(file).slice(1);
            stream.write(`## ${file}\n\`\`\`\n`);
            stream.write(await fs.readFile(filePath, "utf-8"));
            stream.write(`\`\`\`\n`);
        } else if (fileStat.isDirectory()) {
            stream.write(`## ${file}/\n`);
        }
    }
    stream.end();
}

async function iterate() {
    console.log(`[AI] thinking ...`);
    const model = google("gemini-1.5-pro-002");
    const logger = new PrettyLogger();
    try {
        const { textStream } = await streamText({
            model,
            system: SYSTEM_PROMPT,
            maxSteps: MAX_STEPS_PER_ITERATION,
            tools: {
                run: tool({
                    description: "Build and start running Starina on QEMU. QEMU will be kept running in the background so that you can attach GDB to it.",
                    parameters: z.object({
                    }),
                    execute: async (input) => {
                    },
                }),
                attachDebugger: tool({
                    description: "Attach GDB to the running QEMU instance. You must run the `run` tool first to start QEMU.",
                    parameters: z.object({
                    }),
                    execute: async (input) => {
                    }
                }),
                textEditor: tool({
                    description: "Read and edit the codebase.",
                    parameters: z.object({
                        filePath: z.string(),
                        content: z.string(),
                    }),
                    execute: async (input) => {

                    },
                }),
            },
        });

        for await (const chunk of textStream) {
            logger.chat(chunk);
        }
    } catch (error) {
        throw error;
    } finally {
        logger.end();
    }
}

async function ensureCleanGitRepo() {
    const { stdout } = cp.spawnSync("git", ["status", "--porcelain"]);
    if (stdout.length > 0) {
        // throw "Git working tree is not clean. Please commit or stash your changes first.";
    }
}

async function main() {
    const repoDir = process.cwd();
    await ensureCleanGitRepo();

    const dumpPath = path.join(repoDir, "LLM.md");
    console.log("Dumping repository contents to", dumpPath);
    await repo2markdown(repoDir, dumpPath);

    await iterate();
    // const { textStream } = await streamText({
}

main().catch((error) => {
    console.error("Error:", error);
    process.exit(1);
});
```
## ai/package.json
```
{
    "private": true,
    "name": "@starina-os/ai",
    "type": "module",
    "scripts": {
        "dev": "tsx main.ts"
    },
    "dependencies": {
        "@ai-sdk/google": "^1.2.10",
        "ai": "^4.3.4",
        "zod": "^3.24.2"
    },
    "devDependencies": {
        "@types/node": "^22.14.0",
        "tsx": "^4.19.3",
        "typescript": "^5.8.3"
    }
}```
## ai/pnpm-lock.yaml
```
lockfileVersion: '9.0'

settings:
  autoInstallPeers: true
  excludeLinksFromLockfile: false

importers:

  .:
    dependencies:
      '@ai-sdk/google':
        specifier: ^1.2.10
        version: 1.2.10(zod@3.24.2)
      ai:
        specifier: ^4.3.4
        version: 4.3.4(react@19.1.0)(zod@3.24.2)
      zod:
        specifier: ^3.24.2
        version: 3.24.2
    devDependencies:
      '@types/node':
        specifier: ^22.14.0
        version: 22.14.0
      tsx:
        specifier: ^4.19.3
        version: 4.19.3
      typescript:
        specifier: ^5.8.3
        version: 5.8.3

packages:

  '@ai-sdk/google@1.2.10':
    resolution: {integrity: sha512-YmZ9DIO6Un0+RU9PtjM9TfoExmUQg2fk8vTlwT+NOaARyhv8eskRCUTne0zf5uUOazPIJuBEv2I6YE9XnS+tUg==}
    engines: {node: '>=18'}
    peerDependencies:
      zod: ^3.0.0

  '@ai-sdk/provider-utils@2.2.6':
    resolution: {integrity: sha512-sUlZ7Gnq84DCGWMQRIK8XVbkzIBnvPR1diV4v6JwPgpn5armnLI/j+rqn62MpLrU5ZCQZlDKl/Lw6ed3ulYqaA==}
    engines: {node: '>=18'}
    peerDependencies:
      zod: ^3.23.8

  '@ai-sdk/provider@1.1.2':
    resolution: {integrity: sha512-ITdgNilJZwLKR7X5TnUr1BsQW6UTX5yFp0h66Nfx8XjBYkWD9W3yugr50GOz3CnE9m/U/Cd5OyEbTMI0rgi6ZQ==}
    engines: {node: '>=18'}

  '@ai-sdk/react@1.2.8':
    resolution: {integrity: sha512-S2FzCSi4uTF0JuSN6zYMXyiAWVAzi/Hho8ISYgHpGZiICYLNCP2si4DuXQOsnWef3IXzQPLVoE11C63lILZIkw==}
    engines: {node: '>=18'}
    peerDependencies:
      react: ^18 || ^19 || ^19.0.0-rc
      zod: ^3.23.8
    peerDependenciesMeta:
      zod:
        optional: true

  '@ai-sdk/ui-utils@1.2.7':
    resolution: {integrity: sha512-OVRxa4SDj0wVsMZ8tGr/whT89oqNtNoXBKmqWC2BRv5ZG6azL2LYZ5ZK35u3lb4l1IE7cWGsLlmq0py0ttsL7A==}
    engines: {node: '>=18'}
    peerDependencies:
      zod: ^3.23.8

  '@esbuild/aix-ppc64@0.25.2':
    resolution: {integrity: sha512-wCIboOL2yXZym2cgm6mlA742s9QeJ8DjGVaL39dLN4rRwrOgOyYSnOaFPhKZGLb2ngj4EyfAFjsNJwPXZvseag==}
    engines: {node: '>=18'}
    cpu: [ppc64]
    os: [aix]

  '@esbuild/android-arm64@0.25.2':
    resolution: {integrity: sha512-5ZAX5xOmTligeBaeNEPnPaeEuah53Id2tX4c2CVP3JaROTH+j4fnfHCkr1PjXMd78hMst+TlkfKcW/DlTq0i4w==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [android]

  '@esbuild/android-arm@0.25.2':
    resolution: {integrity: sha512-NQhH7jFstVY5x8CKbcfa166GoV0EFkaPkCKBQkdPJFvo5u+nGXLEH/ooniLb3QI8Fk58YAx7nsPLozUWfCBOJA==}
    engines: {node: '>=18'}
    cpu: [arm]
    os: [android]

  '@esbuild/android-x64@0.25.2':
    resolution: {integrity: sha512-Ffcx+nnma8Sge4jzddPHCZVRvIfQ0kMsUsCMcJRHkGJ1cDmhe4SsrYIjLUKn1xpHZybmOqCWwB0zQvsjdEHtkg==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [android]

  '@esbuild/darwin-arm64@0.25.2':
    resolution: {integrity: sha512-MpM6LUVTXAzOvN4KbjzU/q5smzryuoNjlriAIx+06RpecwCkL9JpenNzpKd2YMzLJFOdPqBpuub6eVRP5IgiSA==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [darwin]

  '@esbuild/darwin-x64@0.25.2':
    resolution: {integrity: sha512-5eRPrTX7wFyuWe8FqEFPG2cU0+butQQVNcT4sVipqjLYQjjh8a8+vUTfgBKM88ObB85ahsnTwF7PSIt6PG+QkA==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [darwin]

  '@esbuild/freebsd-arm64@0.25.2':
    resolution: {integrity: sha512-mLwm4vXKiQ2UTSX4+ImyiPdiHjiZhIaE9QvC7sw0tZ6HoNMjYAqQpGyui5VRIi5sGd+uWq940gdCbY3VLvsO1w==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [freebsd]

  '@esbuild/freebsd-x64@0.25.2':
    resolution: {integrity: sha512-6qyyn6TjayJSwGpm8J9QYYGQcRgc90nmfdUb0O7pp1s4lTY+9D0H9O02v5JqGApUyiHOtkz6+1hZNvNtEhbwRQ==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [freebsd]

  '@esbuild/linux-arm64@0.25.2':
    resolution: {integrity: sha512-gq/sjLsOyMT19I8obBISvhoYiZIAaGF8JpeXu1u8yPv8BE5HlWYobmlsfijFIZ9hIVGYkbdFhEqC0NvM4kNO0g==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [linux]

  '@esbuild/linux-arm@0.25.2':
    resolution: {integrity: sha512-UHBRgJcmjJv5oeQF8EpTRZs/1knq6loLxTsjc3nxO9eXAPDLcWW55flrMVc97qFPbmZP31ta1AZVUKQzKTzb0g==}
    engines: {node: '>=18'}
    cpu: [arm]
    os: [linux]

  '@esbuild/linux-ia32@0.25.2':
    resolution: {integrity: sha512-bBYCv9obgW2cBP+2ZWfjYTU+f5cxRoGGQ5SeDbYdFCAZpYWrfjjfYwvUpP8MlKbP0nwZ5gyOU/0aUzZ5HWPuvQ==}
    engines: {node: '>=18'}
    cpu: [ia32]
    os: [linux]

  '@esbuild/linux-loong64@0.25.2':
    resolution: {integrity: sha512-SHNGiKtvnU2dBlM5D8CXRFdd+6etgZ9dXfaPCeJtz+37PIUlixvlIhI23L5khKXs3DIzAn9V8v+qb1TRKrgT5w==}
    engines: {node: '>=18'}
    cpu: [loong64]
    os: [linux]

  '@esbuild/linux-mips64el@0.25.2':
    resolution: {integrity: sha512-hDDRlzE6rPeoj+5fsADqdUZl1OzqDYow4TB4Y/3PlKBD0ph1e6uPHzIQcv2Z65u2K0kpeByIyAjCmjn1hJgG0Q==}
    engines: {node: '>=18'}
    cpu: [mips64el]
    os: [linux]

  '@esbuild/linux-ppc64@0.25.2':
    resolution: {integrity: sha512-tsHu2RRSWzipmUi9UBDEzc0nLc4HtpZEI5Ba+Omms5456x5WaNuiG3u7xh5AO6sipnJ9r4cRWQB2tUjPyIkc6g==}
    engines: {node: '>=18'}
    cpu: [ppc64]
    os: [linux]

  '@esbuild/linux-riscv64@0.25.2':
    resolution: {integrity: sha512-k4LtpgV7NJQOml/10uPU0s4SAXGnowi5qBSjaLWMojNCUICNu7TshqHLAEbkBdAszL5TabfvQ48kK84hyFzjnw==}
    engines: {node: '>=18'}
    cpu: [riscv64]
    os: [linux]

  '@esbuild/linux-s390x@0.25.2':
    resolution: {integrity: sha512-GRa4IshOdvKY7M/rDpRR3gkiTNp34M0eLTaC1a08gNrh4u488aPhuZOCpkF6+2wl3zAN7L7XIpOFBhnaE3/Q8Q==}
    engines: {node: '>=18'}
    cpu: [s390x]
    os: [linux]

  '@esbuild/linux-x64@0.25.2':
    resolution: {integrity: sha512-QInHERlqpTTZ4FRB0fROQWXcYRD64lAoiegezDunLpalZMjcUcld3YzZmVJ2H/Cp0wJRZ8Xtjtj0cEHhYc/uUg==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [linux]

  '@esbuild/netbsd-arm64@0.25.2':
    resolution: {integrity: sha512-talAIBoY5M8vHc6EeI2WW9d/CkiO9MQJ0IOWX8hrLhxGbro/vBXJvaQXefW2cP0z0nQVTdQ/eNyGFV1GSKrxfw==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [netbsd]

  '@esbuild/netbsd-x64@0.25.2':
    resolution: {integrity: sha512-voZT9Z+tpOxrvfKFyfDYPc4DO4rk06qamv1a/fkuzHpiVBMOhpjK+vBmWM8J1eiB3OLSMFYNaOaBNLXGChf5tg==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [netbsd]

  '@esbuild/openbsd-arm64@0.25.2':
    resolution: {integrity: sha512-dcXYOC6NXOqcykeDlwId9kB6OkPUxOEqU+rkrYVqJbK2hagWOMrsTGsMr8+rW02M+d5Op5NNlgMmjzecaRf7Tg==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [openbsd]

  '@esbuild/openbsd-x64@0.25.2':
    resolution: {integrity: sha512-t/TkWwahkH0Tsgoq1Ju7QfgGhArkGLkF1uYz8nQS/PPFlXbP5YgRpqQR3ARRiC2iXoLTWFxc6DJMSK10dVXluw==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [openbsd]

  '@esbuild/sunos-x64@0.25.2':
    resolution: {integrity: sha512-cfZH1co2+imVdWCjd+D1gf9NjkchVhhdpgb1q5y6Hcv9TP6Zi9ZG/beI3ig8TvwT9lH9dlxLq5MQBBgwuj4xvA==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [sunos]

  '@esbuild/win32-arm64@0.25.2':
    resolution: {integrity: sha512-7Loyjh+D/Nx/sOTzV8vfbB3GJuHdOQyrOryFdZvPHLf42Tk9ivBU5Aedi7iyX+x6rbn2Mh68T4qq1SDqJBQO5Q==}
    engines: {node: '>=18'}
    cpu: [arm64]
    os: [win32]

  '@esbuild/win32-ia32@0.25.2':
    resolution: {integrity: sha512-WRJgsz9un0nqZJ4MfhabxaD9Ft8KioqU3JMinOTvobbX6MOSUigSBlogP8QB3uxpJDsFS6yN+3FDBdqE5lg9kg==}
    engines: {node: '>=18'}
    cpu: [ia32]
    os: [win32]

  '@esbuild/win32-x64@0.25.2':
    resolution: {integrity: sha512-kM3HKb16VIXZyIeVrM1ygYmZBKybX8N4p754bw390wGO3Tf2j4L2/WYL+4suWujpgf6GBYs3jv7TyUivdd05JA==}
    engines: {node: '>=18'}
    cpu: [x64]
    os: [win32]

  '@opentelemetry/api@1.9.0':
    resolution: {integrity: sha512-3giAOQvZiH5F9bMlMiv8+GSPMeqg0dbaeo58/0SlA9sxSqZhnUtxzX9/2FzyhS9sWQf5S0GJE0AKBrFqjpeYcg==}
    engines: {node: '>=8.0.0'}

  '@types/diff-match-patch@1.0.36':
    resolution: {integrity: sha512-xFdR6tkm0MWvBfO8xXCSsinYxHcqkQUlcHeSpMC2ukzOb6lwQAfDmW+Qt0AvlGd8HpsS28qKsB+oPeJn9I39jg==}

  '@types/node@22.14.0':
    resolution: {integrity: sha512-Kmpl+z84ILoG+3T/zQFyAJsU6EPTmOCj8/2+83fSN6djd6I4o7uOuGIH6vq3PrjY5BGitSbFuMN18j3iknubbA==}

  ai@4.3.4:
    resolution: {integrity: sha512-uMjzrowIqfU8CCCxhx8QGl7ETydHBROeNL0VoEwetkmDCY6Q8ZTacj6jNNqGJOiCk595aUrGR9VHPY9Ylvy1fg==}
    engines: {node: '>=18'}
    peerDependencies:
      react: ^18 || ^19 || ^19.0.0-rc
      zod: ^3.23.8
    peerDependenciesMeta:
      react:
        optional: true

  chalk@5.4.1:
    resolution: {integrity: sha512-zgVZuo2WcZgfUEmsn6eO3kINexW8RAE4maiQ8QNs8CtpPCSyMiYsULR3HQYkm3w8FIA3SberyMJMSldGsW+U3w==}
    engines: {node: ^12.17.0 || ^14.13 || >=16.0.0}

  dequal@2.0.3:
    resolution: {integrity: sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==}
    engines: {node: '>=6'}

  diff-match-patch@1.0.5:
    resolution: {integrity: sha512-IayShXAgj/QMXgB0IWmKx+rOPuGMhqm5w6jvFxmVenXKIzRqTAAsbBPT3kWQeGANj3jGgvcvv4yK6SxqYmikgw==}

  esbuild@0.25.2:
    resolution: {integrity: sha512-16854zccKPnC+toMywC+uKNeYSv+/eXkevRAfwRD/G9Cleq66m8XFIrigkbvauLLlCfDL45Q2cWegSg53gGBnQ==}
    engines: {node: '>=18'}
    hasBin: true

  fsevents@2.3.3:
    resolution: {integrity: sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==}
    engines: {node: ^8.16.0 || ^10.6.0 || >=11.0.0}
    os: [darwin]

  get-tsconfig@4.10.0:
    resolution: {integrity: sha512-kGzZ3LWWQcGIAmg6iWvXn0ei6WDtV26wzHRMwDSzmAbcXrTEXxHy6IehI6/4eT6VRKyMP1eF1VqwrVUmE/LR7A==}

  json-schema@0.4.0:
    resolution: {integrity: sha512-es94M3nTIfsEPisRafak+HDLfHXnKBhV3vU5eqPcS3flIWqcxJWgXHXiey3YrpaNsanY5ei1VoYEbOzijuq9BA==}

  jsondiffpatch@0.6.0:
    resolution: {integrity: sha512-3QItJOXp2AP1uv7waBkao5nCvhEv+QmJAd38Ybq7wNI74Q+BBmnLn4EDKz6yI9xGAIQoUF87qHt+kc1IVxB4zQ==}
    engines: {node: ^18.0.0 || >=20.0.0}
    hasBin: true

  nanoid@3.3.11:
    resolution: {integrity: sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==}
    engines: {node: ^10 || ^12 || ^13.7 || ^14 || >=15.0.1}
    hasBin: true

  react@19.1.0:
    resolution: {integrity: sha512-FS+XFBNvn3GTAWq26joslQgWNoFu08F4kl0J4CgdNKADkdSGXQyTCnKteIAJy96Br6YbpEU1LSzV5dYtjMkMDg==}
    engines: {node: '>=0.10.0'}

  resolve-pkg-maps@1.0.0:
    resolution: {integrity: sha512-seS2Tj26TBVOC2NIc2rOe2y2ZO7efxITtLZcGSOnHHNOQ7CkiUBfw0Iw2ck6xkIhPwLhKNLS8BO+hEpngQlqzw==}

  secure-json-parse@2.7.0:
    resolution: {integrity: sha512-6aU+Rwsezw7VR8/nyvKTx8QpWH9FrcYiXXlqC4z5d5XQBDRqtbfsRjnwGyqbi3gddNtWHuEk9OANUotL26qKUw==}

  swr@2.3.3:
    resolution: {integrity: sha512-dshNvs3ExOqtZ6kJBaAsabhPdHyeY4P2cKwRCniDVifBMoG/SVI7tfLWqPXriVspf2Rg4tPzXJTnwaihIeFw2A==}
    peerDependencies:
      react: ^16.11.0 || ^17.0.0 || ^18.0.0 || ^19.0.0

  throttleit@2.1.0:
    resolution: {integrity: sha512-nt6AMGKW1p/70DF/hGBdJB57B8Tspmbp5gfJ8ilhLnt7kkr2ye7hzD6NVG8GGErk2HWF34igrL2CXmNIkzKqKw==}
    engines: {node: '>=18'}

  tsx@4.19.3:
    resolution: {integrity: sha512-4H8vUNGNjQ4V2EOoGw005+c+dGuPSnhpPBPHBtsZdGZBk/iJb4kguGlPWaZTZ3q5nMtFOEsY0nRDlh9PJyd6SQ==}
    engines: {node: '>=18.0.0'}
    hasBin: true

  typescript@5.8.3:
    resolution: {integrity: sha512-p1diW6TqL9L07nNxvRMM7hMMw4c5XOo/1ibL4aAIGmSAt9slTE1Xgw5KWuof2uTOvCg9BY7ZRi+GaF+7sfgPeQ==}
    engines: {node: '>=14.17'}
    hasBin: true

  undici-types@6.21.0:
    resolution: {integrity: sha512-iwDZqg0QAGrg9Rav5H4n0M64c3mkR59cJ6wQp+7C4nI0gsmExaedaYLNO44eT4AtBBwjbTiGPMlt2Md0T9H9JQ==}

  use-sync-external-store@1.5.0:
    resolution: {integrity: sha512-Rb46I4cGGVBmjamjphe8L/UnvJD+uPPtTkNvX5mZgqdbavhI4EbgIWJiIHXJ8bc/i9EQGPRh4DwEURJ552Do0A==}
    peerDependencies:
      react: ^16.8.0 || ^17.0.0 || ^18.0.0 || ^19.0.0

  zod-to-json-schema@3.24.5:
    resolution: {integrity: sha512-/AuWwMP+YqiPbsJx5D6TfgRTc4kTLjsh5SOcd4bLsfUg2RcEXrFMJl1DGgdHy2aCfsIA/cr/1JM0xcB2GZji8g==}
    peerDependencies:
      zod: ^3.24.1

  zod@3.24.2:
    resolution: {integrity: sha512-lY7CDW43ECgW9u1TcT3IoXHflywfVqDYze4waEz812jR/bZ8FHDsl7pFQoSZTz5N+2NqRXs8GBwnAwo3ZNxqhQ==}

snapshots:

  '@ai-sdk/google@1.2.10(zod@3.24.2)':
    dependencies:
      '@ai-sdk/provider': 1.1.2
      '@ai-sdk/provider-utils': 2.2.6(zod@3.24.2)
      zod: 3.24.2

  '@ai-sdk/provider-utils@2.2.6(zod@3.24.2)':
    dependencies:
      '@ai-sdk/provider': 1.1.2
      nanoid: 3.3.11
      secure-json-parse: 2.7.0
      zod: 3.24.2

  '@ai-sdk/provider@1.1.2':
    dependencies:
      json-schema: 0.4.0

  '@ai-sdk/react@1.2.8(react@19.1.0)(zod@3.24.2)':
    dependencies:
      '@ai-sdk/provider-utils': 2.2.6(zod@3.24.2)
      '@ai-sdk/ui-utils': 1.2.7(zod@3.24.2)
      react: 19.1.0
      swr: 2.3.3(react@19.1.0)
      throttleit: 2.1.0
    optionalDependencies:
      zod: 3.24.2

  '@ai-sdk/ui-utils@1.2.7(zod@3.24.2)':
    dependencies:
      '@ai-sdk/provider': 1.1.2
      '@ai-sdk/provider-utils': 2.2.6(zod@3.24.2)
      zod: 3.24.2
      zod-to-json-schema: 3.24.5(zod@3.24.2)

  '@esbuild/aix-ppc64@0.25.2':
    optional: true

  '@esbuild/android-arm64@0.25.2':
    optional: true

  '@esbuild/android-arm@0.25.2':
    optional: true

  '@esbuild/android-x64@0.25.2':
    optional: true

  '@esbuild/darwin-arm64@0.25.2':
    optional: true

  '@esbuild/darwin-x64@0.25.2':
    optional: true

  '@esbuild/freebsd-arm64@0.25.2':
    optional: true

  '@esbuild/freebsd-x64@0.25.2':
    optional: true

  '@esbuild/linux-arm64@0.25.2':
    optional: true

  '@esbuild/linux-arm@0.25.2':
    optional: true

  '@esbuild/linux-ia32@0.25.2':
    optional: true

  '@esbuild/linux-loong64@0.25.2':
    optional: true

  '@esbuild/linux-mips64el@0.25.2':
    optional: true

  '@esbuild/linux-ppc64@0.25.2':
    optional: true

  '@esbuild/linux-riscv64@0.25.2':
    optional: true

  '@esbuild/linux-s390x@0.25.2':
    optional: true

  '@esbuild/linux-x64@0.25.2':
    optional: true

  '@esbuild/netbsd-arm64@0.25.2':
    optional: true

  '@esbuild/netbsd-x64@0.25.2':
    optional: true

  '@esbuild/openbsd-arm64@0.25.2':
    optional: true

  '@esbuild/openbsd-x64@0.25.2':
    optional: true

  '@esbuild/sunos-x64@0.25.2':
    optional: true

  '@esbuild/win32-arm64@0.25.2':
    optional: true

  '@esbuild/win32-ia32@0.25.2':
    optional: true

  '@esbuild/win32-x64@0.25.2':
    optional: true

  '@opentelemetry/api@1.9.0': {}

  '@types/diff-match-patch@1.0.36': {}

  '@types/node@22.14.0':
    dependencies:
      undici-types: 6.21.0

  ai@4.3.4(react@19.1.0)(zod@3.24.2):
    dependencies:
      '@ai-sdk/provider': 1.1.2
      '@ai-sdk/provider-utils': 2.2.6(zod@3.24.2)
      '@ai-sdk/react': 1.2.8(react@19.1.0)(zod@3.24.2)
      '@ai-sdk/ui-utils': 1.2.7(zod@3.24.2)
      '@opentelemetry/api': 1.9.0
      jsondiffpatch: 0.6.0
      zod: 3.24.2
    optionalDependencies:
      react: 19.1.0

  chalk@5.4.1: {}

  dequal@2.0.3: {}

  diff-match-patch@1.0.5: {}

  esbuild@0.25.2:
    optionalDependencies:
      '@esbuild/aix-ppc64': 0.25.2
      '@esbuild/android-arm': 0.25.2
      '@esbuild/android-arm64': 0.25.2
      '@esbuild/android-x64': 0.25.2
      '@esbuild/darwin-arm64': 0.25.2
      '@esbuild/darwin-x64': 0.25.2
      '@esbuild/freebsd-arm64': 0.25.2
      '@esbuild/freebsd-x64': 0.25.2
      '@esbuild/linux-arm': 0.25.2
      '@esbuild/linux-arm64': 0.25.2
      '@esbuild/linux-ia32': 0.25.2
      '@esbuild/linux-loong64': 0.25.2
      '@esbuild/linux-mips64el': 0.25.2
      '@esbuild/linux-ppc64': 0.25.2
      '@esbuild/linux-riscv64': 0.25.2
      '@esbuild/linux-s390x': 0.25.2
      '@esbuild/linux-x64': 0.25.2
      '@esbuild/netbsd-arm64': 0.25.2
      '@esbuild/netbsd-x64': 0.25.2
      '@esbuild/openbsd-arm64': 0.25.2
      '@esbuild/openbsd-x64': 0.25.2
      '@esbuild/sunos-x64': 0.25.2
      '@esbuild/win32-arm64': 0.25.2
      '@esbuild/win32-ia32': 0.25.2
      '@esbuild/win32-x64': 0.25.2

  fsevents@2.3.3:
    optional: true

  get-tsconfig@4.10.0:
    dependencies:
      resolve-pkg-maps: 1.0.0

  json-schema@0.4.0: {}

  jsondiffpatch@0.6.0:
    dependencies:
      '@types/diff-match-patch': 1.0.36
      chalk: 5.4.1
      diff-match-patch: 1.0.5

  nanoid@3.3.11: {}

  react@19.1.0: {}

  resolve-pkg-maps@1.0.0: {}

  secure-json-parse@2.7.0: {}

  swr@2.3.3(react@19.1.0):
    dependencies:
      dequal: 2.0.3
      react: 19.1.0
      use-sync-external-store: 1.5.0(react@19.1.0)

  throttleit@2.1.0: {}

  tsx@4.19.3:
    dependencies:
      esbuild: 0.25.2
      get-tsconfig: 4.10.0
    optionalDependencies:
      fsevents: 2.3.3

  typescript@5.8.3: {}

  undici-types@6.21.0: {}

  use-sync-external-store@1.5.0(react@19.1.0):
    dependencies:
      react: 19.1.0

  zod-to-json-schema@3.24.5(zod@3.24.2):
    dependencies:
      zod: 3.24.2

  zod@3.24.2: {}
```
## ai/tsconfig.json
```
{
    "compilerOptions": {
        "target": "ESNext",
        "module": "NodeNext",
        "esModuleInterop": true,
        "forceConsistentCasingInFileNames": true,
        "strict": true,
        "skipLibCheck": true,
        "allowImportingTsExtensions": true,
        "erasableSyntaxOnly": true,
        "noEmit": true
    }
}```
## apps/bin/http_server/Cargo.toml
```
[package]
name = "http_server"
publish = false
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
starina = { workspace = true }
serde = { workspace = true, features = ["derive"] }

# FIXME:
spin = { workspace = true }
```
## apps/bin/http_server/autogen.rs
```
use starina::channel::Channel;
use starina::collections::HashMap;
// TODO: auto geenrate this file from app.toml
use starina::device_tree::DeviceTree;
use starina::iobus::IoBus;
use starina::prelude::*;
use starina::spec::AppSpec;
use starina::spec::EnvItem;
use starina::spec::EnvType;
use starina::syscall::VsyscallPage;

use crate::App;

#[derive(serde::Deserialize)]
pub struct Env {
    pub tcpip: Channel,
    // pub listen_host: String,
    // pub listen_port: u16,
}

pub const APP_SPEC: AppSpec = AppSpec {
    env: &[EnvItem {
        name: "tcpip",
        ty: EnvType::Service { name: "tcpip" },
    }],
    exports: &[],
};

pub fn app_main(vsyscall: *const VsyscallPage) {
    starina::eventloop::app_loop::<Env, App>("http_server", vsyscall);
}
```
## apps/bin/http_server/connection.rs
```
use starina::channel::ChannelSender;
use starina::error::ErrorCode;
use starina::message::StreamDataMsg;
use starina::prelude::*;

use crate::http::request_parser::HttpRequestParser;
use crate::http::request_parser::Part;
use crate::http::response_writer::HttpResponseWriter;
use crate::http::response_writer::Writer;

pub struct ChannelWriter(ChannelSender);

impl ChannelWriter {
    pub fn new(tcpip_sender: ChannelSender) -> Self {
        Self(tcpip_sender)
    }
}

impl Writer for ChannelWriter {
    type Error = ErrorCode;

    fn write(&mut self, buf: &[u8]) -> Result<(), Self::Error> {
        self.0.send(StreamDataMsg { data: buf })
    }
}

pub struct Conn<W: Writer> {
    response_writer: Option<HttpResponseWriter<W>>,
    request_parser: HttpRequestParser,
}

impl<W: Writer> Conn<W> {
    pub fn new(writer: W) -> Self {
        Self {
            response_writer: Some(HttpResponseWriter::new(writer)),
            request_parser: HttpRequestParser::new(),
        }
    }

    pub fn on_tcp_data(&mut self, chunk: &[u8]) {
        match self.request_parser.parse_chunk(chunk) {
            Ok(Some(part)) => {
                warn!("{:?}", part);
                match part {
                    Part::Request {
                        method,
                        path,
                        headers,
                        first_body,
                    } => {
                        // TODO: backpressure
                        let mut response_writer = self.response_writer.take().unwrap();
                        response_writer.set_header("server", "Starina").unwrap();
                        response_writer.set_header("connection", "close").unwrap();
                        response_writer.write_status(200).unwrap();
                        response_writer
                            .write_body(format!("You sent: {} {}", method, path).as_bytes())
                            .unwrap();
                        drop(response_writer);
                    }
                    Part::Body { chunk } => {
                        // Do something.
                    }
                }
            }
            Ok(None) => {
                // Needs more data.
            }
            Err(err) => {
                warn!("HTTP parse error: {:?}", err);
                // TODO: close the connection
                return;
            }
        }
    }
}
```
## apps/bin/http_server/http/mod.rs
```
pub mod request_parser;
pub mod response_writer;
```
## apps/bin/http_server/http/request_parser.rs
```
use core::mem;

use starina::collections::HashMap;
use starina::prelude::*;

/// Per-connection state machine.
#[derive(Debug, Clone, PartialEq, Eq)]
enum State {
    ReadingStartLine,
    ReadingHeaders {
        method: String,
        path: String,
        headers: HashMap<String, Vec<String>>,
    },
    ReadingBody,
    Errored,
}

#[derive(Debug)]
pub enum Part<'a> {
    Request {
        method: String,
        path: String,
        headers: HashMap<String, Vec<String>>,
        first_body: &'a [u8],
    },
    Body {
        chunk: &'a [u8],
    },
}

#[derive(Debug)]
pub enum Error {
    Errored,
    TooLongRequest,
    NonUtf8Requst,
    InvalidStartLine,
    UnsupportedHttpVersion,
    UnsupportedMethod,
    InvalidHeader,
    EmptyHeaderKey,
}

pub struct HttpRequestParser {
    headers_buf: String,
    remaining_headers_size: usize,
    state: State,
}

impl HttpRequestParser {
    pub fn new() -> Self {
        Self {
            state: State::ReadingStartLine,
            headers_buf: String::with_capacity(128),
            remaining_headers_size: 16 * 1024,
        }
    }

    pub fn parse_chunk<'a>(&mut self, chunk: &'a [u8]) -> Result<Option<Part<'a>>, Error> {
        let result = self.do_parse_chunk(chunk);
        if result.is_err() {
            self.state = State::Errored;
        }

        result
    }

    fn do_parse_chunk<'a>(&mut self, chunk: &'a [u8]) -> Result<Option<Part<'a>>, Error> {
        match self.state {
            State::ReadingBody => {
                return Ok(Some(Part::Body { chunk }));
            }
            State::Errored => {
                // Do nothing. Ignore the data.
                return Err(Error::Errored);
            }
            _ => {
                // Keep processing the data below.
            }
        }

        if self
            .remaining_headers_size
            .checked_sub(chunk.len())
            .is_none()
        {
            return Err(Error::TooLongRequest);
        }

        let Ok(chunk_str) = str::from_utf8(chunk) else {
            return Err(Error::NonUtf8Requst);
        };

        self.headers_buf.push_str(chunk_str);
        let headers_buf = core::mem::take(&mut self.headers_buf);

        let mut consumed_len = 0;
        for line in headers_buf.split_inclusive("\r\n") {
            if !line.ends_with("\r\n") {
                // The line is still not terminated.
                break;
            }

            consumed_len += line.len();

            match &mut self.state {
                State::ReadingStartLine => {
                    let mut parts = line.trim_ascii_end().splitn(3, ' ');
                    let (Some(method), Some(path), Some(version)) =
                        (parts.next(), parts.next(), parts.next())
                    else {
                        return Err(Error::InvalidStartLine);
                    };

                    if version != "HTTP/1.1" && version != "HTTP/1.0" {
                        return Err(Error::UnsupportedHttpVersion);
                    }

                    let method_upper = method.to_uppercase();
                    match method_upper.as_str() {
                        "GET" | "POST" | "PUT" | "DELETE" | "PATCH" | "HEAD" | "OPTIONS" => {}
                        _ => {
                            return Err(Error::UnsupportedMethod);
                        }
                    }

                    self.state = State::ReadingHeaders {
                        method: method_upper,
                        path: path.to_string(),
                        headers: HashMap::new(),
                    };
                }
                State::ReadingHeaders { .. } if line == "\r\n" => {
                    // End of headers.
                    self.headers_buf = String::new();
                    let State::ReadingHeaders {
                        method,
                        path,
                        headers,
                        ..
                    } = mem::replace(&mut self.state, State::ReadingBody)
                    else {
                        unreachable!();
                    };

                    let part = Part::Request {
                        method,
                        path,
                        headers,
                        first_body: &chunk[consumed_len..],
                    };

                    return Ok(Some(part));
                }
                State::ReadingHeaders { headers, .. } => {
                    let mut parts = line.trim_ascii_end().splitn(2, ':');
                    let (Some(key), Some(value)) = (parts.next(), parts.next()) else {
                        return Err(Error::InvalidHeader);
                    };

                    let key = key.trim().to_ascii_lowercase();
                    let value = value.trim().to_string();
                    if key.is_empty() {
                        return Err(Error::EmptyHeaderKey);
                    }

                    headers.entry(key).or_insert_with(Vec::new).push(value);
                }
                _ => unreachable!(),
            }
        }

        self.headers_buf = headers_buf[consumed_len..].to_owned();
        Ok(None)
    }
}

#[cfg(test)]
mod tests {
    use starina::error::ErrorCode;

    use super::*;

    #[test]
    fn parse_simple_http_request() {
        let mut parser = HttpRequestParser::new();
        let Ok(Some(Part::Request {
            method,
            path,
            headers,
            first_body,
        })) = parser.parse_chunk(b"GET / HTTP/1.1\r\nHost: example.com\r\n\r\n")
        else {
            panic!();
        };

        assert_eq!(method, "GET");
        assert_eq!(path, "/");
        assert_eq!(headers.len(), 1);
        assert_eq!(headers["host"], vec!["example.com"]);
        assert_eq!(first_body.len(), 0);
    }

    #[test]
    fn parse_http_request_with_body() {
        let mut parser = HttpRequestParser::new();
        let Ok(Some(Part::Request {
            method,
            path,
            headers,
            first_body,
        })) = parser.parse_chunk(
            b"POST /submit HTTP/1.1\r\nHost: example.com\r\nContent-Length: 5\r\n\r\nHello",
        )
        else {
            panic!();
        };

        assert_eq!(method, "POST");
        assert_eq!(path, "/submit");
        assert_eq!(headers.len(), 2);
        assert_eq!(headers["content-length"], vec!["5"]);
        assert_eq!(first_body, b"Hello");
    }

    #[test]
    fn parse_http_request_with_partial_body() {
        let mut parser = HttpRequestParser::new();
        assert!(matches!(
            parser.parse_chunk(
                b"POST /submit HTTP/1.1\r\nHost: example.com\r\nContent-Length: 5\r\n"
            ),
            Ok(None)
        ));

        let Ok(Some(Part::Request {
            method,
            path,
            headers,
            first_body,
        })) = parser.parse_chunk(b"\r\nHello")
        else {
            panic!();
        };

        assert_eq!(method, "POST");
        assert_eq!(path, "/submit");
        assert_eq!(headers.len(), 2);
        assert_eq!(headers["content-length"], vec!["5"]);
        assert_eq!(first_body, b"Hello");
    }

    #[test]
    fn parse_partial_http_request() {
        let mut parser = HttpRequestParser::new();

        assert!(matches!(parser.parse_chunk(b"GE"), Ok(None)));
        assert!(matches!(parser.parse_chunk(b"T /path"), Ok(None)));
        assert!(matches!(
            parser.parse_chunk(b"/to HTTP/1.1\r\nHost"),
            Ok(None)
        ));
        assert!(matches!(parser.parse_chunk(b": example"), Ok(None)));
        assert!(matches!(parser.parse_chunk(b".com\r\n"), Ok(None)));

        let Ok(Some(Part::Request {
            method,
            path,
            headers,
            first_body,
        })) = parser.parse_chunk(b"\r\n")
        else {
            panic!();
        };

        assert_eq!(method, "GET");
        assert_eq!(path, "/path/to");
        assert_eq!(headers.len(), 1);
        assert_eq!(headers["host"], vec!["example.com"]);
        assert_eq!(first_body.len(), 0);

        assert!(matches!(
            parser.parse_chunk(b"Hello"),
            Ok(Some(Part::Body { chunk }))
        ));
        assert!(matches!(
            parser.parse_chunk(b"World"),
            Ok(Some(Part::Body { chunk }))
        ));
    }
}
```
## apps/bin/http_server/http/response_writer.rs
```
use core::fmt::Debug;
use core::fmt::{self};

use starina::prelude::*;

pub trait Writer {
    type Error: Debug;

    fn write(&mut self, buf: &[u8]) -> Result<(), Self::Error>;
}

struct WriterWrapper<W: Writer> {
    writer: W,
    error: Option<W::Error>,
}

impl<W: Writer> fmt::Write for WriterWrapper<W> {
    fn write_str(&mut self, s: &str) -> fmt::Result {
        match self.write(s.as_bytes()) {
            Ok(()) => Ok(()),
            Err(err) => {
                self.error = Some(err);
                Err(fmt::Error)
            }
        }
    }
}

impl<W: Writer> WriterWrapper<W> {
    fn write(&mut self, buf: &[u8]) -> Result<(), W::Error> {
        self.writer.write(buf)
    }

    fn write_fmt(&mut self, args: fmt::Arguments<'_>) -> Result<(), W::Error> {
        match fmt::write(self, args) {
            Ok(()) => Ok(()),
            Err(_) => {
                let err = self.error.take().expect("fmt::write failed");
                Err(err)
            }
        }
    }
}

enum State {
    BeforeHeaders { headers_text: String },
    Body,
}

pub struct HttpResponseWriter<W: Writer> {
    state: State,
    writer: WriterWrapper<W>,
}

impl<W: Writer> HttpResponseWriter<W> {
    pub fn new(writer: W) -> Self {
        Self {
            state: State::BeforeHeaders {
                headers_text: String::new(),
            },
            writer: WriterWrapper {
                writer,
                error: None,
            },
        }
    }

    pub fn set_header(&mut self, name: &str, value: &str) -> Result<(), fmt::Error> {
        use core::fmt::Write;

        let State::BeforeHeaders { headers_text } = &mut self.state else {
            panic!("cannot set header after body has started");
        };

        write!(headers_text, "{}: {}\r\n", name, value)
    }

    pub fn write_status(&mut self, status: u16) -> Result<(), W::Error> {
        let State::BeforeHeaders { headers_text } = &mut self.state else {
            panic!("cannot write status twice");
        };

        write!(&mut self.writer, "HTTP/1.1 {}\r\n", status)?;
        self.writer.write(b"connection: close\r\n")?;
        self.writer.write(b"transfer-encoding: chunked\r\n")?;
        self.writer.write(headers_text.as_bytes())?;
        self.writer.write(b"\r\n")?;
        self.state = State::Body;
        Ok(())
    }

    pub fn write_body(&mut self, chunk: &[u8]) -> Result<(), W::Error> {
        if matches!(self.state, State::BeforeHeaders { .. }) {
            self.write_status(200)?;
        }

        // Chunked transfer encoding.
        write!(&mut self.writer, "{:x}\r\n", chunk.len())?;
        self.writer.write(chunk)?;
        self.writer.write(b"\r\n")?;
        Ok(())
    }
}

impl<W: Writer> Drop for HttpResponseWriter<W> {
    fn drop(&mut self) {
        match &self.state {
            State::BeforeHeaders { .. } => {
                // If we drop the writer before writing the headers, handle it as an error.
                let _ = self.write_status(500);
            }
            State::Body => {
                // The end of response body. Chunked encoding.
                let _ = self.writer.write(b"0\r\n\r\n");
            }
        }
    }
}
```
## apps/bin/http_server/lib.rs
```
#![no_std]

pub mod autogen;
mod connection;
mod http;

use autogen::Env;
use connection::ChannelWriter;
use connection::Conn;
use starina::collections::HashMap;
use starina::eventloop::Context;
use starina::eventloop::Dispatcher;
use starina::eventloop::EventLoop;
use starina::handle::HandleId;
use starina::handle::Handleable;
use starina::message::ConnectMsg;
use starina::message::OpenMsg;
use starina::message::OpenReplyMsg;
use starina::message::StreamDataMsg;
use starina::prelude::*;

#[derive(Debug)]
enum CtrlState {
    Opening,
    Ready,
}

pub struct App {
    state: spin::Mutex<CtrlState>,
    connections: spin::Mutex<HashMap<HandleId, Conn<ChannelWriter>>>,
}

impl EventLoop<Env> for App {
    fn init(dispatcher: &Dispatcher, env: Env) -> Self {
        let tcpip = env.tcpip;

        // let uri = format!("tcp:{}:{}", env.listen_host, env.listen_port);
        info!("connecting to tcpip");
        let uri = format!("tcp-listen:0.0.0.0:80");
        tcpip.send(OpenMsg { uri: &uri }).unwrap();

        dispatcher.split_and_add_channel(tcpip).unwrap();
        Self {
            state: spin::Mutex::new(CtrlState::Opening),
            connections: spin::Mutex::new(HashMap::new()),
        }
    }

    fn on_open_reply(&self, ctx: &Context, msg: OpenReplyMsg) {
        info!("got open-reply");

        // FIXME: Check txid
        let listen_ch = msg.handle;
        ctx.dispatcher.add_channel(listen_ch).unwrap();

        let mut state = self.state.lock();
        assert!(matches!(*state, CtrlState::Opening));
        *state = CtrlState::Ready;
    }

    fn on_connect(&self, ctx: &Context, msg: ConnectMsg) {
        trace!("new client connection");
        // FIXME: Check sender channel - it must be the listen channel
        let data_ch_id = msg.handle.handle_id();
        let sender = ctx
            .dispatcher
            .split_and_add_channel(msg.handle)
            .expect("failed to get channel sender");
        let mut connections = self.connections.lock();
        let tcp_writer = ChannelWriter::new(sender);
        connections.insert(data_ch_id, Conn::new(tcp_writer));
    }

    fn on_stream_data(&self, ctx: &Context, msg: StreamDataMsg<'_>) {
        let mut connections = self.connections.lock();
        let Some(conn) = connections.get_mut(&ctx.sender.handle().id()) else {
            debug_warn!(
                "stream data from an unexpected channel: {:?}",
                ctx.sender.handle().id()
            );
            return;
        };

        conn.on_tcp_data(msg.data);
    }
}
```
## apps/drivers/virtio_net/Cargo.toml
```
[package]
name = "virtio_net"
publish = false
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
starina = { workspace = true }
starina_driver_sdk = { workspace = true }
serde = { workspace = true, features = ["derive"] }
virtio = { workspace = true }

# TODO: Provide mutex in starina
spin = { workspace = true }
```
## apps/drivers/virtio_net/autogen.rs
```
use starina::collections::HashMap;
// TODO: auto geenrate this file from app.toml
use starina::device_tree::DeviceTree;
use starina::iobus::IoBus;
use starina::prelude::*;
use starina::spec::AppSpec;
use starina::spec::DeviceMatch;
use starina::spec::EnvItem;
use starina::spec::EnvType;
use starina::spec::ExportItem;
use starina::syscall::VsyscallPage;

use crate::App;

#[derive(serde::Deserialize)]
pub struct Env {
    pub iobus: HashMap<String, IoBus>,
    pub device_tree: DeviceTree,
}

pub const APP_SPEC: AppSpec = AppSpec {
    env: &[
        EnvItem {
            name: "device_tree",
            ty: EnvType::DeviceTree {
                matches: &[DeviceMatch::Compatible("virtio,mmio")],
            },
        },
        EnvItem {
            name: "iobus",
            ty: EnvType::IoBusMap,
        },
    ],
    exports: &[ExportItem::Service {
        name: "device/ethernet",
    }],
};

pub fn app_main(vsyscall: *const VsyscallPage) {
    starina::eventloop::app_loop::<Env, App>("virtio-net", vsyscall);
}
```
## apps/drivers/virtio_net/lib.rs
```
#![no_std]

pub mod autogen;

use autogen::Env;
use starina::eventloop::Context;
use starina::eventloop::Dispatcher;
use starina::eventloop::EventLoop;
use starina::interrupt::Interrupt;
use starina::message::ConnectMsg;
use starina::message::FramedDataMsg;
use starina::prelude::*;
use virtio_net::VirtioNet;

mod virtio_net;

pub struct App {
    virtio_net: spin::Mutex<VirtioNet>,
}

impl EventLoop<Env> for App {
    fn init(dispatcher: &Dispatcher, env: Env) -> Self {
        let mut virtio_net = VirtioNet::init_or_panic(env);
        let interrupt = virtio_net.take_interrupt().unwrap();
        dispatcher
            .add_interrupt(interrupt)
            .expect("failed to add interrupt");

        // Update the source mac address.
        let mac = virtio_net.mac_addr();
        debug!(
            "MAC address: {:02x}:{:02x}:{:02x}:{:02x}:{:02x}:{:02x}",
            mac[0], mac[1], mac[2], mac[3], mac[4], mac[5],
        );

        Self {
            virtio_net: spin::Mutex::new(virtio_net),
        }
    }

    fn on_connect(&self, ctx: &Context, msg: ConnectMsg) {
        let tcpip_ch = ctx.dispatcher.split_and_add_channel(msg.handle).unwrap();
        self.virtio_net.lock().update_receive(Box::new(move |data| {
            if let Err(err) = tcpip_ch.send(FramedDataMsg { data }) {
                debug_warn!("failed to send data to tcpip: {:?}", err);
            }
        }));
    }

    fn on_framed_data(&self, _ctx: &Context, msg: FramedDataMsg<'_>) {
        trace!("frame data received: {} bytes", msg.data.len());
        self.virtio_net.lock().transmit(msg.data);
        core::mem::forget(msg);
    }

    fn on_interrupt(&self, interrupt: &Interrupt) {
        interrupt.acknowledge().unwrap();
        self.virtio_net.lock().handle_interrupt();
    }
}
```
## apps/drivers/virtio_net/virtio_net.rs
```
use core::mem::offset_of;

use starina::address::DAddr;
use starina::folio::MmioFolio;
use starina::info;
use starina::interrupt::Interrupt;
use starina::iobus::IoBus;
use starina::prelude::Box;
use starina::prelude::vec::Vec;
use starina_driver_sdk::DmaBufferPool;
use virtio::DeviceType;
use virtio::transports::VirtioTransport;
use virtio::transports::mmio::VirtioMmio;
use virtio::virtqueue::VirtQueue;
use virtio::virtqueue::VirtqDescBuffer;
use virtio::virtqueue::VirtqUsedChain;

use crate::autogen::Env;

const DMA_BUF_SIZE: usize = 4096;

#[derive(Debug, Copy, Clone)]
#[repr(C, packed)]
struct VirtioNetModernHeader {
    flags: u8,
    gso_type: u8,
    hdr_len: u16,
    gso_size: u16,
    checksum_start: u16,
    checksum_offset: u16,
    // num_buffer: u16,
}

#[repr(C, packed)]
struct VirtioNetConfig {
    mac: [u8; 6],
    status: u16,
    max_virtqueue_pairs: u16,
    mtu: u16,
    speed: u32,
    duplex: u8,
    rss_max_key_size: u8,
    rss_max_indirection_table_length: u16,
    supported_hash_types: u32,
}

fn probe(mut env: Env) -> Option<(IoBus, Box<dyn VirtioTransport>, Vec<VirtQueue>, Interrupt)> {
    for (name, node) in env.device_tree.devices {
        if !node.compatible.iter().any(|c| c == "virtio,mmio") {
            continue;
        }

        let iobus = env.iobus.get(&node.bus).expect("missing iobus");
        let daddr = DAddr::new(node.reg[0].addr as usize);
        let len = node.reg[0].size as usize;
        let folio = MmioFolio::create_pinned(&iobus, daddr, len).unwrap();
        let mut virtio = VirtioMmio::new(folio);
        let device_type = virtio.probe();

        if device_type == Some(DeviceType::Net) {
            info!("found virtio-net device: {}", name);
            let mut transport = Box::new(virtio) as Box<dyn VirtioTransport>;
            let virtqueues = transport.initialize(&iobus, 0, 2).unwrap();
            let iobus = env.iobus.remove(&node.bus).unwrap();
            let interrupt =
                Interrupt::create(node.interrupts[0]).expect("failed to create interrupt");
            return Some((iobus, transport, virtqueues, interrupt));
        }
    }

    None
}

pub struct VirtioNet {
    mac_addr: [u8; 6],
    _iobus: IoBus,
    transport: Box<dyn VirtioTransport>,
    transmitq: VirtQueue,
    receiveq: VirtQueue,
    transmitq_buffers: DmaBufferPool,
    receiveq_buffers: DmaBufferPool,
    interrupt: Option<Interrupt>,
    receive: Option<Box<dyn FnMut(&[u8]) + Send + Sync>>,
}

impl VirtioNet {
    pub fn init_or_panic(env: Env) -> Self {
        let (iobus, mut transport, mut virtqueues, interrupt) = probe(env).unwrap();
        assert!(transport.is_modern());

        let mut mac = [0; 6];
        for i in 0..6 {
            mac[i] = transport.read_device_config8((offset_of!(VirtioNetConfig, mac) + i) as u16)
        }

        let mut receiveq = virtqueues.remove(0 /* 1st queue */);
        let transmitq = virtqueues.remove(0 /* 2nd queue */);
        let mut receiveq_buffers =
            DmaBufferPool::new(&iobus, DMA_BUF_SIZE, receiveq.num_descs() as usize);
        let transmitq_buffers =
            DmaBufferPool::new(&iobus, DMA_BUF_SIZE, transmitq.num_descs() as usize);

        while let Some(i) = receiveq_buffers.allocate() {
            let chain = &[VirtqDescBuffer::WritableFromDevice {
                daddr: receiveq_buffers.daddr(i),
                len: DMA_BUF_SIZE,
            }];

            receiveq.enqueue(chain);
        }
        receiveq.notify(&mut *transport);

        Self {
            _iobus: iobus,
            mac_addr: mac,
            transport,
            receiveq,
            transmitq,
            receiveq_buffers,
            transmitq_buffers,
            interrupt: Some(interrupt),
            receive: None,
        }
    }

    pub fn update_receive(&mut self, f: Box<dyn FnMut(&[u8]) + Send + Sync>) {
        self.receive = Some(f);
    }

    pub fn mac_addr(&self) -> &[u8; 6] {
        &self.mac_addr
    }

    pub fn take_interrupt(&mut self) -> Option<Interrupt> {
        self.interrupt.take()
    }

    pub fn transmit(&mut self, payload: &[u8]) {
        let mut writer = self.transmitq_buffers.to_device().unwrap();
        writer
            .write(VirtioNetModernHeader {
                flags: 0,
                hdr_len: 0,
                gso_type: 0,
                gso_size: 0,
                checksum_start: 0,
                checksum_offset: 0,
                // num_buffer: 0,
            })
            .unwrap();
        writer.write_bytes(payload).unwrap();
        let daddr = writer.finish();

        self.transmitq.enqueue(&[
            VirtqDescBuffer::ReadOnlyFromDevice {
                daddr,
                len: size_of::<VirtioNetModernHeader>(),
            },
            VirtqDescBuffer::ReadOnlyFromDevice {
                daddr: daddr.add(size_of::<VirtioNetModernHeader>()),
                len: payload.len(),
            },
        ]);
        self.transmitq.notify(&mut *self.transport);
    }

    pub fn handle_interrupt(&mut self) {
        loop {
            let status = self.transport.read_isr_status();
            self.transport.ack_interrupt(status);

            if !status.queue_intr() {
                break;
            }

            while let Some(VirtqUsedChain { descs, total_len }) = self.receiveq.pop_used() {
                debug_assert!(descs.len() == 1);
                let mut remaining = total_len;
                for desc in descs {
                    let VirtqDescBuffer::WritableFromDevice { daddr, len } = desc else {
                        panic!("unexpected desc");
                    };

                    let read_len = core::cmp::min(len, remaining);
                    remaining -= read_len;

                    let mut buf = self
                        .receiveq_buffers
                        .from_device(daddr)
                        .expect("invalid daddr");

                    let _header = buf.read::<VirtioNetModernHeader>();
                    let payload = buf.read_bytes(read_len).unwrap();
                    if let Some(receive) = self.receive.as_mut() {
                        receive(payload);
                    }
                }
            }

            while let Some(VirtqUsedChain { descs, .. }) = self.transmitq.pop_used() {
                let VirtqDescBuffer::ReadOnlyFromDevice { daddr, .. } = descs[0] else {
                    panic!("unexpected desc");
                };
                let buffer_index = self
                    .transmitq_buffers
                    .daddr_to_id(daddr)
                    .expect("invalid daddr");
                self.transmitq_buffers.free(buffer_index);
            }

            while let Some(buffer_index) = self.receiveq_buffers.allocate() {
                let chain = &[VirtqDescBuffer::WritableFromDevice {
                    daddr: self.receiveq_buffers.daddr(buffer_index),
                    len: DMA_BUF_SIZE,
                }];

                self.receiveq.enqueue(chain);
            }

            self.receiveq.notify(&mut *self.transport);
        }
    }
}
```
## apps/servers/tcpip/Cargo.toml
```
[package]
name = "tcpip"
publish = false
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
starina = { workspace = true }
serde = { workspace = true, features = ["derive"] }
spin = { workspace = true }
log = "0.4.22"
smoltcp = { version = "0.12.0", default-features = false, features = [
    "log",
    "alloc",
    "medium-ethernet",
    "socket-tcp",
    "proto-ipv4",
] }
```
## apps/servers/tcpip/autogen.rs
```
use starina::channel::Channel;
// TODO: auto geenrate this file from app.toml
use starina::spec::AppSpec;
use starina::spec::EnvItem;
use starina::spec::EnvType;
use starina::spec::ExportItem;
use starina::syscall::VsyscallPage;

use crate::App;

#[derive(serde::Deserialize)]
pub struct Env {
    pub driver: Channel,
}

pub const APP_SPEC: AppSpec = AppSpec {
    env: &[EnvItem {
        name: "driver",
        ty: EnvType::Service {
            name: "device/ethernet",
        },
    }],
    exports: &[ExportItem::Service { name: "tcpip" }],
};

pub fn app_main(vsyscall: *const VsyscallPage) {
    starina::eventloop::app_loop::<Env, App>("tcpip", vsyscall);
}
```
## apps/servers/tcpip/device.rs
```
use smoltcp::phy::DeviceCapabilities;
use smoltcp::time::Instant;
use starina::collections::vec_deque::VecDeque;
use starina::prelude::vec::Vec;
use starina::prelude::*;

/// Represents a right to receive a RX packet.
pub struct RxTokenImpl(Vec<u8>);

impl smoltcp::phy::RxToken for RxTokenImpl {
    /// Smoltcp wants to receive a packet.
    fn consume<R, F>(self, f: F) -> R
    where
        F: FnOnce(&[u8]) -> R,
    {
        // Simply pass the buffer to smoltcp.
        f(&self.0)
    }
}

pub struct TxTokenImpl<'a>(&'a mut NetDevice);

impl<'a> smoltcp::phy::TxToken for TxTokenImpl<'a> {
    /// Smoltcp wants to transmit a packet of `len` bytes.
    fn consume<R, F>(self, len: usize, f: F) -> R
    where
        F: FnOnce(&mut [u8]) -> R,
    {
        assert!(len <= self.0.tx_buf.len());

        // Let smoltcp fill a packet to transmit.
        let ret = f(&mut self.0.tx_buf[..len]);

        (self.0.transmit)(&self.0.tx_buf[..len]);
        ret
    }
}

/// A network device implementation for smoltcp.
pub struct NetDevice {
    transmit: Box<dyn Fn(&[u8]) + Send + Sync>,
    tx_buf: Vec<u8>,
    rx_queue: VecDeque<Vec<u8>>,
}

impl NetDevice {
    pub fn new(transmit: Box<dyn Fn(&[u8]) + Send + Sync>) -> NetDevice {
        NetDevice {
            transmit,
            tx_buf: vec![0; 1514],
            rx_queue: VecDeque::new(),
        }
    }

    pub fn receive_pkt(&mut self, pkt: &[u8]) {
        self.rx_queue.push_back(pkt.to_vec());
    }
}

impl smoltcp::phy::Device for NetDevice {
    type RxToken<'a> = RxTokenImpl;
    type TxToken<'a> = TxTokenImpl<'a>;

    fn capabilities(&self) -> DeviceCapabilities {
        let mut caps = DeviceCapabilities::default();
        caps.medium = smoltcp::phy::Medium::Ethernet;
        caps.max_transmission_unit = 1514;
        caps
    }

    fn receive(&mut self, _timestamp: Instant) -> Option<(Self::RxToken<'_>, Self::TxToken<'_>)> {
        self.rx_queue
            .pop_front()
            .map(|pkt| (RxTokenImpl(pkt), TxTokenImpl(self)))
    }

    fn transmit(&mut self, _timestamp: Instant) -> Option<Self::TxToken<'_>> {
        Some(TxTokenImpl(self))
    }
}
```
## apps/servers/tcpip/lib.rs
```
#![no_std]

pub mod autogen;
mod device;
mod smoltcp_logger;
mod tcpip;

use core::net::Ipv4Addr;

use autogen::Env;
use device::NetDevice;
use smoltcp::wire::EthernetAddress;
use smoltcp::wire::HardwareAddress;
use smoltcp::wire::IpAddress;
use smoltcp::wire::IpCidr;
use smoltcp::wire::IpListenEndpoint;
use starina::channel::Channel;
use starina::collections::HashMap;
use starina::eventloop::Context;
use starina::eventloop::Dispatcher;
use starina::eventloop::EventLoop;
use starina::handle::HandleId;
use starina::handle::Handleable;
use starina::message::ConnectMsg;
use starina::message::FramedDataMsg;
use starina::message::OpenMsg;
use starina::message::OpenReplyMsg;
use starina::message::StreamDataMsg;
use starina::prelude::*;
use tcpip::SocketEvent;
use tcpip::TcpIp;

fn parse_addr(addr: &str) -> Option<(Ipv4Addr, u16)> {
    let mut parts = addr.split(':');
    let ip = parts.next()?.parse().ok()?;
    let port = parts.next()?.parse().ok()?;
    Some((ip, port))
}

pub struct App {
    tcpip: spin::Mutex<TcpIp<'static>>,
    data_channels: spin::Mutex<HashMap<HandleId, smoltcp::iface::SocketHandle>>,
}

impl EventLoop<Env> for App {
    fn init(dispatcher: &Dispatcher, env: Env) -> Self {
        smoltcp_logger::init();

        let driver = dispatcher
            .split_and_add_channel(env.driver)
            .expect("failed to get channel sender");

        info!("hello from tcpip");

        let transmit = move |data: &[u8]| {
            trace!("transmit {} bytes", data.len());
            if let Err(err) = driver.send(FramedDataMsg { data }) {
                debug_warn!("failed to send: {:?}", err);
            }
        };

        // FIXME:
        let device = NetDevice::new(Box::new(transmit));
        let ip = IpCidr::new(IpAddress::v4(10, 0, 2, 15), 24);
        let gw_ip = Ipv4Addr::new(10, 0, 2, 2);
        let mac: [u8; 6] = [0x52, 0x54, 0x00, 0x12, 0x34, 0x56];

        let hwaddr = HardwareAddress::Ethernet(EthernetAddress(mac));
        let tcpip = TcpIp::new(device, ip, gw_ip, hwaddr);

        Self {
            tcpip: spin::Mutex::new(tcpip),
            data_channels: spin::Mutex::new(HashMap::new()),
        }
    }

    fn on_connect(&self, ctx: &Context, msg: ConnectMsg) {
        ctx.dispatcher.add_channel(msg.handle).unwrap();
    }

    fn on_open(&self, ctx: &Context, msg: OpenMsg<'_>) {
        info!("got open message: {}", msg.uri);
        match msg.uri.split_once(':') {
            Some(("tcp-listen", rest)) => {
                let Some((ip, port)) = parse_addr(rest) else {
                    debug_warn!("invalid tcp-listen message: {}", msg.uri);
                    return;
                };

                let listen_addr = match ip {
                    Ipv4Addr::UNSPECIFIED => IpListenEndpoint { addr: None, port },
                    _ => (ip, port).into(),
                };

                let (our_ch, their_ch) = Channel::new().unwrap();
                let sender = ctx.dispatcher.split_and_add_channel(our_ch).unwrap();

                // Have a separate scope to drop the tcpip lock as soon as possible.
                {
                    trace!("tcp-listen: {:?}", listen_addr);
                    let mut tcpip = self.tcpip.lock();
                    tcpip.tcp_listen(listen_addr, sender).unwrap();
                }

                ctx.sender.send(OpenReplyMsg { handle: their_ch }).unwrap(); // FIXME: what if backpressure happens?
            }
            _ => {
                debug_warn!("unknown open message: {}", msg.uri);
                // FIXME: How should we reply error?
            }
        }
    }

    fn on_stream_data(&self, ctx: &Context, msg: StreamDataMsg<'_>) {
        let smol_handle = self
            .data_channels
            .lock()
            .get(&ctx.sender.handle().id())
            .copied()
            .unwrap();
        let mut tcpip = self.tcpip.lock();
        // TODO: error handling
        tcpip.tcp_send(smol_handle, msg.data).unwrap();
        poll(&ctx.dispatcher, &mut *tcpip, &self.data_channels);
    }

    fn on_framed_data(&self, ctx: &Context, msg: FramedDataMsg<'_>) {
        let mut tcpip = self.tcpip.lock();
        tcpip.receive_packet(msg.data);
        poll(&ctx.dispatcher, &mut *tcpip, &self.data_channels);
    }
}

fn poll(
    dispatcher: &Dispatcher,
    tcpip: &mut TcpIp,
    data_channels: &spin::Mutex<HashMap<HandleId, smoltcp::iface::SocketHandle>>,
) {
    tcpip.poll(
        &(dispatcher, data_channels),
        |(dispatcher, data_channels), ev| {
            match ev {
                SocketEvent::Data { ch, data } => {
                    ch.send(StreamDataMsg { data }).unwrap(); // FIXME: what if backpressure happens?
                }
                SocketEvent::Close { ch } => {
                    dispatcher.close_channel(ch.handle().id()).unwrap();
                }
                SocketEvent::NewConnection { ch, smol_handle } => {
                    let (ours, theirs) = Channel::new().unwrap();

                    data_channels.lock().insert(ours.handle_id(), smol_handle);
                    let our_ch_sender = dispatcher
                        .split_and_add_channel(ours)
                        .expect("failed to get channel sender");

                    ch.send(ConnectMsg { handle: theirs }).unwrap(); // FIXME: what if backpressure happens?

                    // The socket has become an esblished socket, so replace the old
                    // sender handle with a new data channel.
                    *ch = our_ch_sender;
                }
            }
        },
    );
}
```
## apps/servers/tcpip/smoltcp_logger.rs
```
use starina::prelude::*;

/// A logger implementation for `log` crate so that we can observe what's
/// happening in smoltcp.
struct Logger;

static LOGGER: Logger = Logger;

impl log::Log for Logger {
    fn enabled(&self, _metadata: &log::Metadata) -> bool {
        true
    }

    fn flush(&self) {}

    fn log(&self, record: &log::Record) {
        debug!(
            "{}: {}",
            record.module_path().unwrap_or("(unknown)"),
            record.args()
        );
    }
}

// TODO: Move this log crate support to starina crate. Other libraries may use log
//       crate too.
pub fn init() {
    log::set_logger(&LOGGER).unwrap();
    log::set_max_level(if cfg!(debug_assertions) {
        log::LevelFilter::Trace
    } else {
        log::LevelFilter::Info
    });
}
```
## apps/servers/tcpip/tcpip.rs
```
use core::net::Ipv4Addr;

use smoltcp::iface::Config;
use smoltcp::iface::Interface;
use smoltcp::iface::PollResult;
use smoltcp::iface::SocketHandle;
use smoltcp::iface::SocketSet;
use smoltcp::socket::tcp;
use smoltcp::time::Instant;
use smoltcp::wire::HardwareAddress;
use smoltcp::wire::IpCidr;
use smoltcp::wire::IpEndpoint;
use smoltcp::wire::IpListenEndpoint;
use starina::channel::ChannelSender;
use starina::collections::HashMap;
use starina::error::ErrorCode;
use starina::prelude::*;

use crate::device::NetDevice;

fn now() -> Instant {
    // FIXME:
    Instant::from_millis(0)
}

#[derive(Debug, PartialEq, Eq)]
enum SocketState {
    Connecting { remote_endpoint: IpEndpoint },
    Listening { listen_endpoint: IpListenEndpoint },
    Established,
    Closed,
}

struct Socket {
    ch: ChannelSender,
    smol_handle: SocketHandle,
    state: SocketState,
}

#[derive(Debug)]
pub enum SocketEvent<'a> {
    NewConnection {
        ch: &'a mut ChannelSender,
        smol_handle: SocketHandle,
    },
    Data {
        ch: &'a ChannelSender,
        data: &'a [u8],
    },
    Close {
        ch: &'a ChannelSender,
    },
}

pub struct TcpIp<'a> {
    /// Our socket states. The key is the smoltcp socket handle.
    sockets: HashMap<SocketHandle, Socket>,
    /// The smoltcp socket states.
    smol_sockets: SocketSet<'a>,
    device: NetDevice,
    recv_buf: Vec<u8>,
    iface: Interface,
    next_ephemeral_port: u16,
}

impl<'a> TcpIp<'a> {
    pub fn new(
        mut device: NetDevice,
        our_ip: IpCidr,
        gw_ip: Ipv4Addr,
        hwaddr: HardwareAddress,
    ) -> TcpIp<'a> {
        let config = Config::new(hwaddr);
        let mut iface = Interface::new(config, &mut device, now());
        let smol_sockets = SocketSet::new(Vec::with_capacity(16));

        iface.update_ip_addrs(|ip_addrs| {
            ip_addrs.push(our_ip).unwrap();
        });

        iface.routes_mut().add_default_ipv4_route(gw_ip).unwrap();

        TcpIp {
            device,
            iface,
            smol_sockets,
            sockets: HashMap::new(),
            recv_buf: vec![0; 1514],
            next_ephemeral_port: 49152,
        }
    }

    /// Makes progress in smoltcp - receive RX packets, update socket states,
    /// and transmit TX packets.
    ///
    /// As it detects changes in socket states, it calls the `callback` so that
    /// we can do message passing in the main loop.
    pub fn poll<C, F>(&mut self, ctx: &C, mut callback: F)
    where
        F: FnMut(&C, SocketEvent<'_>),
    {
        loop {
            let result = self
                .iface
                .poll(now(), &mut self.device, &mut self.smol_sockets);

            match result {
                PollResult::SocketStateChanged => {
                    // Continue processing sockets.
                }
                PollResult::None => {
                    // No changes in smoltcp.
                    break;
                }
            }

            let mut needs_listen = Vec::new();
            for (handle, sock) in self.sockets.iter_mut() {
                let smol_sock = self.smol_sockets.get_mut::<tcp::Socket>(sock.smol_handle);
                match (&mut sock.state, smol_sock.state()) {
                    (SocketState::Connecting { .. }, tcp::State::SynSent) => {
                        trace!("connecting socket {:?}", handle);
                    }
                    (SocketState::Connecting { .. }, _state) => {
                        todo!();
                    }
                    (
                        SocketState::Listening { .. },
                        tcp::State::Listen | tcp::State::SynReceived,
                    ) => {
                        // Do nothing.
                    }
                    (SocketState::Listening { listen_endpoint }, tcp::State::Established) => {
                        // Create a new listening socket as this one is now
                        // established.
                        //
                        // Note: This should be done before calling the callback
                        //       becaseu it may overwrite `ch` and drop the
                        //       previous one.
                        needs_listen.push((*listen_endpoint, sock.ch.clone()));

                        // The listening socket has transitioned to established.
                        callback(
                            ctx,
                            SocketEvent::NewConnection {
                                ch: &mut sock.ch,
                                smol_handle: *handle,
                            },
                        );

                        sock.state = SocketState::Established;
                    }
                    (SocketState::Listening { .. }, _) => {
                        // Inactive, closed, or unknown state. Close the socket.
                        callback(ctx, SocketEvent::Close { ch: &sock.ch });
                        sock.state = SocketState::Closed;
                    }
                    (SocketState::Established, _) if smol_sock.can_recv() => {
                        // The establish connection with some received data.
                        loop {
                            let len = smol_sock.recv_slice(self.recv_buf.as_mut_slice()).unwrap();
                            if len == 0 {
                                break;
                            }

                            callback(
                                ctx,
                                SocketEvent::Data {
                                    ch: &sock.ch,
                                    data: &self.recv_buf[..len],
                                },
                            );
                        }
                    }
                    (SocketState::Established, tcp::State::Established) => {
                        // Do nothing.
                    }
                    (SocketState::Established, _) => {
                        // Unknown state. Close the connection.
                        callback(ctx, SocketEvent::Close { ch: &sock.ch });
                        sock.state = SocketState::Closed;
                    }
                    (SocketState::Closed, _) => {
                        unreachable!();
                    }
                }
            }

            // Remove closed sockets from self.sockets and smoltcp's socket set.
            self.sockets.retain(|handle, sock| {
                if sock.state == SocketState::Closed {
                    debug_warn!("closing socket {:?}", handle);
                    self.smol_sockets.remove(*handle);
                    false
                } else {
                    true
                }
            });

            for (listen_endpoint, ch) in needs_listen {
                self.replenish_listen_sock(listen_endpoint, ch);
            }
        }
    }

    fn replenish_listen_sock(&mut self, listen_endpoint: IpListenEndpoint, ch: ChannelSender) {
        let rx_buf = tcp::SocketBuffer::new(vec![0; 8192]);
        let tx_buf = tcp::SocketBuffer::new(vec![0; 8192]);
        let mut sock = tcp::Socket::new(rx_buf, tx_buf);
        sock.listen(listen_endpoint).unwrap();

        let handle = self.smol_sockets.add(sock);
        self.sockets.insert(
            handle,
            Socket {
                ch,
                smol_handle: handle,
                state: SocketState::Listening { listen_endpoint },
            },
        );
    }

    fn get_ephemeral_port(&mut self) -> Result<u16, ErrorCode> {
        let port = self.next_ephemeral_port;
        self.next_ephemeral_port += 1;
        Ok(port)
    }

    pub fn tcp_connect(
        &mut self,
        remote_endpoint: IpEndpoint,
        ch: ChannelSender,
    ) -> Result<(), ErrorCode> {
        let rx_buf = tcp::SocketBuffer::new(vec![0; 8192]);
        let tx_buf = tcp::SocketBuffer::new(vec![0; 8192]);
        let mut sock = tcp::Socket::new(rx_buf, tx_buf);
        let our_port = self.get_ephemeral_port()?;
        sock.connect(self.iface.context(), remote_endpoint, our_port)
            .unwrap(); // FIXME:

        let handle = self.smol_sockets.add(sock);
        self.sockets.insert(
            handle,
            Socket {
                ch,
                smol_handle: handle,
                state: SocketState::Connecting { remote_endpoint },
            },
        );

        Ok(())
    }

    pub fn tcp_listen(
        &mut self,
        listen_endpoint: IpListenEndpoint,
        ch: ChannelSender,
    ) -> Result<(), ErrorCode> {
        self.replenish_listen_sock(listen_endpoint, ch);
        Ok(())
    }

    pub fn tcp_send(&mut self, handle: SocketHandle, data: &[u8]) -> Result<(), ErrorCode> {
        let socket = self.sockets.get_mut(&handle).ok_or(ErrorCode::NotFound)?;

        if !matches!(socket.state, SocketState::Established { .. }) {
            return Err(ErrorCode::InvalidState);
        }

        // Write the data to the TCP buffer.
        if self
            .smol_sockets
            .get_mut::<tcp::Socket>(socket.smol_handle)
            .send_slice(data)
            .is_err()
        {
            return Err(ErrorCode::InvalidState);
        }

        Ok(())
    }

    pub fn receive_packet(&mut self, pkt: &[u8]) {
        self.device.receive_pkt(pkt);
    }
}
```
## docs/.gitignore
```
/node_modules
/.vitepress/cache
```
## docs/.vitepress/config.mts
```
import { defineConfig } from 'vitepress'

// https://vitepress.dev/reference/site-config
export default defineConfig({
    title: "Starina Documentation",
    description: "A VitePress Site",
    themeConfig: {
        nav: [
            { text: 'Home', link: '/' },
            { text: 'Examples', link: '/markdown-examples' }
        ],

        sidebar: [
            {
                text: 'Examples',
                items: [
                    { text: 'Markdown Examples', link: '/markdown-examples' },
                    { text: 'Runtime API Examples', link: '/api-examples' }
                ]
            }
        ],

        socialLinks: [
            { icon: 'github', link: 'https://github.com/vuejs/vitepress' }
        ]
    }
})
```
## docs/index.md
```
---
layout: home

hero:
  name: "Starina Documentation"
  text: "Starina Documentation"
---

```
## docs/kernel-coding-guidelines.md
```
# Kernel Coding Guidelines

Kernel development is much more strict than application development. In this guide, we present some implicit rules that you should follow when writing kernel code.

## Execution flow

Once the kernel is booted, it will behaves like an event handler: it waits for events (e.g. system calls, interrupts, and exceptions), saves the current thread's state, does the necessary job, and resumes a thread.

## Single kernel stack design

Unlike traditional operating systems, Starina kernel uses a single stack per CPU, instead of having a dedicated stack for each thread. This design resembles how async Rust works - we need a separate state machine. In kernel, we don't use `async`/`await` syntax, but we use `ThreadState` to represent the state of a thread.

## APIs

| `libstd` equivalent | Kernel alternative | Remarks |
|----------------|--------------------|----|
| `Arc` | `crate::refcount::SharedRef` | |
| `Mutex` | `crate::spinlock::SpinLock` | |
| `thread_local` | `CpuVar` | A CPU-local variable, which is similar to `thread_local` in the userspace. |

## Rules

- Avoid `panic`s. If you use `unwrap`, describe why you think it never fails.
- Handle allocation failures in collections (e.g. `Vec`). Use `try_reserve` before adding a new element to a collection.

```
## docs/package.json
```
{
    "private": true,
    "scripts": {
        "docs:dev": "vitepress dev",
        "docs:build": "vitepress build",
        "docs:preview": "vitepress preview"
    },
    "devDependencies": {
        "vitepress": "^1.6.3"
    }
}```
## docs/pnpm-lock.yaml
```
lockfileVersion: '9.0'

settings:
  autoInstallPeers: true
  excludeLinksFromLockfile: false

importers:

  .:
    devDependencies:
      vitepress:
        specifier: ^1.6.3
        version: 1.6.3(@algolia/client-search@5.23.2)(postcss@8.5.3)(search-insights@2.17.3)

packages:

  '@algolia/autocomplete-core@1.17.7':
    resolution: {integrity: sha512-BjiPOW6ks90UKl7TwMv7oNQMnzU+t/wk9mgIDi6b1tXpUek7MW0lbNOUHpvam9pe3lVCf4xPFT+lK7s+e+fs7Q==}

  '@algolia/autocomplete-plugin-algolia-insights@1.17.7':
    resolution: {integrity: sha512-Jca5Ude6yUOuyzjnz57og7Et3aXjbwCSDf/8onLHSQgw1qW3ALl9mrMWaXb5FmPVkV3EtkD2F/+NkT6VHyPu9A==}
    peerDependencies:
      search-insights: '>= 1 < 3'

  '@algolia/autocomplete-preset-algolia@1.17.7':
    resolution: {integrity: sha512-ggOQ950+nwbWROq2MOCIL71RE0DdQZsceqrg32UqnhDz8FlO9rL8ONHNsI2R1MH0tkgVIDKI/D0sMiUchsFdWA==}
    peerDependencies:
      '@algolia/client-search': '>= 4.9.1 < 6'
      algoliasearch: '>= 4.9.1 < 6'

  '@algolia/autocomplete-shared@1.17.7':
    resolution: {integrity: sha512-o/1Vurr42U/qskRSuhBH+VKxMvkkUVTLU6WZQr+L5lGZZLYWyhdzWjW0iGXY7EkwRTjBqvN2EsR81yCTGV/kmg==}
    peerDependencies:
      '@algolia/client-search': '>= 4.9.1 < 6'
      algoliasearch: '>= 4.9.1 < 6'

  '@algolia/client-abtesting@5.23.2':
    resolution: {integrity: sha512-EudQGeYEzviwqPH8WoqP5VTQssE/PW6sEdL0zzOyKt2bWnWoUp5Rnm67sCbxYDR44JpUchbkul0PfWrSYsBPjQ==}
    engines: {node: '>= 14.0.0'}

  '@algolia/client-analytics@5.23.2':
    resolution: {integrity: sha512-zmJrkZqWFu+ft+VRcttZZJhw5ElkhBtOArRzQOu9sRnrSSodBOdPRhAfvu8tG93Hv67wh5qQaTBwLxM58AxuMg==}
    engines: {node: '>= 14.0.0'}

  '@algolia/client-common@5.23.2':
    resolution: {integrity: sha512-xaE6o4BMdqYBe0iB7JjX6G9/Qeqx6TSs9T4d6VJ0JHPsEyklSwIbKRiomPeYD7vzt2P4t45Io6QBhifOUP+0qg==}
    engines: {node: '>= 14.0.0'}

  '@algolia/client-insights@5.23.2':
    resolution: {integrity: sha512-F85hpMszbr5ZGt8gFdl7WOugELRF4z3R1nD9n3t7PZ/2alV7IR75UQY8/jMQDwij/lrnVaKbLeIvKKy6K7ncZw==}
    engines: {node: '>= 14.0.0'}

  '@algolia/client-personalization@5.23.2':
    resolution: {integrity: sha512-TuGaGKiQvQqFNR4c3Vdl+JBe6dkEPmRzVyIdWLrurOPEmFmVCKRxtSnLr0TVFl6de/JfDAXuchvtvLHFxv9P2A==}
    engines: {node: '>= 14.0.0'}

  '@algolia/client-query-suggestions@5.23.2':
    resolution: {integrity: sha512-fg2tZf7Sf51Icjfrea0dnfbfwlJ7kXMcRsWSJN3DZhEi/Y4mMmK9L0Cq8sby6HDzxy5T8xEWNWC3TMx5FvrJ6w==}
    engines: {node: '>= 14.0.0'}

  '@algolia/client-search@5.23.2':
    resolution: {integrity: sha512-XiTjt0qgsJk9OqvDpMwTgUaPAYNSQcMILRfSYiorgiyc71yYM7Lq1vRSVxhB0m51mrViWj4rIR6kSiJRXebqvQ==}
    engines: {node: '>= 14.0.0'}

  '@algolia/ingestion@1.23.2':
    resolution: {integrity: sha512-7ClIghvUFZTomBipD8Kor9Z5llcAM3lHUBG3VFOvUsOxOJcaMMONlBXyoFDfI1na+u14lVaGehY2oIEfY1eB0w==}
    engines: {node: '>= 14.0.0'}

  '@algolia/monitoring@1.23.2':
    resolution: {integrity: sha512-kF7KKd0iIIlaD70flFS+8+DNxRvIzrG9A22iWG5LDX225Kl6pITroq+qIUweqqyyoqJBYuIXKZGDGtnahEwQxw==}
    engines: {node: '>= 14.0.0'}

  '@algolia/recommend@5.23.2':
    resolution: {integrity: sha512-nAgS2O5ww8J4fgW6GAiybAdr0uH7MV74srPdx51cPJRpQBEge4WnYBaOWx1/a53qI0xwNtQudnEyBGUzsSYaAw==}
    engines: {node: '>= 14.0.0'}

  '@algolia/requester-browser-xhr@5.23.2':
    resolution: {integrity: sha512-yw6IzgQcwr4cZuoQCEoQui9G0rhVRGCyhPhW+gmrXe6oVr4qB50FV6mWGLA170+iqGVjPn/DVuOhExjBzcViTQ==}
    engines: {node: '>= 14.0.0'}

  '@algolia/requester-fetch@5.23.2':
    resolution: {integrity: sha512-8rmSybTwIqmGx3P0qkOEUkkyeIewglaKq6yUnxnVkBJbd4USfIZsw9cME1YUEHeZI7aOhTQg9QteUHSKXclF5A==}
    engines: {node: '>= 14.0.0'}

  '@algolia/requester-node-http@5.23.2':
    resolution: {integrity: sha512-IHpUiW3d3oVE5tCYqQN7X71/EbXI7f8WxU85eWW1UYEWEknqW3csdGctyIW7+qMHFfxeDymI1Wln/gGHHIXLIw==}
    engines: {node: '>= 14.0.0'}

  '@babel/helper-string-parser@7.25.9':
    resolution: {integrity: sha512-4A/SCr/2KLd5jrtOMFzaKjVtAei3+2r/NChoBNoZ3EyP/+GlhoaEGoWOZUmFmoITP7zOJyHIMm+DYRd8o3PvHA==}
    engines: {node: '>=6.9.0'}

  '@babel/helper-validator-identifier@7.25.9':
    resolution: {integrity: sha512-Ed61U6XJc3CVRfkERJWDz4dJwKe7iLmmJsbOGu9wSloNSFttHV0I8g6UAgb7qnK5ly5bGLPd4oXZlxCdANBOWQ==}
    engines: {node: '>=6.9.0'}

  '@babel/parser@7.27.0':
    resolution: {integrity: sha512-iaepho73/2Pz7w2eMS0Q5f83+0RKI7i4xmiYeBmDzfRVbQtTOG7Ts0S4HzJVsTMGI9keU8rNfuZr8DKfSt7Yyg==}
    engines: {node: '>=6.0.0'}
    hasBin: true

  '@babel/types@7.27.0':
    resolution: {integrity: sha512-H45s8fVLYjbhFH62dIJ3WtmJ6RSPt/3DRO0ZcT2SUiYiQyz3BLVb9ADEnLl91m74aQPS3AzzeajZHYOalWe3bg==}
    engines: {node: '>=6.9.0'}

  '@docsearch/css@3.8.2':
    resolution: {integrity: sha512-y05ayQFyUmCXze79+56v/4HpycYF3uFqB78pLPrSV5ZKAlDuIAAJNhaRi8tTdRNXh05yxX/TyNnzD6LwSM89vQ==}

  '@docsearch/js@3.8.2':
    resolution: {integrity: sha512-Q5wY66qHn0SwA7Taa0aDbHiJvaFJLOJyHmooQ7y8hlwwQLQ/5WwCcoX0g7ii04Qi2DJlHsd0XXzJ8Ypw9+9YmQ==}

  '@docsearch/react@3.8.2':
    resolution: {integrity: sha512-xCRrJQlTt8N9GU0DG4ptwHRkfnSnD/YpdeaXe02iKfqs97TkZJv60yE+1eq/tjPcVnTW8dP5qLP7itifFVV5eg==}
    peerDependencies:
      '@types/react': '>= 16.8.0 < 19.0.0'
      react: '>= 16.8.0 < 19.0.0'
      react-dom: '>= 16.8.0 < 19.0.0'
      search-insights: '>= 1 < 3'
    peerDependenciesMeta:
      '@types/react':
        optional: true
      react:
        optional: true
      react-dom:
        optional: true
      search-insights:
        optional: true

  '@esbuild/aix-ppc64@0.21.5':
    resolution: {integrity: sha512-1SDgH6ZSPTlggy1yI6+Dbkiz8xzpHJEVAlF/AM1tHPLsf5STom9rwtjE4hKAF20FfXXNTFqEYXyJNWh1GiZedQ==}
    engines: {node: '>=12'}
    cpu: [ppc64]
    os: [aix]

  '@esbuild/android-arm64@0.21.5':
    resolution: {integrity: sha512-c0uX9VAUBQ7dTDCjq+wdyGLowMdtR/GoC2U5IYk/7D1H1JYC0qseD7+11iMP2mRLN9RcCMRcjC4YMclCzGwS/A==}
    engines: {node: '>=12'}
    cpu: [arm64]
    os: [android]

  '@esbuild/android-arm@0.21.5':
    resolution: {integrity: sha512-vCPvzSjpPHEi1siZdlvAlsPxXl7WbOVUBBAowWug4rJHb68Ox8KualB+1ocNvT5fjv6wpkX6o/iEpbDrf68zcg==}
    engines: {node: '>=12'}
    cpu: [arm]
    os: [android]

  '@esbuild/android-x64@0.21.5':
    resolution: {integrity: sha512-D7aPRUUNHRBwHxzxRvp856rjUHRFW1SdQATKXH2hqA0kAZb1hKmi02OpYRacl0TxIGz/ZmXWlbZgjwWYaCakTA==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [android]

  '@esbuild/darwin-arm64@0.21.5':
    resolution: {integrity: sha512-DwqXqZyuk5AiWWf3UfLiRDJ5EDd49zg6O9wclZ7kUMv2WRFr4HKjXp/5t8JZ11QbQfUS6/cRCKGwYhtNAY88kQ==}
    engines: {node: '>=12'}
    cpu: [arm64]
    os: [darwin]

  '@esbuild/darwin-x64@0.21.5':
    resolution: {integrity: sha512-se/JjF8NlmKVG4kNIuyWMV/22ZaerB+qaSi5MdrXtd6R08kvs2qCN4C09miupktDitvh8jRFflwGFBQcxZRjbw==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [darwin]

  '@esbuild/freebsd-arm64@0.21.5':
    resolution: {integrity: sha512-5JcRxxRDUJLX8JXp/wcBCy3pENnCgBR9bN6JsY4OmhfUtIHe3ZW0mawA7+RDAcMLrMIZaf03NlQiX9DGyB8h4g==}
    engines: {node: '>=12'}
    cpu: [arm64]
    os: [freebsd]

  '@esbuild/freebsd-x64@0.21.5':
    resolution: {integrity: sha512-J95kNBj1zkbMXtHVH29bBriQygMXqoVQOQYA+ISs0/2l3T9/kj42ow2mpqerRBxDJnmkUDCaQT/dfNXWX/ZZCQ==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [freebsd]

  '@esbuild/linux-arm64@0.21.5':
    resolution: {integrity: sha512-ibKvmyYzKsBeX8d8I7MH/TMfWDXBF3db4qM6sy+7re0YXya+K1cem3on9XgdT2EQGMu4hQyZhan7TeQ8XkGp4Q==}
    engines: {node: '>=12'}
    cpu: [arm64]
    os: [linux]

  '@esbuild/linux-arm@0.21.5':
    resolution: {integrity: sha512-bPb5AHZtbeNGjCKVZ9UGqGwo8EUu4cLq68E95A53KlxAPRmUyYv2D6F0uUI65XisGOL1hBP5mTronbgo+0bFcA==}
    engines: {node: '>=12'}
    cpu: [arm]
    os: [linux]

  '@esbuild/linux-ia32@0.21.5':
    resolution: {integrity: sha512-YvjXDqLRqPDl2dvRODYmmhz4rPeVKYvppfGYKSNGdyZkA01046pLWyRKKI3ax8fbJoK5QbxblURkwK/MWY18Tg==}
    engines: {node: '>=12'}
    cpu: [ia32]
    os: [linux]

  '@esbuild/linux-loong64@0.21.5':
    resolution: {integrity: sha512-uHf1BmMG8qEvzdrzAqg2SIG/02+4/DHB6a9Kbya0XDvwDEKCoC8ZRWI5JJvNdUjtciBGFQ5PuBlpEOXQj+JQSg==}
    engines: {node: '>=12'}
    cpu: [loong64]
    os: [linux]

  '@esbuild/linux-mips64el@0.21.5':
    resolution: {integrity: sha512-IajOmO+KJK23bj52dFSNCMsz1QP1DqM6cwLUv3W1QwyxkyIWecfafnI555fvSGqEKwjMXVLokcV5ygHW5b3Jbg==}
    engines: {node: '>=12'}
    cpu: [mips64el]
    os: [linux]

  '@esbuild/linux-ppc64@0.21.5':
    resolution: {integrity: sha512-1hHV/Z4OEfMwpLO8rp7CvlhBDnjsC3CttJXIhBi+5Aj5r+MBvy4egg7wCbe//hSsT+RvDAG7s81tAvpL2XAE4w==}
    engines: {node: '>=12'}
    cpu: [ppc64]
    os: [linux]

  '@esbuild/linux-riscv64@0.21.5':
    resolution: {integrity: sha512-2HdXDMd9GMgTGrPWnJzP2ALSokE/0O5HhTUvWIbD3YdjME8JwvSCnNGBnTThKGEB91OZhzrJ4qIIxk/SBmyDDA==}
    engines: {node: '>=12'}
    cpu: [riscv64]
    os: [linux]

  '@esbuild/linux-s390x@0.21.5':
    resolution: {integrity: sha512-zus5sxzqBJD3eXxwvjN1yQkRepANgxE9lgOW2qLnmr8ikMTphkjgXu1HR01K4FJg8h1kEEDAqDcZQtbrRnB41A==}
    engines: {node: '>=12'}
    cpu: [s390x]
    os: [linux]

  '@esbuild/linux-x64@0.21.5':
    resolution: {integrity: sha512-1rYdTpyv03iycF1+BhzrzQJCdOuAOtaqHTWJZCWvijKD2N5Xu0TtVC8/+1faWqcP9iBCWOmjmhoH94dH82BxPQ==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [linux]

  '@esbuild/netbsd-x64@0.21.5':
    resolution: {integrity: sha512-Woi2MXzXjMULccIwMnLciyZH4nCIMpWQAs049KEeMvOcNADVxo0UBIQPfSmxB3CWKedngg7sWZdLvLczpe0tLg==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [netbsd]

  '@esbuild/openbsd-x64@0.21.5':
    resolution: {integrity: sha512-HLNNw99xsvx12lFBUwoT8EVCsSvRNDVxNpjZ7bPn947b8gJPzeHWyNVhFsaerc0n3TsbOINvRP2byTZ5LKezow==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [openbsd]

  '@esbuild/sunos-x64@0.21.5':
    resolution: {integrity: sha512-6+gjmFpfy0BHU5Tpptkuh8+uw3mnrvgs+dSPQXQOv3ekbordwnzTVEb4qnIvQcYXq6gzkyTnoZ9dZG+D4garKg==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [sunos]

  '@esbuild/win32-arm64@0.21.5':
    resolution: {integrity: sha512-Z0gOTd75VvXqyq7nsl93zwahcTROgqvuAcYDUr+vOv8uHhNSKROyU961kgtCD1e95IqPKSQKH7tBTslnS3tA8A==}
    engines: {node: '>=12'}
    cpu: [arm64]
    os: [win32]

  '@esbuild/win32-ia32@0.21.5':
    resolution: {integrity: sha512-SWXFF1CL2RVNMaVs+BBClwtfZSvDgtL//G/smwAc5oVK/UPu2Gu9tIaRgFmYFFKrmg3SyAjSrElf0TiJ1v8fYA==}
    engines: {node: '>=12'}
    cpu: [ia32]
    os: [win32]

  '@esbuild/win32-x64@0.21.5':
    resolution: {integrity: sha512-tQd/1efJuzPC6rCFwEvLtci/xNFcTZknmXs98FYDfGE4wP9ClFV98nyKrzJKVPMhdDnjzLhdUyMX4PsQAPjwIw==}
    engines: {node: '>=12'}
    cpu: [x64]
    os: [win32]

  '@iconify-json/simple-icons@1.2.30':
    resolution: {integrity: sha512-KiVViMvnohpS5Q9WMP+4ksOhF3Dnq73Ba9hxBhUIIhp1r6RJ6edMZ8QGKZcFZp/B0/PZC4jAIhXcKKq73WZckQ==}

  '@iconify/types@2.0.0':
    resolution: {integrity: sha512-+wluvCrRhXrhyOmRDJ3q8mux9JkKy5SJ/v8ol2tu4FVjyYvtEzkc/3pK15ET6RKg4b4w4BmTk1+gsCUhf21Ykg==}

  '@jridgewell/sourcemap-codec@1.5.0':
    resolution: {integrity: sha512-gv3ZRaISU3fjPAgNsriBRqGWQL6quFx04YMPW/zD8XMLsU32mhCCbfbO6KZFLjvYpCZ8zyDEgqsgf+PwPaM7GQ==}

  '@rollup/rollup-android-arm-eabi@4.39.0':
    resolution: {integrity: sha512-lGVys55Qb00Wvh8DMAocp5kIcaNzEFTmGhfFd88LfaogYTRKrdxgtlO5H6S49v2Nd8R2C6wLOal0qv6/kCkOwA==}
    cpu: [arm]
    os: [android]

  '@rollup/rollup-android-arm64@4.39.0':
    resolution: {integrity: sha512-It9+M1zE31KWfqh/0cJLrrsCPiF72PoJjIChLX+rEcujVRCb4NLQ5QzFkzIZW8Kn8FTbvGQBY5TkKBau3S8cCQ==}
    cpu: [arm64]
    os: [android]

  '@rollup/rollup-darwin-arm64@4.39.0':
    resolution: {integrity: sha512-lXQnhpFDOKDXiGxsU9/l8UEGGM65comrQuZ+lDcGUx+9YQ9dKpF3rSEGepyeR5AHZ0b5RgiligsBhWZfSSQh8Q==}
    cpu: [arm64]
    os: [darwin]

  '@rollup/rollup-darwin-x64@4.39.0':
    resolution: {integrity: sha512-mKXpNZLvtEbgu6WCkNij7CGycdw9cJi2k9v0noMb++Vab12GZjFgUXD69ilAbBh034Zwn95c2PNSz9xM7KYEAQ==}
    cpu: [x64]
    os: [darwin]

  '@rollup/rollup-freebsd-arm64@4.39.0':
    resolution: {integrity: sha512-jivRRlh2Lod/KvDZx2zUR+I4iBfHcu2V/BA2vasUtdtTN2Uk3jfcZczLa81ESHZHPHy4ih3T/W5rPFZ/hX7RtQ==}
    cpu: [arm64]
    os: [freebsd]

  '@rollup/rollup-freebsd-x64@4.39.0':
    resolution: {integrity: sha512-8RXIWvYIRK9nO+bhVz8DwLBepcptw633gv/QT4015CpJ0Ht8punmoHU/DuEd3iw9Hr8UwUV+t+VNNuZIWYeY7Q==}
    cpu: [x64]
    os: [freebsd]

  '@rollup/rollup-linux-arm-gnueabihf@4.39.0':
    resolution: {integrity: sha512-mz5POx5Zu58f2xAG5RaRRhp3IZDK7zXGk5sdEDj4o96HeaXhlUwmLFzNlc4hCQi5sGdR12VDgEUqVSHer0lI9g==}
    cpu: [arm]
    os: [linux]

  '@rollup/rollup-linux-arm-musleabihf@4.39.0':
    resolution: {integrity: sha512-+YDwhM6gUAyakl0CD+bMFpdmwIoRDzZYaTWV3SDRBGkMU/VpIBYXXEvkEcTagw/7VVkL2vA29zU4UVy1mP0/Yw==}
    cpu: [arm]
    os: [linux]

  '@rollup/rollup-linux-arm64-gnu@4.39.0':
    resolution: {integrity: sha512-EKf7iF7aK36eEChvlgxGnk7pdJfzfQbNvGV/+l98iiMwU23MwvmV0Ty3pJ0p5WQfm3JRHOytSIqD9LB7Bq7xdQ==}
    cpu: [arm64]
    os: [linux]

  '@rollup/rollup-linux-arm64-musl@4.39.0':
    resolution: {integrity: sha512-vYanR6MtqC7Z2SNr8gzVnzUul09Wi1kZqJaek3KcIlI/wq5Xtq4ZPIZ0Mr/st/sv/NnaPwy/D4yXg5x0B3aUUA==}
    cpu: [arm64]
    os: [linux]

  '@rollup/rollup-linux-loongarch64-gnu@4.39.0':
    resolution: {integrity: sha512-NMRUT40+h0FBa5fb+cpxtZoGAggRem16ocVKIv5gDB5uLDgBIwrIsXlGqYbLwW8YyO3WVTk1FkFDjMETYlDqiw==}
    cpu: [loong64]
    os: [linux]

  '@rollup/rollup-linux-powerpc64le-gnu@4.39.0':
    resolution: {integrity: sha512-0pCNnmxgduJ3YRt+D+kJ6Ai/r+TaePu9ZLENl+ZDV/CdVczXl95CbIiwwswu4L+K7uOIGf6tMo2vm8uadRaICQ==}
    cpu: [ppc64]
    os: [linux]

  '@rollup/rollup-linux-riscv64-gnu@4.39.0':
    resolution: {integrity: sha512-t7j5Zhr7S4bBtksT73bO6c3Qa2AV/HqiGlj9+KB3gNF5upcVkx+HLgxTm8DK4OkzsOYqbdqbLKwvGMhylJCPhQ==}
    cpu: [riscv64]
    os: [linux]

  '@rollup/rollup-linux-riscv64-musl@4.39.0':
    resolution: {integrity: sha512-m6cwI86IvQ7M93MQ2RF5SP8tUjD39Y7rjb1qjHgYh28uAPVU8+k/xYWvxRO3/tBN2pZkSMa5RjnPuUIbrwVxeA==}
    cpu: [riscv64]
    os: [linux]

  '@rollup/rollup-linux-s390x-gnu@4.39.0':
    resolution: {integrity: sha512-iRDJd2ebMunnk2rsSBYlsptCyuINvxUfGwOUldjv5M4tpa93K8tFMeYGpNk2+Nxl+OBJnBzy2/JCscGeO507kA==}
    cpu: [s390x]
    os: [linux]

  '@rollup/rollup-linux-x64-gnu@4.39.0':
    resolution: {integrity: sha512-t9jqYw27R6Lx0XKfEFe5vUeEJ5pF3SGIM6gTfONSMb7DuG6z6wfj2yjcoZxHg129veTqU7+wOhY6GX8wmf90dA==}
    cpu: [x64]
    os: [linux]

  '@rollup/rollup-linux-x64-musl@4.39.0':
    resolution: {integrity: sha512-ThFdkrFDP55AIsIZDKSBWEt/JcWlCzydbZHinZ0F/r1h83qbGeenCt/G/wG2O0reuENDD2tawfAj2s8VK7Bugg==}
    cpu: [x64]
    os: [linux]

  '@rollup/rollup-win32-arm64-msvc@4.39.0':
    resolution: {integrity: sha512-jDrLm6yUtbOg2TYB3sBF3acUnAwsIksEYjLeHL+TJv9jg+TmTwdyjnDex27jqEMakNKf3RwwPahDIt7QXCSqRQ==}
    cpu: [arm64]
    os: [win32]

  '@rollup/rollup-win32-ia32-msvc@4.39.0':
    resolution: {integrity: sha512-6w9uMuza+LbLCVoNKL5FSLE7yvYkq9laSd09bwS0tMjkwXrmib/4KmoJcrKhLWHvw19mwU+33ndC69T7weNNjQ==}
    cpu: [ia32]
    os: [win32]

  '@rollup/rollup-win32-x64-msvc@4.39.0':
    resolution: {integrity: sha512-yAkUOkIKZlK5dl7u6dg897doBgLXmUHhIINM2c+sND3DZwnrdQkkSiDh7N75Ll4mM4dxSkYfXqU9fW3lLkMFug==}
    cpu: [x64]
    os: [win32]

  '@shikijs/core@2.5.0':
    resolution: {integrity: sha512-uu/8RExTKtavlpH7XqnVYBrfBkUc20ngXiX9NSrBhOVZYv/7XQRKUyhtkeflY5QsxC0GbJThCerruZfsUaSldg==}

  '@shikijs/engine-javascript@2.5.0':
    resolution: {integrity: sha512-VjnOpnQf8WuCEZtNUdjjwGUbtAVKuZkVQ/5cHy/tojVVRIRtlWMYVjyWhxOmIq05AlSOv72z7hRNRGVBgQOl0w==}

  '@shikijs/engine-oniguruma@2.5.0':
    resolution: {integrity: sha512-pGd1wRATzbo/uatrCIILlAdFVKdxImWJGQ5rFiB5VZi2ve5xj3Ax9jny8QvkaV93btQEwR/rSz5ERFpC5mKNIw==}

  '@shikijs/langs@2.5.0':
    resolution: {integrity: sha512-Qfrrt5OsNH5R+5tJ/3uYBBZv3SuGmnRPejV9IlIbFH3HTGLDlkqgHymAlzklVmKBjAaVmkPkyikAV/sQ1wSL+w==}

  '@shikijs/themes@2.5.0':
    resolution: {integrity: sha512-wGrk+R8tJnO0VMzmUExHR+QdSaPUl/NKs+a4cQQRWyoc3YFbUzuLEi/KWK1hj+8BfHRKm2jNhhJck1dfstJpiw==}

  '@shikijs/transformers@2.5.0':
    resolution: {integrity: sha512-SI494W5X60CaUwgi8u4q4m4s3YAFSxln3tzNjOSYqq54wlVgz0/NbbXEb3mdLbqMBztcmS7bVTaEd2w0qMmfeg==}

  '@shikijs/types@2.5.0':
    resolution: {integrity: sha512-ygl5yhxki9ZLNuNpPitBWvcy9fsSKKaRuO4BAlMyagszQidxcpLAr0qiW/q43DtSIDxO6hEbtYLiFZNXO/hdGw==}

  '@shikijs/vscode-textmate@10.0.2':
    resolution: {integrity: sha512-83yeghZ2xxin3Nj8z1NMd/NCuca+gsYXswywDy5bHvwlWL8tpTQmzGeUuHd9FC3E/SBEMvzJRwWEOz5gGes9Qg==}

  '@types/estree@1.0.7':
    resolution: {integrity: sha512-w28IoSUCJpidD/TGviZwwMJckNESJZXFu7NBZ5YJ4mEUnNraUn9Pm8HSZm/jDF1pDWYKspWE7oVphigUPRakIQ==}

  '@types/hast@3.0.4':
    resolution: {integrity: sha512-WPs+bbQw5aCj+x6laNGWLH3wviHtoCv/P3+otBhbOhJgG8qtpdAMlTCxLtsTWA7LH1Oh/bFCHsBn0TPS5m30EQ==}

  '@types/linkify-it@5.0.0':
    resolution: {integrity: sha512-sVDA58zAw4eWAffKOaQH5/5j3XeayukzDk+ewSsnv3p4yJEZHCCzMDiZM8e0OUrRvmpGZ85jf4yDHkHsgBNr9Q==}

  '@types/markdown-it@14.1.2':
    resolution: {integrity: sha512-promo4eFwuiW+TfGxhi+0x3czqTYJkG8qB17ZUJiVF10Xm7NLVRSLUsfRTU/6h1e24VvRnXCx+hG7li58lkzog==}

  '@types/mdast@4.0.4':
    resolution: {integrity: sha512-kGaNbPh1k7AFzgpud/gMdvIm5xuECykRR+JnWKQno9TAXVa6WIVCGTPvYGekIDL4uwCZQSYbUxNBSb1aUo79oA==}

  '@types/mdurl@2.0.0':
    resolution: {integrity: sha512-RGdgjQUZba5p6QEFAVx2OGb8rQDL/cPRG7GiedRzMcJ1tYnUANBncjbSB1NRGwbvjcPeikRABz2nshyPk1bhWg==}

  '@types/unist@3.0.3':
    resolution: {integrity: sha512-ko/gIFJRv177XgZsZcBwnqJN5x/Gien8qNOn0D5bQU/zAzVf9Zt3BlcUiLqhV9y4ARk0GbT3tnUiPNgnTXzc/Q==}

  '@types/web-bluetooth@0.0.21':
    resolution: {integrity: sha512-oIQLCGWtcFZy2JW77j9k8nHzAOpqMHLQejDA48XXMWH6tjCQHz5RCFz1bzsmROyL6PUm+LLnUiI4BCn221inxA==}

  '@ungap/structured-clone@1.3.0':
    resolution: {integrity: sha512-WmoN8qaIAo7WTYWbAZuG8PYEhn5fkz7dZrqTBZ7dtt//lL2Gwms1IcnQ5yHqjDfX8Ft5j4YzDM23f87zBfDe9g==}

  '@vitejs/plugin-vue@5.2.3':
    resolution: {integrity: sha512-IYSLEQj4LgZZuoVpdSUCw3dIynTWQgPlaRP6iAvMle4My0HdYwr5g5wQAfwOeHQBmYwEkqF70nRpSilr6PoUDg==}
    engines: {node: ^18.0.0 || >=20.0.0}
    peerDependencies:
      vite: ^5.0.0 || ^6.0.0
      vue: ^3.2.25

  '@vue/compiler-core@3.5.13':
    resolution: {integrity: sha512-oOdAkwqUfW1WqpwSYJce06wvt6HljgY3fGeM9NcVA1HaYOij3mZG9Rkysn0OHuyUAGMbEbARIpsG+LPVlBJ5/Q==}

  '@vue/compiler-dom@3.5.13':
    resolution: {integrity: sha512-ZOJ46sMOKUjO3e94wPdCzQ6P1Lx/vhp2RSvfaab88Ajexs0AHeV0uasYhi99WPaogmBlRHNRuly8xV75cNTMDA==}

  '@vue/compiler-sfc@3.5.13':
    resolution: {integrity: sha512-6VdaljMpD82w6c2749Zhf5T9u5uLBWKnVue6XWxprDobftnletJ8+oel7sexFfM3qIxNmVE7LSFGTpv6obNyaQ==}

  '@vue/compiler-ssr@3.5.13':
    resolution: {integrity: sha512-wMH6vrYHxQl/IybKJagqbquvxpWCuVYpoUJfCqFZwa/JY1GdATAQ+TgVtgrwwMZ0D07QhA99rs/EAAWfvG6KpA==}

  '@vue/devtools-api@7.7.2':
    resolution: {integrity: sha512-1syn558KhyN+chO5SjlZIwJ8bV/bQ1nOVTG66t2RbG66ZGekyiYNmRO7X9BJCXQqPsFHlnksqvPhce2qpzxFnA==}

  '@vue/devtools-kit@7.7.2':
    resolution: {integrity: sha512-CY0I1JH3Z8PECbn6k3TqM1Bk9ASWxeMtTCvZr7vb+CHi+X/QwQm5F1/fPagraamKMAHVfuuCbdcnNg1A4CYVWQ==}

  '@vue/devtools-shared@7.7.2':
    resolution: {integrity: sha512-uBFxnp8gwW2vD6FrJB8JZLUzVb6PNRG0B0jBnHsOH8uKyva2qINY8PTF5Te4QlTbMDqU5K6qtJDr6cNsKWhbOA==}

  '@vue/reactivity@3.5.13':
    resolution: {integrity: sha512-NaCwtw8o48B9I6L1zl2p41OHo/2Z4wqYGGIK1Khu5T7yxrn+ATOixn/Udn2m+6kZKB/J7cuT9DbWWhRxqixACg==}

  '@vue/runtime-core@3.5.13':
    resolution: {integrity: sha512-Fj4YRQ3Az0WTZw1sFe+QDb0aXCerigEpw418pw1HBUKFtnQHWzwojaukAs2X/c9DQz4MQ4bsXTGlcpGxU/RCIw==}

  '@vue/runtime-dom@3.5.13':
    resolution: {integrity: sha512-dLaj94s93NYLqjLiyFzVs9X6dWhTdAlEAciC3Moq7gzAc13VJUdCnjjRurNM6uTLFATRHexHCTu/Xp3eW6yoog==}

  '@vue/server-renderer@3.5.13':
    resolution: {integrity: sha512-wAi4IRJV/2SAW3htkTlB+dHeRmpTiVIK1OGLWV1yeStVSebSQQOwGwIq0D3ZIoBj2C2qpgz5+vX9iEBkTdk5YA==}
    peerDependencies:
      vue: 3.5.13

  '@vue/shared@3.5.13':
    resolution: {integrity: sha512-/hnE/qP5ZoGpol0a5mDi45bOd7t3tjYJBjsgCsivow7D48cJeV5l05RD82lPqi7gRiphZM37rnhW1l6ZoCNNnQ==}

  '@vueuse/core@12.8.2':
    resolution: {integrity: sha512-HbvCmZdzAu3VGi/pWYm5Ut+Kd9mn1ZHnn4L5G8kOQTPs/IwIAmJoBrmYk2ckLArgMXZj0AW3n5CAejLUO+PhdQ==}

  '@vueuse/integrations@12.8.2':
    resolution: {integrity: sha512-fbGYivgK5uBTRt7p5F3zy6VrETlV9RtZjBqd1/HxGdjdckBgBM4ugP8LHpjolqTj14TXTxSK1ZfgPbHYyGuH7g==}
    peerDependencies:
      async-validator: ^4
      axios: ^1
      change-case: ^5
      drauu: ^0.4
      focus-trap: ^7
      fuse.js: ^7
      idb-keyval: ^6
      jwt-decode: ^4
      nprogress: ^0.2
      qrcode: ^1.5
      sortablejs: ^1
      universal-cookie: ^7
    peerDependenciesMeta:
      async-validator:
        optional: true
      axios:
        optional: true
      change-case:
        optional: true
      drauu:
        optional: true
      focus-trap:
        optional: true
      fuse.js:
        optional: true
      idb-keyval:
        optional: true
      jwt-decode:
        optional: true
      nprogress:
        optional: true
      qrcode:
        optional: true
      sortablejs:
        optional: true
      universal-cookie:
        optional: true

  '@vueuse/metadata@12.8.2':
    resolution: {integrity: sha512-rAyLGEuoBJ/Il5AmFHiziCPdQzRt88VxR+Y/A/QhJ1EWtWqPBBAxTAFaSkviwEuOEZNtW8pvkPgoCZQ+HxqW1A==}

  '@vueuse/shared@12.8.2':
    resolution: {integrity: sha512-dznP38YzxZoNloI0qpEfpkms8knDtaoQ6Y/sfS0L7Yki4zh40LFHEhur0odJC6xTHG5dxWVPiUWBXn+wCG2s5w==}

  algoliasearch@5.23.2:
    resolution: {integrity: sha512-IhKP22Czzg8Y9HaF6aIb5aAHK2HBj4VAzLLnKEPUnxqDwxpryH9sXbm0NkeY7Cby9GlF81wF+AG/VulKDFBphg==}
    engines: {node: '>= 14.0.0'}

  birpc@0.2.19:
    resolution: {integrity: sha512-5WeXXAvTmitV1RqJFppT5QtUiz2p1mRSYU000Jkft5ZUCLJIk4uQriYNO50HknxKwM6jd8utNc66K1qGIwwWBQ==}

  ccount@2.0.1:
    resolution: {integrity: sha512-eyrF0jiFpY+3drT6383f1qhkbGsLSifNAjA61IUjZjmLCWjItY6LB9ft9YhoDgwfmclB2zhu51Lc7+95b8NRAg==}

  character-entities-html4@2.1.0:
    resolution: {integrity: sha512-1v7fgQRj6hnSwFpq1Eu0ynr/CDEw0rXo2B61qXrLNdHZmPKgb7fqS1a2JwF0rISo9q77jDI8VMEHoApn8qDoZA==}

  character-entities-legacy@3.0.0:
    resolution: {integrity: sha512-RpPp0asT/6ufRm//AJVwpViZbGM/MkjQFxJccQRHmISF/22NBtsHqAWmL+/pmkPWoIUJdWyeVleTl1wydHATVQ==}

  comma-separated-tokens@2.0.3:
    resolution: {integrity: sha512-Fu4hJdvzeylCfQPp9SGWidpzrMs7tTrlu6Vb8XGaRGck8QSNZJJp538Wrb60Lax4fPwR64ViY468OIUTbRlGZg==}

  copy-anything@3.0.5:
    resolution: {integrity: sha512-yCEafptTtb4bk7GLEQoM8KVJpxAfdBJYaXyzQEgQQQgYrZiDp8SJmGKlYza6CYjEDNstAdNdKA3UuoULlEbS6w==}
    engines: {node: '>=12.13'}

  csstype@3.1.3:
    resolution: {integrity: sha512-M1uQkMl8rQK/szD0LNhtqxIPLpimGm8sOBwU7lLnCpSbTyY3yeU1Vc7l4KT5zT4s/yOxHH5O7tIuuLOCnLADRw==}

  dequal@2.0.3:
    resolution: {integrity: sha512-0je+qPKHEMohvfRTCEo3CrPG6cAzAYgmzKyxRiYSSDkS6eGJdyVJm7WaYA5ECaAD9wLB2T4EEeymA5aFVcYXCA==}
    engines: {node: '>=6'}

  devlop@1.1.0:
    resolution: {integrity: sha512-RWmIqhcFf1lRYBvNmr7qTNuyCt/7/ns2jbpp1+PalgE/rDQcBT0fioSMUpJ93irlUhC5hrg4cYqe6U+0ImW0rA==}

  emoji-regex-xs@1.0.0:
    resolution: {integrity: sha512-LRlerrMYoIDrT6jgpeZ2YYl/L8EulRTt5hQcYjy5AInh7HWXKimpqx68aknBFpGL2+/IcogTcaydJEgaTmOpDg==}

  entities@4.5.0:
    resolution: {integrity: sha512-V0hjH4dGPh9Ao5p0MoRY6BVqtwCjhz6vI5LT8AJ55H+4g9/4vbHx1I54fS0XuclLhDHArPQCiMjDxjaL8fPxhw==}
    engines: {node: '>=0.12'}

  esbuild@0.21.5:
    resolution: {integrity: sha512-mg3OPMV4hXywwpoDxu3Qda5xCKQi+vCTZq8S9J/EpkhB2HzKXq4SNFZE3+NK93JYxc8VMSep+lOUSC/RVKaBqw==}
    engines: {node: '>=12'}
    hasBin: true

  estree-walker@2.0.2:
    resolution: {integrity: sha512-Rfkk/Mp/DL7JVje3u18FxFujQlTNR2q6QfMSMB7AvCBx91NGj/ba3kCfza0f6dVDbw7YlRf/nDrn7pQrCCyQ/w==}

  focus-trap@7.6.4:
    resolution: {integrity: sha512-xx560wGBk7seZ6y933idtjJQc1l+ck+pI3sKvhKozdBV1dRZoKhkW5xoCaFv9tQiX5RH1xfSxjuNu6g+lmN/gw==}

  fsevents@2.3.3:
    resolution: {integrity: sha512-5xoDfX+fL7faATnagmWPpbFtwh/R77WmMMqqHGS65C3vvB0YHrgF+B1YmZ3441tMj5n63k0212XNoJwzlhffQw==}
    engines: {node: ^8.16.0 || ^10.6.0 || >=11.0.0}
    os: [darwin]

  hast-util-to-html@9.0.5:
    resolution: {integrity: sha512-OguPdidb+fbHQSU4Q4ZiLKnzWo8Wwsf5bZfbvu7//a9oTYoqD/fWpe96NuHkoS9h0ccGOTe0C4NGXdtS0iObOw==}

  hast-util-whitespace@3.0.0:
    resolution: {integrity: sha512-88JUN06ipLwsnv+dVn+OIYOvAuvBMy/Qoi6O7mQHxdPXpjy+Cd6xRkWwux7DKO+4sYILtLBRIKgsdpS2gQc7qw==}

  hookable@5.5.3:
    resolution: {integrity: sha512-Yc+BQe8SvoXH1643Qez1zqLRmbA5rCL+sSmk6TVos0LWVfNIB7PGncdlId77WzLGSIB5KaWgTaNTs2lNVEI6VQ==}

  html-void-elements@3.0.0:
    resolution: {integrity: sha512-bEqo66MRXsUGxWHV5IP0PUiAWwoEjba4VCzg0LjFJBpchPaTfyfCKTG6bc5F8ucKec3q5y6qOdGyYTSBEvhCrg==}

  is-what@4.1.16:
    resolution: {integrity: sha512-ZhMwEosbFJkA0YhFnNDgTM4ZxDRsS6HqTo7qsZM08fehyRYIYa0yHu5R6mgo1n/8MgaPBXiPimPD77baVFYg+A==}
    engines: {node: '>=12.13'}

  magic-string@0.30.17:
    resolution: {integrity: sha512-sNPKHvyjVf7gyjwS4xGTaW/mCnF8wnjtifKBEhxfZ7E/S8tQ0rssrwGNn6q8JH/ohItJfSQp9mBtQYuTlH5QnA==}

  mark.js@8.11.1:
    resolution: {integrity: sha512-1I+1qpDt4idfgLQG+BNWmrqku+7/2bi5nLf4YwF8y8zXvmfiTBY3PV3ZibfrjBueCByROpuBjLLFCajqkgYoLQ==}

  mdast-util-to-hast@13.2.0:
    resolution: {integrity: sha512-QGYKEuUsYT9ykKBCMOEDLsU5JRObWQusAolFMeko/tYPufNkRffBAQjIE+99jbA87xv6FgmjLtwjh9wBWajwAA==}

  micromark-util-character@2.1.1:
    resolution: {integrity: sha512-wv8tdUTJ3thSFFFJKtpYKOYiGP2+v96Hvk4Tu8KpCAsTMs6yi+nVmGh1syvSCsaxz45J6Jbw+9DD6g97+NV67Q==}

  micromark-util-encode@2.0.1:
    resolution: {integrity: sha512-c3cVx2y4KqUnwopcO9b/SCdo2O67LwJJ/UyqGfbigahfegL9myoEFoDYZgkT7f36T0bLrM9hZTAaAyH+PCAXjw==}

  micromark-util-sanitize-uri@2.0.1:
    resolution: {integrity: sha512-9N9IomZ/YuGGZZmQec1MbgxtlgougxTodVwDzzEouPKo3qFWvymFHWcnDi2vzV1ff6kas9ucW+o3yzJK9YB1AQ==}

  micromark-util-symbol@2.0.1:
    resolution: {integrity: sha512-vs5t8Apaud9N28kgCrRUdEed4UJ+wWNvicHLPxCa9ENlYuAY31M0ETy5y1vA33YoNPDFTghEbnh6efaE8h4x0Q==}

  micromark-util-types@2.0.2:
    resolution: {integrity: sha512-Yw0ECSpJoViF1qTU4DC6NwtC4aWGt1EkzaQB8KPPyCRR8z9TWeV0HbEFGTO+ZY1wB22zmxnJqhPyTpOVCpeHTA==}

  minisearch@7.1.2:
    resolution: {integrity: sha512-R1Pd9eF+MD5JYDDSPAp/q1ougKglm14uEkPMvQ/05RGmx6G9wvmLTrTI/Q5iPNJLYqNdsDQ7qTGIcNWR+FrHmA==}

  mitt@3.0.1:
    resolution: {integrity: sha512-vKivATfr97l2/QBCYAkXYDbrIWPM2IIKEl7YPhjCvKlG3kE2gm+uBo6nEXK3M5/Ffh/FLpKExzOQ3JJoJGFKBw==}

  nanoid@3.3.11:
    resolution: {integrity: sha512-N8SpfPUnUp1bK+PMYW8qSWdl9U+wwNWI4QKxOYDy9JAro3WMX7p2OeVRF9v+347pnakNevPmiHhNmZ2HbFA76w==}
    engines: {node: ^10 || ^12 || ^13.7 || ^14 || >=15.0.1}
    hasBin: true

  oniguruma-to-es@3.1.1:
    resolution: {integrity: sha512-bUH8SDvPkH3ho3dvwJwfonjlQ4R80vjyvrU8YpxuROddv55vAEJrTuCuCVUhhsHbtlD9tGGbaNApGQckXhS8iQ==}

  perfect-debounce@1.0.0:
    resolution: {integrity: sha512-xCy9V055GLEqoFaHoC1SoLIaLmWctgCUaBaWxDZ7/Zx4CTyX7cJQLJOok/orfjZAh9kEYpjJa4d0KcJmCbctZA==}

  picocolors@1.1.1:
    resolution: {integrity: sha512-xceH2snhtb5M9liqDsmEw56le376mTZkEX/jEb/RxNFyegNul7eNslCXP9FDj/Lcu0X8KEyMceP2ntpaHrDEVA==}

  postcss@8.5.3:
    resolution: {integrity: sha512-dle9A3yYxlBSrt8Fu+IpjGT8SY8hN0mlaA6GY8t0P5PjIOZemULz/E2Bnm/2dcUOena75OTNkHI76uZBNUUq3A==}
    engines: {node: ^10 || ^12 || >=14}

  preact@10.26.4:
    resolution: {integrity: sha512-KJhO7LBFTjP71d83trW+Ilnjbo+ySsaAgCfXOXUlmGzJ4ygYPWmysm77yg4emwfmoz3b22yvH5IsVFHbhUaH5w==}

  property-information@7.0.0:
    resolution: {integrity: sha512-7D/qOz/+Y4X/rzSB6jKxKUsQnphO046ei8qxG59mtM3RG3DHgTK81HrxrmoDVINJb8NKT5ZsRbwHvQ6B68Iyhg==}

  regex-recursion@6.0.2:
    resolution: {integrity: sha512-0YCaSCq2VRIebiaUviZNs0cBz1kg5kVS2UKUfNIx8YVs1cN3AV7NTctO5FOKBA+UT2BPJIWZauYHPqJODG50cg==}

  regex-utilities@2.3.0:
    resolution: {integrity: sha512-8VhliFJAWRaUiVvREIiW2NXXTmHs4vMNnSzuJVhscgmGav3g9VDxLrQndI3dZZVVdp0ZO/5v0xmX516/7M9cng==}

  regex@6.0.1:
    resolution: {integrity: sha512-uorlqlzAKjKQZ5P+kTJr3eeJGSVroLKoHmquUj4zHWuR+hEyNqlXsSKlYYF5F4NI6nl7tWCs0apKJ0lmfsXAPA==}

  rfdc@1.4.1:
    resolution: {integrity: sha512-q1b3N5QkRUWUl7iyylaaj3kOpIT0N2i9MqIEQXP73GVsN9cw3fdx8X63cEmWhJGi2PPCF23Ijp7ktmd39rawIA==}

  rollup@4.39.0:
    resolution: {integrity: sha512-thI8kNc02yNvnmJp8dr3fNWJ9tCONDhp6TV35X6HkKGGs9E6q7YWCHbe5vKiTa7TAiNcFEmXKj3X/pG2b3ci0g==}
    engines: {node: '>=18.0.0', npm: '>=8.0.0'}
    hasBin: true

  search-insights@2.17.3:
    resolution: {integrity: sha512-RQPdCYTa8A68uM2jwxoY842xDhvx3E5LFL1LxvxCNMev4o5mLuokczhzjAgGwUZBAmOKZknArSxLKmXtIi2AxQ==}

  shiki@2.5.0:
    resolution: {integrity: sha512-mI//trrsaiCIPsja5CNfsyNOqgAZUb6VpJA+340toL42UpzQlXpwRV9nch69X6gaUxrr9kaOOa6e3y3uAkGFxQ==}

  source-map-js@1.2.1:
    resolution: {integrity: sha512-UXWMKhLOwVKb728IUtQPXxfYU+usdybtUrK/8uGE8CQMvrhOpwvzDBwj0QhSL7MQc7vIsISBG8VQ8+IDQxpfQA==}
    engines: {node: '>=0.10.0'}

  space-separated-tokens@2.0.2:
    resolution: {integrity: sha512-PEGlAwrG8yXGXRjW32fGbg66JAlOAwbObuqVoJpv/mRgoWDQfgH1wDPvtzWyUSNAXBGSk8h755YDbbcEy3SH2Q==}

  speakingurl@14.0.1:
    resolution: {integrity: sha512-1POYv7uv2gXoyGFpBCmpDVSNV74IfsWlDW216UPjbWufNf+bSU6GdbDsxdcxtfwb4xlI3yxzOTKClUosxARYrQ==}
    engines: {node: '>=0.10.0'}

  stringify-entities@4.0.4:
    resolution: {integrity: sha512-IwfBptatlO+QCJUo19AqvrPNqlVMpW9YEL2LIVY+Rpv2qsjCGxaDLNRgeGsQWJhfItebuJhsGSLjaBbNSQ+ieg==}

  superjson@2.2.2:
    resolution: {integrity: sha512-5JRxVqC8I8NuOUjzBbvVJAKNM8qoVuH0O77h4WInc/qC2q5IreqKxYwgkga3PfA22OayK2ikceb/B26dztPl+Q==}
    engines: {node: '>=16'}

  tabbable@6.2.0:
    resolution: {integrity: sha512-Cat63mxsVJlzYvN51JmVXIgNoUokrIaT2zLclCXjRd8boZ0004U4KCs/sToJ75C6sdlByWxpYnb5Boif1VSFew==}

  trim-lines@3.0.1:
    resolution: {integrity: sha512-kRj8B+YHZCc9kQYdWfJB2/oUl9rA99qbowYYBtr4ui4mZyAQ2JpvVBd/6U2YloATfqBhBTSMhTpgBHtU0Mf3Rg==}

  unist-util-is@6.0.0:
    resolution: {integrity: sha512-2qCTHimwdxLfz+YzdGfkqNlH0tLi9xjTnHddPmJwtIG9MGsdbutfTc4P+haPD7l7Cjxf/WZj+we5qfVPvvxfYw==}

  unist-util-position@5.0.0:
    resolution: {integrity: sha512-fucsC7HjXvkB5R3kTCO7kUjRdrS0BJt3M/FPxmHMBOm8JQi2BsHAHFsy27E0EolP8rp0NzXsJ+jNPyDWvOJZPA==}

  unist-util-stringify-position@4.0.0:
    resolution: {integrity: sha512-0ASV06AAoKCDkS2+xw5RXJywruurpbC4JZSm7nr7MOt1ojAzvyyaO+UxZf18j8FCF6kmzCZKcAgN/yu2gm2XgQ==}

  unist-util-visit-parents@6.0.1:
    resolution: {integrity: sha512-L/PqWzfTP9lzzEa6CKs0k2nARxTdZduw3zyh8d2NVBnsyvHjSX4TWse388YrrQKbvI8w20fGjGlhgT96WwKykw==}

  unist-util-visit@5.0.0:
    resolution: {integrity: sha512-MR04uvD+07cwl/yhVuVWAtw+3GOR/knlL55Nd/wAdblk27GCVt3lqpTivy/tkJcZoNPzTwS1Y+KMojlLDhoTzg==}

  vfile-message@4.0.2:
    resolution: {integrity: sha512-jRDZ1IMLttGj41KcZvlrYAaI3CfqpLpfpf+Mfig13viT6NKvRzWZ+lXz0Y5D60w6uJIBAOGq9mSHf0gktF0duw==}

  vfile@6.0.3:
    resolution: {integrity: sha512-KzIbH/9tXat2u30jf+smMwFCsno4wHVdNmzFyL+T/L3UGqqk6JKfVqOFOZEpZSHADH1k40ab6NUIXZq422ov3Q==}

  vite@5.4.17:
    resolution: {integrity: sha512-5+VqZryDj4wgCs55o9Lp+p8GE78TLVg0lasCH5xFZ4jacZjtqZa6JUw9/p0WeAojaOfncSM6v77InkFPGnvPvg==}
    engines: {node: ^18.0.0 || >=20.0.0}
    hasBin: true
    peerDependencies:
      '@types/node': ^18.0.0 || >=20.0.0
      less: '*'
      lightningcss: ^1.21.0
      sass: '*'
      sass-embedded: '*'
      stylus: '*'
      sugarss: '*'
      terser: ^5.4.0
    peerDependenciesMeta:
      '@types/node':
        optional: true
      less:
        optional: true
      lightningcss:
        optional: true
      sass:
        optional: true
      sass-embedded:
        optional: true
      stylus:
        optional: true
      sugarss:
        optional: true
      terser:
        optional: true

  vitepress@1.6.3:
    resolution: {integrity: sha512-fCkfdOk8yRZT8GD9BFqusW3+GggWYZ/rYncOfmgcDtP3ualNHCAg+Robxp2/6xfH1WwPHtGpPwv7mbA3qomtBw==}
    hasBin: true
    peerDependencies:
      markdown-it-mathjax3: ^4
      postcss: ^8
    peerDependenciesMeta:
      markdown-it-mathjax3:
        optional: true
      postcss:
        optional: true

  vue@3.5.13:
    resolution: {integrity: sha512-wmeiSMxkZCSc+PM2w2VRsOYAZC8GdipNFRTsLSfodVqI9mbejKeXEGr8SckuLnrQPGe3oJN5c3K0vpoU9q/wCQ==}
    peerDependencies:
      typescript: '*'
    peerDependenciesMeta:
      typescript:
        optional: true

  zwitch@2.0.4:
    resolution: {integrity: sha512-bXE4cR/kVZhKZX/RjPEflHaKVhUVl85noU3v6b8apfQEc1x4A+zBxjZ4lN8LqGd6WZ3dl98pY4o717VFmoPp+A==}

snapshots:

  '@algolia/autocomplete-core@1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)(search-insights@2.17.3)':
    dependencies:
      '@algolia/autocomplete-plugin-algolia-insights': 1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)(search-insights@2.17.3)
      '@algolia/autocomplete-shared': 1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)
    transitivePeerDependencies:
      - '@algolia/client-search'
      - algoliasearch
      - search-insights

  '@algolia/autocomplete-plugin-algolia-insights@1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)(search-insights@2.17.3)':
    dependencies:
      '@algolia/autocomplete-shared': 1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)
      search-insights: 2.17.3
    transitivePeerDependencies:
      - '@algolia/client-search'
      - algoliasearch

  '@algolia/autocomplete-preset-algolia@1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)':
    dependencies:
      '@algolia/autocomplete-shared': 1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)
      '@algolia/client-search': 5.23.2
      algoliasearch: 5.23.2

  '@algolia/autocomplete-shared@1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)':
    dependencies:
      '@algolia/client-search': 5.23.2
      algoliasearch: 5.23.2

  '@algolia/client-abtesting@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/client-analytics@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/client-common@5.23.2': {}

  '@algolia/client-insights@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/client-personalization@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/client-query-suggestions@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/client-search@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/ingestion@1.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/monitoring@1.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/recommend@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  '@algolia/requester-browser-xhr@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2

  '@algolia/requester-fetch@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2

  '@algolia/requester-node-http@5.23.2':
    dependencies:
      '@algolia/client-common': 5.23.2

  '@babel/helper-string-parser@7.25.9': {}

  '@babel/helper-validator-identifier@7.25.9': {}

  '@babel/parser@7.27.0':
    dependencies:
      '@babel/types': 7.27.0

  '@babel/types@7.27.0':
    dependencies:
      '@babel/helper-string-parser': 7.25.9
      '@babel/helper-validator-identifier': 7.25.9

  '@docsearch/css@3.8.2': {}

  '@docsearch/js@3.8.2(@algolia/client-search@5.23.2)(search-insights@2.17.3)':
    dependencies:
      '@docsearch/react': 3.8.2(@algolia/client-search@5.23.2)(search-insights@2.17.3)
      preact: 10.26.4
    transitivePeerDependencies:
      - '@algolia/client-search'
      - '@types/react'
      - react
      - react-dom
      - search-insights

  '@docsearch/react@3.8.2(@algolia/client-search@5.23.2)(search-insights@2.17.3)':
    dependencies:
      '@algolia/autocomplete-core': 1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)(search-insights@2.17.3)
      '@algolia/autocomplete-preset-algolia': 1.17.7(@algolia/client-search@5.23.2)(algoliasearch@5.23.2)
      '@docsearch/css': 3.8.2
      algoliasearch: 5.23.2
    optionalDependencies:
      search-insights: 2.17.3
    transitivePeerDependencies:
      - '@algolia/client-search'

  '@esbuild/aix-ppc64@0.21.5':
    optional: true

  '@esbuild/android-arm64@0.21.5':
    optional: true

  '@esbuild/android-arm@0.21.5':
    optional: true

  '@esbuild/android-x64@0.21.5':
    optional: true

  '@esbuild/darwin-arm64@0.21.5':
    optional: true

  '@esbuild/darwin-x64@0.21.5':
    optional: true

  '@esbuild/freebsd-arm64@0.21.5':
    optional: true

  '@esbuild/freebsd-x64@0.21.5':
    optional: true

  '@esbuild/linux-arm64@0.21.5':
    optional: true

  '@esbuild/linux-arm@0.21.5':
    optional: true

  '@esbuild/linux-ia32@0.21.5':
    optional: true

  '@esbuild/linux-loong64@0.21.5':
    optional: true

  '@esbuild/linux-mips64el@0.21.5':
    optional: true

  '@esbuild/linux-ppc64@0.21.5':
    optional: true

  '@esbuild/linux-riscv64@0.21.5':
    optional: true

  '@esbuild/linux-s390x@0.21.5':
    optional: true

  '@esbuild/linux-x64@0.21.5':
    optional: true

  '@esbuild/netbsd-x64@0.21.5':
    optional: true

  '@esbuild/openbsd-x64@0.21.5':
    optional: true

  '@esbuild/sunos-x64@0.21.5':
    optional: true

  '@esbuild/win32-arm64@0.21.5':
    optional: true

  '@esbuild/win32-ia32@0.21.5':
    optional: true

  '@esbuild/win32-x64@0.21.5':
    optional: true

  '@iconify-json/simple-icons@1.2.30':
    dependencies:
      '@iconify/types': 2.0.0

  '@iconify/types@2.0.0': {}

  '@jridgewell/sourcemap-codec@1.5.0': {}

  '@rollup/rollup-android-arm-eabi@4.39.0':
    optional: true

  '@rollup/rollup-android-arm64@4.39.0':
    optional: true

  '@rollup/rollup-darwin-arm64@4.39.0':
    optional: true

  '@rollup/rollup-darwin-x64@4.39.0':
    optional: true

  '@rollup/rollup-freebsd-arm64@4.39.0':
    optional: true

  '@rollup/rollup-freebsd-x64@4.39.0':
    optional: true

  '@rollup/rollup-linux-arm-gnueabihf@4.39.0':
    optional: true

  '@rollup/rollup-linux-arm-musleabihf@4.39.0':
    optional: true

  '@rollup/rollup-linux-arm64-gnu@4.39.0':
    optional: true

  '@rollup/rollup-linux-arm64-musl@4.39.0':
    optional: true

  '@rollup/rollup-linux-loongarch64-gnu@4.39.0':
    optional: true

  '@rollup/rollup-linux-powerpc64le-gnu@4.39.0':
    optional: true

  '@rollup/rollup-linux-riscv64-gnu@4.39.0':
    optional: true

  '@rollup/rollup-linux-riscv64-musl@4.39.0':
    optional: true

  '@rollup/rollup-linux-s390x-gnu@4.39.0':
    optional: true

  '@rollup/rollup-linux-x64-gnu@4.39.0':
    optional: true

  '@rollup/rollup-linux-x64-musl@4.39.0':
    optional: true

  '@rollup/rollup-win32-arm64-msvc@4.39.0':
    optional: true

  '@rollup/rollup-win32-ia32-msvc@4.39.0':
    optional: true

  '@rollup/rollup-win32-x64-msvc@4.39.0':
    optional: true

  '@shikijs/core@2.5.0':
    dependencies:
      '@shikijs/engine-javascript': 2.5.0
      '@shikijs/engine-oniguruma': 2.5.0
      '@shikijs/types': 2.5.0
      '@shikijs/vscode-textmate': 10.0.2
      '@types/hast': 3.0.4
      hast-util-to-html: 9.0.5

  '@shikijs/engine-javascript@2.5.0':
    dependencies:
      '@shikijs/types': 2.5.0
      '@shikijs/vscode-textmate': 10.0.2
      oniguruma-to-es: 3.1.1

  '@shikijs/engine-oniguruma@2.5.0':
    dependencies:
      '@shikijs/types': 2.5.0
      '@shikijs/vscode-textmate': 10.0.2

  '@shikijs/langs@2.5.0':
    dependencies:
      '@shikijs/types': 2.5.0

  '@shikijs/themes@2.5.0':
    dependencies:
      '@shikijs/types': 2.5.0

  '@shikijs/transformers@2.5.0':
    dependencies:
      '@shikijs/core': 2.5.0
      '@shikijs/types': 2.5.0

  '@shikijs/types@2.5.0':
    dependencies:
      '@shikijs/vscode-textmate': 10.0.2
      '@types/hast': 3.0.4

  '@shikijs/vscode-textmate@10.0.2': {}

  '@types/estree@1.0.7': {}

  '@types/hast@3.0.4':
    dependencies:
      '@types/unist': 3.0.3

  '@types/linkify-it@5.0.0': {}

  '@types/markdown-it@14.1.2':
    dependencies:
      '@types/linkify-it': 5.0.0
      '@types/mdurl': 2.0.0

  '@types/mdast@4.0.4':
    dependencies:
      '@types/unist': 3.0.3

  '@types/mdurl@2.0.0': {}

  '@types/unist@3.0.3': {}

  '@types/web-bluetooth@0.0.21': {}

  '@ungap/structured-clone@1.3.0': {}

  '@vitejs/plugin-vue@5.2.3(vite@5.4.17)(vue@3.5.13)':
    dependencies:
      vite: 5.4.17
      vue: 3.5.13

  '@vue/compiler-core@3.5.13':
    dependencies:
      '@babel/parser': 7.27.0
      '@vue/shared': 3.5.13
      entities: 4.5.0
      estree-walker: 2.0.2
      source-map-js: 1.2.1

  '@vue/compiler-dom@3.5.13':
    dependencies:
      '@vue/compiler-core': 3.5.13
      '@vue/shared': 3.5.13

  '@vue/compiler-sfc@3.5.13':
    dependencies:
      '@babel/parser': 7.27.0
      '@vue/compiler-core': 3.5.13
      '@vue/compiler-dom': 3.5.13
      '@vue/compiler-ssr': 3.5.13
      '@vue/shared': 3.5.13
      estree-walker: 2.0.2
      magic-string: 0.30.17
      postcss: 8.5.3
      source-map-js: 1.2.1

  '@vue/compiler-ssr@3.5.13':
    dependencies:
      '@vue/compiler-dom': 3.5.13
      '@vue/shared': 3.5.13

  '@vue/devtools-api@7.7.2':
    dependencies:
      '@vue/devtools-kit': 7.7.2

  '@vue/devtools-kit@7.7.2':
    dependencies:
      '@vue/devtools-shared': 7.7.2
      birpc: 0.2.19
      hookable: 5.5.3
      mitt: 3.0.1
      perfect-debounce: 1.0.0
      speakingurl: 14.0.1
      superjson: 2.2.2

  '@vue/devtools-shared@7.7.2':
    dependencies:
      rfdc: 1.4.1

  '@vue/reactivity@3.5.13':
    dependencies:
      '@vue/shared': 3.5.13

  '@vue/runtime-core@3.5.13':
    dependencies:
      '@vue/reactivity': 3.5.13
      '@vue/shared': 3.5.13

  '@vue/runtime-dom@3.5.13':
    dependencies:
      '@vue/reactivity': 3.5.13
      '@vue/runtime-core': 3.5.13
      '@vue/shared': 3.5.13
      csstype: 3.1.3

  '@vue/server-renderer@3.5.13(vue@3.5.13)':
    dependencies:
      '@vue/compiler-ssr': 3.5.13
      '@vue/shared': 3.5.13
      vue: 3.5.13

  '@vue/shared@3.5.13': {}

  '@vueuse/core@12.8.2':
    dependencies:
      '@types/web-bluetooth': 0.0.21
      '@vueuse/metadata': 12.8.2
      '@vueuse/shared': 12.8.2
      vue: 3.5.13
    transitivePeerDependencies:
      - typescript

  '@vueuse/integrations@12.8.2(focus-trap@7.6.4)':
    dependencies:
      '@vueuse/core': 12.8.2
      '@vueuse/shared': 12.8.2
      vue: 3.5.13
    optionalDependencies:
      focus-trap: 7.6.4
    transitivePeerDependencies:
      - typescript

  '@vueuse/metadata@12.8.2': {}

  '@vueuse/shared@12.8.2':
    dependencies:
      vue: 3.5.13
    transitivePeerDependencies:
      - typescript

  algoliasearch@5.23.2:
    dependencies:
      '@algolia/client-abtesting': 5.23.2
      '@algolia/client-analytics': 5.23.2
      '@algolia/client-common': 5.23.2
      '@algolia/client-insights': 5.23.2
      '@algolia/client-personalization': 5.23.2
      '@algolia/client-query-suggestions': 5.23.2
      '@algolia/client-search': 5.23.2
      '@algolia/ingestion': 1.23.2
      '@algolia/monitoring': 1.23.2
      '@algolia/recommend': 5.23.2
      '@algolia/requester-browser-xhr': 5.23.2
      '@algolia/requester-fetch': 5.23.2
      '@algolia/requester-node-http': 5.23.2

  birpc@0.2.19: {}

  ccount@2.0.1: {}

  character-entities-html4@2.1.0: {}

  character-entities-legacy@3.0.0: {}

  comma-separated-tokens@2.0.3: {}

  copy-anything@3.0.5:
    dependencies:
      is-what: 4.1.16

  csstype@3.1.3: {}

  dequal@2.0.3: {}

  devlop@1.1.0:
    dependencies:
      dequal: 2.0.3

  emoji-regex-xs@1.0.0: {}

  entities@4.5.0: {}

  esbuild@0.21.5:
    optionalDependencies:
      '@esbuild/aix-ppc64': 0.21.5
      '@esbuild/android-arm': 0.21.5
      '@esbuild/android-arm64': 0.21.5
      '@esbuild/android-x64': 0.21.5
      '@esbuild/darwin-arm64': 0.21.5
      '@esbuild/darwin-x64': 0.21.5
      '@esbuild/freebsd-arm64': 0.21.5
      '@esbuild/freebsd-x64': 0.21.5
      '@esbuild/linux-arm': 0.21.5
      '@esbuild/linux-arm64': 0.21.5
      '@esbuild/linux-ia32': 0.21.5
      '@esbuild/linux-loong64': 0.21.5
      '@esbuild/linux-mips64el': 0.21.5
      '@esbuild/linux-ppc64': 0.21.5
      '@esbuild/linux-riscv64': 0.21.5
      '@esbuild/linux-s390x': 0.21.5
      '@esbuild/linux-x64': 0.21.5
      '@esbuild/netbsd-x64': 0.21.5
      '@esbuild/openbsd-x64': 0.21.5
      '@esbuild/sunos-x64': 0.21.5
      '@esbuild/win32-arm64': 0.21.5
      '@esbuild/win32-ia32': 0.21.5
      '@esbuild/win32-x64': 0.21.5

  estree-walker@2.0.2: {}

  focus-trap@7.6.4:
    dependencies:
      tabbable: 6.2.0

  fsevents@2.3.3:
    optional: true

  hast-util-to-html@9.0.5:
    dependencies:
      '@types/hast': 3.0.4
      '@types/unist': 3.0.3
      ccount: 2.0.1
      comma-separated-tokens: 2.0.3
      hast-util-whitespace: 3.0.0
      html-void-elements: 3.0.0
      mdast-util-to-hast: 13.2.0
      property-information: 7.0.0
      space-separated-tokens: 2.0.2
      stringify-entities: 4.0.4
      zwitch: 2.0.4

  hast-util-whitespace@3.0.0:
    dependencies:
      '@types/hast': 3.0.4

  hookable@5.5.3: {}

  html-void-elements@3.0.0: {}

  is-what@4.1.16: {}

  magic-string@0.30.17:
    dependencies:
      '@jridgewell/sourcemap-codec': 1.5.0

  mark.js@8.11.1: {}

  mdast-util-to-hast@13.2.0:
    dependencies:
      '@types/hast': 3.0.4
      '@types/mdast': 4.0.4
      '@ungap/structured-clone': 1.3.0
      devlop: 1.1.0
      micromark-util-sanitize-uri: 2.0.1
      trim-lines: 3.0.1
      unist-util-position: 5.0.0
      unist-util-visit: 5.0.0
      vfile: 6.0.3

  micromark-util-character@2.1.1:
    dependencies:
      micromark-util-symbol: 2.0.1
      micromark-util-types: 2.0.2

  micromark-util-encode@2.0.1: {}

  micromark-util-sanitize-uri@2.0.1:
    dependencies:
      micromark-util-character: 2.1.1
      micromark-util-encode: 2.0.1
      micromark-util-symbol: 2.0.1

  micromark-util-symbol@2.0.1: {}

  micromark-util-types@2.0.2: {}

  minisearch@7.1.2: {}

  mitt@3.0.1: {}

  nanoid@3.3.11: {}

  oniguruma-to-es@3.1.1:
    dependencies:
      emoji-regex-xs: 1.0.0
      regex: 6.0.1
      regex-recursion: 6.0.2

  perfect-debounce@1.0.0: {}

  picocolors@1.1.1: {}

  postcss@8.5.3:
    dependencies:
      nanoid: 3.3.11
      picocolors: 1.1.1
      source-map-js: 1.2.1

  preact@10.26.4: {}

  property-information@7.0.0: {}

  regex-recursion@6.0.2:
    dependencies:
      regex-utilities: 2.3.0

  regex-utilities@2.3.0: {}

  regex@6.0.1:
    dependencies:
      regex-utilities: 2.3.0

  rfdc@1.4.1: {}

  rollup@4.39.0:
    dependencies:
      '@types/estree': 1.0.7
    optionalDependencies:
      '@rollup/rollup-android-arm-eabi': 4.39.0
      '@rollup/rollup-android-arm64': 4.39.0
      '@rollup/rollup-darwin-arm64': 4.39.0
      '@rollup/rollup-darwin-x64': 4.39.0
      '@rollup/rollup-freebsd-arm64': 4.39.0
      '@rollup/rollup-freebsd-x64': 4.39.0
      '@rollup/rollup-linux-arm-gnueabihf': 4.39.0
      '@rollup/rollup-linux-arm-musleabihf': 4.39.0
      '@rollup/rollup-linux-arm64-gnu': 4.39.0
      '@rollup/rollup-linux-arm64-musl': 4.39.0
      '@rollup/rollup-linux-loongarch64-gnu': 4.39.0
      '@rollup/rollup-linux-powerpc64le-gnu': 4.39.0
      '@rollup/rollup-linux-riscv64-gnu': 4.39.0
      '@rollup/rollup-linux-riscv64-musl': 4.39.0
      '@rollup/rollup-linux-s390x-gnu': 4.39.0
      '@rollup/rollup-linux-x64-gnu': 4.39.0
      '@rollup/rollup-linux-x64-musl': 4.39.0
      '@rollup/rollup-win32-arm64-msvc': 4.39.0
      '@rollup/rollup-win32-ia32-msvc': 4.39.0
      '@rollup/rollup-win32-x64-msvc': 4.39.0
      fsevents: 2.3.3

  search-insights@2.17.3: {}

  shiki@2.5.0:
    dependencies:
      '@shikijs/core': 2.5.0
      '@shikijs/engine-javascript': 2.5.0
      '@shikijs/engine-oniguruma': 2.5.0
      '@shikijs/langs': 2.5.0
      '@shikijs/themes': 2.5.0
      '@shikijs/types': 2.5.0
      '@shikijs/vscode-textmate': 10.0.2
      '@types/hast': 3.0.4

  source-map-js@1.2.1: {}

  space-separated-tokens@2.0.2: {}

  speakingurl@14.0.1: {}

  stringify-entities@4.0.4:
    dependencies:
      character-entities-html4: 2.1.0
      character-entities-legacy: 3.0.0

  superjson@2.2.2:
    dependencies:
      copy-anything: 3.0.5

  tabbable@6.2.0: {}

  trim-lines@3.0.1: {}

  unist-util-is@6.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-position@5.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-stringify-position@4.0.0:
    dependencies:
      '@types/unist': 3.0.3

  unist-util-visit-parents@6.0.1:
    dependencies:
      '@types/unist': 3.0.3
      unist-util-is: 6.0.0

  unist-util-visit@5.0.0:
    dependencies:
      '@types/unist': 3.0.3
      unist-util-is: 6.0.0
      unist-util-visit-parents: 6.0.1

  vfile-message@4.0.2:
    dependencies:
      '@types/unist': 3.0.3
      unist-util-stringify-position: 4.0.0

  vfile@6.0.3:
    dependencies:
      '@types/unist': 3.0.3
      vfile-message: 4.0.2

  vite@5.4.17:
    dependencies:
      esbuild: 0.21.5
      postcss: 8.5.3
      rollup: 4.39.0
    optionalDependencies:
      fsevents: 2.3.3

  vitepress@1.6.3(@algolia/client-search@5.23.2)(postcss@8.5.3)(search-insights@2.17.3):
    dependencies:
      '@docsearch/css': 3.8.2
      '@docsearch/js': 3.8.2(@algolia/client-search@5.23.2)(search-insights@2.17.3)
      '@iconify-json/simple-icons': 1.2.30
      '@shikijs/core': 2.5.0
      '@shikijs/transformers': 2.5.0
      '@shikijs/types': 2.5.0
      '@types/markdown-it': 14.1.2
      '@vitejs/plugin-vue': 5.2.3(vite@5.4.17)(vue@3.5.13)
      '@vue/devtools-api': 7.7.2
      '@vue/shared': 3.5.13
      '@vueuse/core': 12.8.2
      '@vueuse/integrations': 12.8.2(focus-trap@7.6.4)
      focus-trap: 7.6.4
      mark.js: 8.11.1
      minisearch: 7.1.2
      shiki: 2.5.0
      vite: 5.4.17
      vue: 3.5.13
    optionalDependencies:
      postcss: 8.5.3
    transitivePeerDependencies:
      - '@algolia/client-search'
      - '@types/node'
      - '@types/react'
      - async-validator
      - axios
      - change-case
      - drauu
      - fuse.js
      - idb-keyval
      - jwt-decode
      - less
      - lightningcss
      - nprogress
      - qrcode
      - react
      - react-dom
      - sass
      - sass-embedded
      - search-insights
      - sortablejs
      - stylus
      - sugarss
      - terser
      - typescript
      - universal-cookie

  vue@3.5.13:
    dependencies:
      '@vue/compiler-dom': 3.5.13
      '@vue/compiler-sfc': 3.5.13
      '@vue/runtime-dom': 3.5.13
      '@vue/server-renderer': 3.5.13(vue@3.5.13)
      '@vue/shared': 3.5.13

  zwitch@2.0.4: {}
```
## kernel/Cargo.toml
```
[package]
name = "kernel"
publish = false
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[[bin]]
name = "kernel"
path = "main.rs"

[dependencies]
starina_types = { workspace = true }
starina_utils = { workspace = true }

spin = { workspace = true }
arrayvec = { workspace = true }
hashbrown = { workspace = true }
rustc-hash = { workspace = true }
serde_json = { workspace = true }
fdt-rs = { workspace = true }

# The kernel does not and should not use this API crate directly, but
# specifying "in-kernel" here automatically enables the feature in all
# in-kernel apps thanks to the feature unification feature of Cargo:
# https://doc.rust-lang.org/1.59.0/cargo/reference/features.html#feature-unification
starina = { workspace = true, features = ["in-kernel"] }

virtio_net = { workspace = true }
tcpip = { workspace = true }
http_server = { workspace = true }
```
## kernel/allocator.rs
```
use core::alloc::GlobalAlloc;
use core::alloc::Layout;
use core::num::NonZeroUsize;

use crate::spinlock::SpinLock;

#[cfg_attr(target_os = "none", global_allocator)]
#[cfg_attr(not(target_os = "none"), allow(unused))]
pub static GLOBAL_ALLOCATOR: GlobalAllocator = GlobalAllocator::new();

/// The default in-kernel memory allocator.
///
/// Allocated memory are always accessible from the kernel's address space,
/// that is, memory pages added to this allocator must not be swapped out,
/// or something like that.
pub struct GlobalAllocator {
    inner: SpinLock<BumpAllocator>,
}

impl GlobalAllocator {
    /// Creates a new global allocator.
    ///
    /// The allocator is initially empty. Memory regions must be added
    /// by calling [`GlobalAllocator::add_region`] method.
    pub const fn new() -> GlobalAllocator {
        let allocator = BumpAllocator::new();

        GlobalAllocator {
            inner: SpinLock::new(allocator),
        }
    }

    /// Adds a new memory region to the allocator.
    ///
    /// The memory region must be always mapped to the kernel's address space.
    pub fn add_region(&self, heap: *mut u8, heap_len: usize) {
        self.inner.lock().add_region(heap as usize, heap_len);
    }
}

unsafe impl GlobalAlloc for GlobalAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let addr = self
            .inner
            .lock()
            .allocate(layout.size(), layout.align())
            .expect("failed to allocate memory");

        addr.get() as *mut u8
    }

    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {
        /* We can't deallocate. This is well-known limitation of bump allocator! */
    }
}

const fn align_down(value: usize, align: usize) -> usize {
    debug_assert!(align.is_power_of_two());
    (value) & !(align - 1)
}

/// A bump memory allocator.
///
/// Unlike typical allocators, this allocator does not support freeing memory.
/// Instead, it only supports allocating memory. This makes it extremely fast
/// and simple.
///
/// Typically, this allocator is used for allocating memory in initialization
/// phase such that the allocated memory is never freed.
pub struct BumpAllocator {
    top: usize,
    bottom: usize,
}

impl Default for BumpAllocator {
    fn default() -> Self {
        Self::new()
    }
}

impl BumpAllocator {
    // Creates a new bump allocator. Initially, the allocator has no memory
    // region. Call `add_region` to add a memory region.
    pub const fn new() -> BumpAllocator {
        BumpAllocator { bottom: 0, top: 0 }
    }

    // Gives a meory region `[base, base + len)` to the allocator.
    // `base` must be non-zero.
    pub fn add_region(&mut self, base: usize, len: usize) {
        debug_assert!(self.bottom == 0, "only one region is supported");
        debug_assert!(base > 0);

        self.bottom = base;
        self.top = base + len;
    }

    /// Allocates `size` bytes of memory with the given `align` bytes alignment.
    /// Returns the beginning address of the allocated memory if successful.
    #[track_caller]
    pub fn allocate(&mut self, size: usize, align: usize) -> Option<NonZeroUsize> {
        if size == 0 {
            return None;
        }

        let new_top = align_down(self.top.checked_sub(size)?, align);
        if new_top < self.bottom {
            return None;
        }

        self.top = new_top;

        // SAFETY: `self.top` is checked to be larger than `self.bottom`.
        unsafe { Some(NonZeroUsize::new_unchecked(self.top)) }
    }
}

#[cfg(test)]
mod tests {
    use core::num::NonZeroUsize;

    use super::*;

    fn nonzero(value: usize) -> NonZeroUsize {
        NonZeroUsize::new(value).unwrap()
    }

    #[test]
    fn test_zero_size() {
        let mut allocator = BumpAllocator::new();
        allocator.add_region(0x20000, 0x4000);
        assert_eq!(allocator.allocate(0, 0x1000), None);
    }

    #[test]
    fn test_bump_allocator() {
        let mut allocator = BumpAllocator::new();
        allocator.add_region(0x20000, 0x4000);
        assert_eq!(allocator.allocate(0x1000, 0x1000), Some(nonzero(0x23000)));
        assert_eq!(allocator.allocate(0x1000, 0x1000), Some(nonzero(0x22000)));
        assert_eq!(allocator.allocate(0xf00, 0x1000), Some(nonzero(0x21000)));
        assert_eq!(allocator.allocate(0x1000, 0x1000), Some(nonzero(0x20000)));
        assert_eq!(allocator.allocate(0x1000, 0x1000), None);
    }
}
```
## kernel/arch/host/mod.rs
```
#![allow(unused_variables)]

use std::cell::RefCell;
use std::io::Write;

use starina::address::DAddr;
use starina::address::PAddr;
use starina::address::VAddr;
use starina::device_tree::Reg;
use starina::error::ErrorCode;
use starina::interrupt::Irq;
use starina::interrupt::IrqMatcher;
use starina_types::syscall::RetVal;
use starina_types::vmspace::PageProtect;

use crate::interrupt::Interrupt;
use crate::refcount::SharedRef;

pub const PAGE_SIZE: usize = 4096;

pub fn percpu_init() {
    todo!()
}

pub fn halt() -> ! {
    panic!("halted");
}

pub fn console_write(s: &[u8]) {
    std::io::stdout().write_all(s).unwrap();
}

// #[naked]
pub extern "C" fn enter_kernelland(
    _a0: isize,
    _a1: isize,
    _a2: isize,
    _a3: isize,
    _a4: isize,
    _a5: isize,
) -> RetVal {
    todo!()
}

pub fn enter_userland(thread: *mut crate::arch::Thread) -> ! {
    todo!()
}

pub fn idle() -> ! {
    todo!();
}

pub struct Thread {}

impl Thread {
    pub fn new_inkernel(pc: usize, arg: usize) -> Thread {
        Thread {}
    }

    pub fn new_idle() -> Thread {
        Thread {}
    }

    pub fn set_retval(&mut self, retval: RetVal) {
        todo!()
    }
}

pub const NUM_CPUS_MAX: usize = 1;

pub struct CpuVar {}

impl CpuVar {
    pub fn new(idle_thread: &crate::refcount::SharedRef<crate::thread::Thread>) -> Self {
        CpuVar {}
    }
}

thread_local! {
    static CPUVAR: RefCell<*mut crate::cpuvar::CpuVar> =
        const { RefCell::new(std::ptr::null_mut()) }
    ;
}

pub fn set_cpuvar(cpuvar: *mut crate::cpuvar::CpuVar) {
    CPUVAR.with_borrow_mut(|cpuvar_ref| {
        *cpuvar_ref = cpuvar;
    });
}

pub fn get_cpuvar() -> &'static crate::cpuvar::CpuVar {
    CPUVAR.with_borrow(|cpuvar_ref| {
        debug_assert!(!cpuvar_ref.is_null());
        unsafe { &**cpuvar_ref }
    })
}

pub struct VmSpace {}

impl VmSpace {
    pub fn new() -> Result<VmSpace, ErrorCode> {
        todo!()
    }

    pub fn map_fixed(
        &self,
        vaddr: VAddr,
        paddr: PAddr,
        len: usize,
        prot: PageProtect,
    ) -> Result<(), ErrorCode> {
        todo!()
    }

    pub fn map_anywhere(
        &self,
        paddr: PAddr,
        len: usize,
        prot: PageProtect,
    ) -> Result<VAddr, ErrorCode> {
        todo!()
    }

    pub fn switch(&self) {
        todo!()
    }
}

pub fn kernel_scope<F, R>(f: F) -> R
where
    F: FnOnce() -> R,
{
    todo!()
}

pub fn map_daddr(paddr: PAddr) -> Result<DAddr, ErrorCode> {
    todo!()
}

pub fn unmap_daddr(daddr: DAddr) -> Result<(), ErrorCode> {
    todo!()
}

pub fn vaddr2paddr(vaddr: VAddr) -> Result<PAddr, ErrorCode> {
    todo!()
}

pub fn paddr2vaddr(paddr: PAddr) -> Result<VAddr, ErrorCode> {
    todo!()
}

pub static INTERRUPT_CONTROLLER: InterruptController = InterruptController {};

pub struct InterruptController {}

impl InterruptController {
    pub const fn new() -> Self {
        todo!()
    }

    pub fn try_init(&self, compatible: &[String], reg: &[Reg]) -> Result<(), ErrorCode> {
        todo!()
    }

    pub fn parse_interrupts_cell(&self, interrupts_cell: &[u32]) -> Result<IrqMatcher, ()> {
        todo!()
    }
    pub fn acquire_irq(&self, irq_matcher: IrqMatcher) -> Result<Irq, ErrorCode> {
        todo!()
    }

    pub fn enable_irq(&self, interrupt: SharedRef<Interrupt>) {
        todo!()
    }

    pub fn acknowledge_irq(&self, irq: Irq) {
        todo!()
    }
}
```
## kernel/arch/mod.rs
```
#[cfg(not(target_os = "none"))]
mod host;
#[cfg(all(target_os = "none", target_arch = "riscv64"))]
mod riscv64;

#[cfg(not(target_os = "none"))]
pub use host::*;
#[cfg(all(target_os = "none", target_arch = "riscv64"))]
pub use riscv64::*;
```
## kernel/arch/riscv64/boot.S
```
// The kernel entrypoint for RISC-V machines. We expect Linux's RISC-V boot
// requirements:
//
//   - a0: THe hartid of this CPU.
//   - a1: The address of the device tree blob.
.section ".text.boot", "ax"
.global boot
boot:
    // Note: Don't modify a0, a1 registers here: they are used as arguments to
    //       riscv64_boot.
    mv ra, zero
    mv fp, zero
    la sp, __boot_stack_top
    j riscv64_boot

.rodata
.balign 4096
.global __vsyscall_page
__vsyscall_page:
    ecall
    ret
```
## kernel/arch/riscv64/cpuvar.rs
```
use core::arch::asm;

use super::thread::Context;
use crate::refcount::SharedRef;
use crate::thread::Thread;

pub struct CpuVar {
    pub context: *mut Context,
    pub(super) kernel_sp: u64,
    pub(super) a0_scratch: u64,
}

impl CpuVar {
    pub fn new(idle_thread: &SharedRef<Thread>) -> Self {
        unsafe extern "C" {
            static __boot_stack_top: u8;
        }

        let sp_top = &raw const __boot_stack_top as u64;
        Self {
            context: unsafe { &raw mut (*idle_thread.arch_thread_ptr()).context },
            kernel_sp: sp_top,
            a0_scratch: 0,
        }
    }
}

pub fn get_cpuvar() -> &'static crate::cpuvar::CpuVar {
    // Load the address of the current CPU's `CpuVar` from `tp`.
    let cpuvar: *const crate::cpuvar::CpuVar;
    unsafe {
        asm!("mv {}, tp", out(reg) cpuvar);
    }
    unsafe { &*cpuvar }
}

pub fn set_cpuvar(cpuvar: *mut crate::cpuvar::CpuVar) {
    // Store the address of the current CPU's `CpuVar` to `tp`.
    unsafe {
        asm!("mv tp, {}", in(reg) cpuvar);
    }
}
```
## kernel/arch/riscv64/csr.rs
```
use core::arch::asm;

#[repr(usize)]
pub enum StvecMode {
    Direct = 0,
}

pub unsafe fn write_stvec(addr: usize, mode: StvecMode) {
    assert!(addr & 0b11 == 0, "addr is not aligned");
    unsafe {
        asm!("csrw stvec, {}", in(reg) (addr | mode as usize));
    }
}
```
## kernel/arch/riscv64/idle.rs
```
use core::arch::asm;
use core::arch::naked_asm;

use super::csr::StvecMode;
use super::csr::write_stvec;
use super::interrupt::interrupt_handler;
use super::transition::switch_to_kernel;

/// The entry point of interrupts or exceptions.
#[naked]
#[repr(align(4))]
unsafe extern "C" fn idle_entry() -> ! {
    unsafe {
        naked_asm!(
            r#"
            j {resume_from_idle}
            "#,
            resume_from_idle = sym resume_from_idle,
        );
    }
}

fn resume_from_idle() -> ! {
    unsafe {
        write_stvec(switch_to_kernel as *const () as usize, StvecMode::Direct);
    }

    interrupt_handler();
    todo!()
}

pub fn idle() -> ! {
    trace!("idle");

    unsafe {
        write_stvec(idle_entry as *const () as usize, StvecMode::Direct);

        // Memory fence to ensure writes so far become visible to other cores,
        // before entering WFI.
        asm!("fence");
        // Enable interrupts.
        asm!("csrsi sstatus, 1 << 1");
    }

    loop {
        unsafe {
            asm!("wfi");
        }
    }
}
```
## kernel/arch/riscv64/interrupt.rs
```
use alloc::string::String;
use core::arch::asm;

use starina::device_tree::Reg;
use starina::error::ErrorCode;
use starina::interrupt::Irq;
use starina::interrupt::IrqMatcher;

use super::plic;
use super::plic::use_plic;
use crate::interrupt::Interrupt;
use crate::refcount::SharedRef;
use crate::thread::switch_thread;

pub extern "C" fn interrupt_handler() -> ! {
    let cpuvar = super::get_cpuvar();

    let scause: u64;
    let stval: u64;
    unsafe {
        asm!("csrr {}, scause", out(reg) scause);
        asm!("csrr {}, stval", out(reg) stval);
    }

    let is_intr = scause & (1 << 63) != 0;
    let code = scause & !(1 << 63);
    let scause_str = match (is_intr, code) {
        (true, 0) => "user software interrupt",
        (true, 1) => "supervisor software interrupt",
        (true, 2) => "hypervisor software interrupt",
        (true, 3) => "machine software interrupt",
        (true, 4) => "user timer interrupt",
        (true, 5) => "supervisor timer interrupt",
        (true, 6) => "hypervisor timer interrupt",
        (true, 7) => "machine timer interrupt",
        (true, 8) => "user external interrupt",
        (true, 9) => "supervisor external interrupt",
        (true, 10) => "hypervisor external interrupt",
        (true, 11) => "machine external interrupt",
        (false, 0) => "instruction address misaligned",
        (false, 1) => "instruction access fault",
        (false, 2) => "illegal instruction",
        (false, 3) => "breakpoint",
        (false, 4) => "load address misaligned",
        (false, 5) => "load access fault",
        (false, 6) => "store/AMO address misaligned",
        (false, 7) => "store/AMO access fault",
        (false, 8) => "environment call from U-mode",
        (false, 9) => "environment call from S-mode",
        (false, 10) => "reserved",
        (false, 11) => "environment call from M-mode",
        (false, 12) => "instruction page fault",
        (false, 13) => "load page fault",
        (false, 15) => "store/AMO page fault",
        _ => "unknown",
    };

    let sepc = unsafe { (*cpuvar.arch.context).sepc } as u64;

    trace!(
        "interrupt: {} (scause={:#x}), sepc: {:#x}, stval: {:#x}",
        scause_str, scause, sepc, stval
    );

    if (is_intr, code) == (true, 9) {
        use_plic(|plic| {
            plic.handle_interrupt();
        });
        switch_thread();
    } else if (is_intr, code) == (false, 8) {
        unsafe {
            // Skip ecall instruction
            (*cpuvar.arch.context).sepc += 4;
        }

        // let a0 = unsafe { (*cpuvar.arch.context).a0 } as isize;
        // let a1 = unsafe { (*cpuvar.arch.context).a1 } as isize;
        // let a2 = unsafe { (*cpuvar.arch.context).a2 } as isize;
        // let a3 = unsafe { (*cpuvar.arch.context).a3 } as isize;
        // let a4 = unsafe { (*cpuvar.arch.context).a4 } as isize;
        // let a5 = unsafe { (*cpuvar.arch.context).a5 } as isize;
        // let ret = syscall_handler(a0, a1, a2, a3, a4, a5);
        todo!()
    } else {
        panic!("unhandled intrrupt");
    }
}
pub static INTERRUPT_CONTROLLER: PlicWrapper = PlicWrapper::new();

#[derive(Debug)]
pub enum InterruptCellParseError {
    InvalidCellCount,
}

pub struct PlicWrapper {
    _private: (),
}

impl PlicWrapper {
    pub const fn new() -> Self {
        Self { _private: () }
    }

    pub fn try_init(&self, compatible: &[String], reg: &[Reg]) -> Result<(), ErrorCode> {
        plic::try_init(compatible, reg)
    }

    pub fn parse_interrupts_cell(
        &self,
        interrupts_cell: &[u32],
    ) -> Result<IrqMatcher, InterruptCellParseError> {
        if interrupts_cell.len() != 1 {
            return Err(InterruptCellParseError::InvalidCellCount);
        }

        let irq = Irq::from_raw(interrupts_cell[0]);
        Ok(IrqMatcher::Static(irq))
    }

    pub fn acquire_irq(&self, irq_matcher: IrqMatcher) -> Result<Irq, ErrorCode> {
        match irq_matcher {
            IrqMatcher::Static(irq) => Ok(irq),
        }
    }

    pub fn enable_irq(&self, interrupt: SharedRef<Interrupt>) {
        use_plic(|plic| {
            plic.enable_irq(interrupt.irq());
            plic.register_listener(interrupt.irq(), interrupt);
        });
    }

    pub fn acknowledge_irq(&self, irq: Irq) {
        use_plic(|plic| {
            plic.acknowledge(irq);
        });
    }
}
```
## kernel/arch/riscv64/kernel.json
```
{
    "arch": "riscv64",
    "code-model": "medium",
    "cpu": "generic-rv64",
    "os": "none",
    "crt-objects-fallback": "false",
    "data-layout": "e-m:e-p:64:64-i64:64-i128:128-n32:64-S128",
    "eh-frame-header": false,
    "frame-pointer": "always",
    "emit-debug-gdb-scripts": false,
    "features": "+m,+a,+f,+d,+c",
    "linker-flavor": "ld.lld",
    "linker": "rust-lld",
    "pre-link-args": {
        "ld.lld": [
            "--script=kernel/arch/riscv64/kernel.ld",
            "-Map",
            "starina.map"
        ]
    },
    "llvm-abiname": "lp64d",
    "llvm-target": "riscv64",
    "max-atomic-width": 64,
    "panic-strategy": "abort",
    "relocation-model": "static",
    "supported-sanitizers": [
        "kernel-address"
    ],
    "target-pointer-width": "64"
}
```
## kernel/arch/riscv64/kernel.ld
```
ENTRY(boot)

SECTIONS {
    . = 0x80200000;

    __kernel_start = .;

    .text :{
        KEEP(*(.text.boot));

        /* For some reason #[align(4)] in functions is no longer supported in
           latest Rust nightly. This is a quick workaround. */
        . = ALIGN(4);
        *(.text.switch_to_kernel);
        . = ALIGN(4);
        *(.text.idle_entry);

        *(.text .text.*);
    }

    .rodata : ALIGN(16) {
        *(.rodata .rodata.*);
    }

    .data : ALIGN(16) {
        *(.data .data.*);
    }

    .bss : ALIGN(16) {
        __bss = .;
        *(.bss .bss.* .sbss .sbss.*);
        __bss_end = .;
    }

    . = ALIGN(4096);
    . += 16 * 1024 * 1024; /* 16 MB */
    __boot_stack_top = .;

    __free_ram = .;
    . += 64 * 1024 * 1024; /* 64 MB */
    __free_ram_end = .;
}
```
## kernel/arch/riscv64/mod.rs
```
use core::arch::asm;
use core::arch::global_asm;

use arrayvec::ArrayVec;
use csr::StvecMode;
use csr::write_stvec;
use plic::use_plic;
use starina::address::DAddr;
use starina::address::PAddr;
use starina::address::VAddr;
use starina::error::ErrorCode;
use transition::switch_to_kernel;

use crate::BootInfo;
use crate::FreeRam;
use crate::cpuvar::CpuId;

global_asm!(include_str!("boot.S"));

mod cpuvar;
mod csr;
mod idle;
mod interrupt;
mod plic;
mod sbi;
mod thread;
mod transition;
mod vmspace;

pub use cpuvar::CpuVar;
pub use cpuvar::get_cpuvar;
pub use cpuvar::set_cpuvar;
pub use idle::idle;
pub use interrupt::INTERRUPT_CONTROLLER;
pub use thread::Thread;
pub use thread::enter_kernelland;
pub use thread::enter_userland;
pub use vmspace::VmSpace;

pub const PAGE_SIZE: usize = 4096;
pub const NUM_CPUS_MAX: usize = 4;

pub fn halt() -> ! {
    loop {
        unsafe {
            asm!("wfi");
        }
    }
}

pub fn kernel_scope<F, R>(f: F) -> R
where
    F: FnOnce() -> R,
{
    unsafe {
        asm!("csrrw tp, sscratch, tp");
        let ret = f();
        asm!("csrrw tp, sscratch, tp");
        ret
    }
}

pub fn map_daddr(paddr: PAddr) -> Result<DAddr, ErrorCode> {
    // We don't have IOMMU. Device will see the same address as the kernel.
    Ok(DAddr::new(paddr.as_usize()))
}

pub fn unmap_daddr(daddr: DAddr) -> Result<(), ErrorCode> {
    // We don't do anything in map_daddr. Nothing to unmap.
    Ok(())
}

pub fn vaddr2paddr(vaddr: VAddr) -> Result<PAddr, ErrorCode> {
    // Identical mapping.
    // FIXME:
    Ok(PAddr::new(vaddr.as_usize()))
}

pub fn paddr2vaddr(paddr: PAddr) -> Result<VAddr, ErrorCode> {
    // Identical mapping.
    // FIXME:
    Ok(VAddr::new(paddr.as_usize()))
}

pub fn console_write(bytes: &[u8]) {
    for byte in bytes {
        sbi::console_putchar(*byte);
    }
}

unsafe extern "C" {
    static __bss: u8;
    static __bss_end: u8;
    static __free_ram: u8;
    static __free_ram_end: u8;
}

#[unsafe(no_mangle)]
unsafe extern "C" fn riscv64_boot(hartid: u64, dtb: *const u8) -> ! {
    let bss_start = &raw const __bss as usize;
    let bss_end = &raw const __bss_end as usize;
    let free_ram = &raw const __free_ram as usize;
    let free_ram_end = &raw const __free_ram_end as usize;

    // Clear bss.
    unsafe {
        core::ptr::write_bytes(bss_start as *mut u8, 0, bss_end - bss_start);
    }

    let cpu_id = CpuId::new(hartid.try_into().unwrap());

    let mut free_rams = ArrayVec::new();
    free_rams.push(FreeRam {
        addr: free_ram as *mut u8,
        size: free_ram_end - free_ram,
    });

    crate::boot(BootInfo {
        cpu_id,
        free_rams,
        dtb,
    });
}

pub fn percpu_init() {
    unsafe {
        asm!("csrw sscratch, tp");
    }

    unsafe {
        write_stvec(switch_to_kernel as *const () as usize, StvecMode::Direct);

        let mut sie: u64;
        asm!("csrr {}, sie", out(reg) sie);
        sie |= 1 << 1; // SSIE: supervisor-level software interrupts
        sie |= 1 << 5; // STIE: supervisor-level timer interrupts
        sie |= 1 << 9; // SEIE: supervisor-level external interrupts
        asm!("csrw sie, {}", in(reg) sie);
    }

    use_plic(|plic| {
        plic.init_per_cpu(get_cpuvar().cpu_id);
    });
}
```
## kernel/arch/riscv64/plic.rs
```
use alloc::collections::BTreeMap;
use alloc::string::String;
use alloc::vec::Vec;

use starina::device_tree::Reg;
use starina_types::address::PAddr;
use starina_types::error::ErrorCode;
use starina_types::interrupt::Irq;

use crate::arch::get_cpuvar;
use crate::cpuvar::CpuId;
use crate::folio::Folio;
use crate::interrupt::Interrupt;
use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;
use crate::utils::mmio::LittleEndian;
use crate::utils::mmio::MmioFolio;
use crate::utils::mmio::MmioReg;
use crate::utils::mmio::ReadWrite;

const IRQ_MAX: usize = 1024;
const PLIC_SIZE: usize = 0x400000;

// Interrupt Source Priority
// https://github.com/riscv/riscv-plic-spec/blob/master/riscv-plic.adoc#3-interrupt-priorities
fn priority_reg(irq: Irq) -> MmioReg<LittleEndian, ReadWrite, u32> {
    MmioReg::new(4 * (irq.as_raw() as usize))
}

// Interrupt Enable Bits
// https://github.com/riscv/riscv-plic-spec/blob/master/riscv-plic.adoc#5-interrupt-enables
fn enable_reg(irq: Irq) -> MmioReg<LittleEndian, ReadWrite, u32> {
    MmioReg::new(0x2080 + ((irq.as_raw() as usize) / 32 * size_of::<u32>()))
}

/// Interrupt Claim Register
/// https://github.com/riscv/riscv-plic-spec/blob/master/riscv-plic.adoc#7-interrupt-claim-process
fn claim_reg(hart: CpuId) -> MmioReg<LittleEndian, ReadWrite, u32> {
    MmioReg::new(0x201004 + 0x2000 * hart.as_usize())
}

// Priority Threshold
// https://github.com/riscv/riscv-plic-spec/blob/master/riscv-plic.adoc#6-priority-thresholds
fn threshold_reg(hart: CpuId) -> MmioReg<LittleEndian, ReadWrite, u32> {
    MmioReg::new(0x201000 + 0x2000 * hart.as_usize())
}

static PLIC: SpinLock<Option<Plic>> = SpinLock::new(None);

pub fn try_init(compatible: &[String], reg: &[Reg]) -> Result<(), ErrorCode> {
    let mut plic_lock = PLIC.lock();
    if plic_lock.is_some() {
        return Ok(()); // Already initialized.
    }

    if !compatible.iter().any(|s| s == "riscv,plic0") {
        return Err(ErrorCode::NotSupported);
    }

    let plic = Plic::new(reg);
    plic_lock.replace(plic);
    Ok(())
}

pub fn use_plic(f: impl FnOnce(&mut Plic)) {
    let mut plic_lock = PLIC.lock();
    let plic = plic_lock.as_mut().expect("PLIC is not initialized");
    f(plic);
}

pub struct Plic {
    folio: MmioFolio,
    listeners: BTreeMap<Irq, SharedRef<Interrupt>>,
}

impl Plic {
    pub fn new(reg: &[Reg]) -> Self {
        debug_assert!(reg.len() == 1);

        let plic_paddr: usize = reg[0].addr as usize;

        trace!("PLIC: paddr={:#x}", plic_paddr);
        let folio = Folio::alloc_at(PAddr::new(plic_paddr), PLIC_SIZE).unwrap();
        let mmio_folio = MmioFolio::from_folio(folio).unwrap();

        Plic {
            folio: mmio_folio,
            listeners: BTreeMap::new(),
        }
    }

    pub fn init_per_cpu(&mut self, cpu_id: CpuId) {
        // Enable all interrupts by setting the threshold to 0.
        //
        // Note: Don't use cpuvar() here because it's not initialized yet.
        threshold_reg(cpu_id).write(&mut self.folio, 0);
    }

    pub fn get_pending_irq(&mut self) -> Irq {
        let raw_irq = claim_reg(get_cpuvar().cpu_id).read(&mut self.folio);
        Irq::from_raw(raw_irq)
    }

    pub fn enable_irq(&mut self, irq: Irq) {
        assert!((irq.as_raw() as usize) < IRQ_MAX);
        trace!("PLIC: enabling irq={}", irq.as_raw());
        trace!("PLIC priority: {:x}", 4 * (irq.as_raw() as usize));

        priority_reg(irq).write(&mut self.folio, 1);

        let enable = enable_reg(irq);
        let mut value = enable.read(&mut self.folio);
        value |= 1 << ((irq.as_raw() as usize) % 32);
        enable.write(&mut self.folio, value);
    }

    pub fn acknowledge(&mut self, irq: Irq) {
        assert!((irq.as_raw() as usize) < IRQ_MAX);

        claim_reg(get_cpuvar().cpu_id).write(&mut self.folio, irq.as_raw());
    }

    pub fn register_listener(&mut self, irq: Irq, listener: SharedRef<Interrupt>) {
        self.listeners.insert(irq, listener);
    }

    pub fn unregister_listener(&mut self, irq: Irq) {
        self.listeners.remove(&irq);
    }

    pub fn handle_interrupt(&mut self) {
        let irq = self.get_pending_irq();
        if let Some(listener) = self.listeners.get(&irq) {
            listener.trigger().unwrap();
        }
    }
}
```
## kernel/arch/riscv64/sbi.rs
```
use core::arch::asm;

#[allow(non_camel_case_types)]
type c_long = i64;

pub enum Error {
    Unknown(#[allow(unused)] c_long),
}

/// See <https://github.com/riscv-non-isa/riscv-sbi-doc/blob/master/src/binary-encoding.adoc>
#[warn(clippy::too_many_arguments)]
unsafe fn sbi_call(
    a0: c_long,
    a1: c_long,
    a2: c_long,
    a3: c_long,
    a4: c_long,
    a5: c_long,
    fid: c_long,
    eid: c_long,
) -> Result<c_long, Error> {
    let error: c_long;
    let retval: c_long;

    unsafe {
        asm!(
            "ecall",
            inout("a0") a0 => error, inout("a1") a1 => retval, in("a2") a2,
            in("a3") a3, in("a4") a4, in("a5") a5, in("a6") fid, in("a7") eid,
        );
    }

    if error == 0 {
        Ok(retval)
    } else {
        Err(Error::Unknown(error))
    }
}

pub fn console_putchar(c: u8) {
    unsafe {
        let _ = sbi_call(c as c_long, 0, 0, 0, 0, 0, 0, 1);
    }
}
```
## kernel/arch/riscv64/thread.rs
```
use core::alloc::GlobalAlloc;
use core::alloc::Layout;
use core::arch::asm;
use core::arch::naked_asm;
use core::mem::offset_of;

use starina_types::syscall::RetVal;

use crate::allocator::GLOBAL_ALLOCATOR;
use crate::syscall::syscall_inkernel_handler;

/// Context of a thread.
#[derive(Debug, Default)]
#[repr(C, packed)]
pub struct Context {
    pub sepc: u64,
    pub sstatus: u64,
    pub ra: u64,
    pub sp: u64,
    pub gp: u64,
    pub tp: u64,
    pub a0: u64,
    pub a1: u64,
    pub a2: u64,
    pub a3: u64,
    pub a4: u64,
    pub a5: u64,
    pub a6: u64,
    pub a7: u64,
    pub s0: u64,
    pub s1: u64,
    pub s2: u64,
    pub s3: u64,
    pub s4: u64,
    pub s5: u64,
    pub s6: u64,
    pub s7: u64,
    pub s8: u64,
    pub s9: u64,
    pub s10: u64,
    pub s11: u64,
    pub t0: u64,
    pub t1: u64,
    pub t2: u64,
    pub t3: u64,
    pub t4: u64,
    pub t5: u64,
    pub t6: u64,
}

pub struct Thread {
    pub(super) context: Context,
}

impl Thread {
    pub fn new_idle() -> Thread {
        Thread {
            context: Default::default(),
        }
    }

    pub fn new_inkernel(pc: usize, arg: usize) -> Thread {
        let stack_size = 1024 * 1024;
        let stack =
            unsafe { GLOBAL_ALLOCATOR.alloc(Layout::from_size_align(stack_size, 16).unwrap()) };
        let sp = stack as u64 + stack_size as u64;

        let mut sstatus: u64;
        unsafe {
            core::arch::asm!("csrr {}, sstatus", out(reg) sstatus);
        }

        Thread {
            context: Context {
                sepc: pc.try_into().unwrap(),
                sstatus,
                a0: arg.try_into().unwrap(),
                sp,
                ..Default::default()
            },
        }
    }

    pub fn set_retval(&mut self, retval: RetVal) {
        self.context.a0 = retval.as_isize() as u64;
    }
}

#[naked]
#[unsafe(no_mangle)]
pub extern "C" fn enter_kernelland(
    _a0: isize,
    _a1: isize,
    _a2: isize,
    _a3: isize,
    _a4: isize,
    _a5: isize,
) -> RetVal {
    unsafe {
        naked_asm!(
            r#"
                // Disable interrupts in kernel.
                csrci sstatus, 1 << 1

                csrrw tp, sscratch, tp
                ld t0, {context_offset}(tp) // Load CpuVar.arch.context

                // Save general-purpose registers.
                sd sp, {sp_offset}(t0)
                sd gp, {gp_offset}(t0)
                sd s0, {s0_offset}(t0)
                sd s1, {s1_offset}(t0)
                sd s2, {s2_offset}(t0)
                sd s3, {s3_offset}(t0)
                sd s4, {s4_offset}(t0)
                sd s5, {s5_offset}(t0)
                sd s6, {s6_offset}(t0)
                sd s7, {s7_offset}(t0)
                sd s8, {s8_offset}(t0)
                sd s9, {s9_offset}(t0)
                sd s10, {s10_offset}(t0)
                sd s11, {s11_offset}(t0)
                sd ra, {sepc_offset}(t0)

                // Save sstatus.
                csrr t1, sstatus
                sd t1, {sstatus_offset}(t0)

                // Read the original tp temporarily saved in sscratch, and
                // restore the original sscratch value.
                csrrw t1, sscratch, tp
                sd t1, {tp_offset}(t0)

                ld sp, {kernel_sp_offset}(tp)

                // Handle the system call.
                j {syscall_inkernel_handler}
            "#,
            context_offset = const offset_of!(crate::arch::CpuVar, context),
            kernel_sp_offset = const offset_of!(crate::arch::CpuVar, kernel_sp),
            sepc_offset = const offset_of!(Context, sepc),
            sstatus_offset = const offset_of!(Context, sstatus),
            sp_offset = const offset_of!(Context, sp),
            gp_offset = const offset_of!(Context, gp),
            tp_offset = const offset_of!(Context, tp),
            s0_offset = const offset_of!(Context, s0),
            s1_offset = const offset_of!(Context, s1),
            s2_offset = const offset_of!(Context, s2),
            s3_offset = const offset_of!(Context, s3),
            s4_offset = const offset_of!(Context, s4),
            s5_offset = const offset_of!(Context, s5),
            s6_offset = const offset_of!(Context, s6),
            s7_offset = const offset_of!(Context, s7),
            s8_offset = const offset_of!(Context, s8),
            s9_offset = const offset_of!(Context, s9),
            s10_offset = const offset_of!(Context, s10),
            s11_offset = const offset_of!(Context, s11),
            syscall_inkernel_handler = sym syscall_inkernel_handler,
        )
    }
}

pub fn enter_userland(thread: *mut crate::arch::Thread) -> ! {
    let context: *mut Context = unsafe { &mut (*thread).context as *mut _ };
    let mut sstatus: u64;
    unsafe {
        asm!("csrr {0}, sstatus", out(reg) sstatus);
        sstatus |= 1 << 8; // Set SPP to go back to kernel mode
        asm!("csrw sstatus, {0}", in(reg) sstatus);
    }

    unsafe {
        asm!(r#"
            sd a0, {context_offset}(tp) // Update CpuVar.arch.context

            ld a1, {sepc_offset}(a0)
            csrw sepc, a1
            ld a1, {sstatus_offset}(a0) // TODO: unnecessary?

            // Restore general-purpose registers.
            ld ra, {ra_offset}(a0)
            ld sp, {sp_offset}(a0)
            ld gp, {gp_offset}(a0)
            ld tp, {tp_offset}(a0)
            ld t0, {t0_offset}(a0)
            ld t1, {t1_offset}(a0)
            ld t2, {t2_offset}(a0)
            ld s0, {s0_offset}(a0)
            ld s1, {s1_offset}(a0)
            ld a1, {a1_offset}(a0)
            ld a2, {a2_offset}(a0)
            ld a3, {a3_offset}(a0)
            ld a4, {a4_offset}(a0)
            ld a5, {a5_offset}(a0)
            ld a6, {a6_offset}(a0)
            ld a7, {a7_offset}(a0)
            ld s2, {s2_offset}(a0)
            ld s3, {s3_offset}(a0)
            ld s4, {s4_offset}(a0)
            ld s5, {s5_offset}(a0)
            ld s6, {s6_offset}(a0)
            ld s7, {s7_offset}(a0)
            ld s8, {s8_offset}(a0)
            ld s9, {s9_offset}(a0)
            ld s10, {s10_offset}(a0)
            ld s11, {s11_offset}(a0)
            ld t3, {t3_offset}(a0)
            ld t4, {t4_offset}(a0)
            ld t5, {t5_offset}(a0)
            ld t6, {t6_offset}(a0)

            ld a0, {a0_offset}(a0)
            sret
        "#,
            in ("a0") context as usize,
            context_offset = const offset_of!(crate::arch::CpuVar, context),
            sepc_offset = const offset_of!(Context, sepc),
            sstatus_offset = const offset_of!(Context, sstatus),
            ra_offset = const offset_of!(Context, ra),
            sp_offset = const offset_of!(Context, sp),
            gp_offset = const offset_of!(Context, gp),
            tp_offset = const offset_of!(Context, tp),
            t0_offset = const offset_of!(Context, t0),
            t1_offset = const offset_of!(Context, t1),
            t2_offset = const offset_of!(Context, t2),
            s0_offset = const offset_of!(Context, s0),
            s1_offset = const offset_of!(Context, s1),
            a0_offset = const offset_of!(Context, a0),
            a1_offset = const offset_of!(Context, a1),
            a2_offset = const offset_of!(Context, a2),
            a3_offset = const offset_of!(Context, a3),
            a4_offset = const offset_of!(Context, a4),
            a5_offset = const offset_of!(Context, a5),
            a6_offset = const offset_of!(Context, a6),
            a7_offset = const offset_of!(Context, a7),
            s2_offset = const offset_of!(Context, s2),
            s3_offset = const offset_of!(Context, s3),
            s4_offset = const offset_of!(Context, s4),
            s5_offset = const offset_of!(Context, s5),
            s6_offset = const offset_of!(Context, s6),
            s7_offset = const offset_of!(Context, s7),
            s8_offset = const offset_of!(Context, s8),
            s9_offset = const offset_of!(Context, s9),
            s10_offset = const offset_of!(Context, s10),
            s11_offset = const offset_of!(Context, s11),
            t3_offset = const offset_of!(Context, t3),
            t4_offset = const offset_of!(Context, t4),
            t5_offset = const offset_of!(Context, t5),
            t6_offset = const offset_of!(Context, t6),
            options(noreturn)
        );
    }
}
```
## kernel/arch/riscv64/transition.rs
```
use core::arch::naked_asm;
use core::mem::offset_of;

use super::cpuvar::CpuVar;
use super::interrupt::interrupt_handler;
use super::thread::Context;

/// The entry point for traps: exceptions, interrupts, and system calls.
#[naked]
#[repr(align(4))]
pub unsafe extern "C" fn switch_to_kernel() -> ! {
    unsafe {
        naked_asm!(
            r#"
                csrrw tp, sscratch, tp      // Save tp to sscratch and load Cpuvar
                sd a0, {a0_scratch_offset}(tp)
                ld a0, {context_offset}(tp) // Load CpuVar.arch.context

                sd ra, {ra_offset}(a0)
                sd sp, {sp_offset}(a0)
                sd gp, {gp_offset}(a0)
                sd t0, {t0_offset}(a0)
                sd t1, {t1_offset}(a0)
                sd t2, {t2_offset}(a0)
                sd s0, {s0_offset}(a0)
                sd s1, {s1_offset}(a0)
                sd a1, {a1_offset}(a0)
                sd a2, {a2_offset}(a0)
                sd a3, {a3_offset}(a0)
                sd a4, {a4_offset}(a0)
                sd a5, {a5_offset}(a0)
                sd a6, {a6_offset}(a0)
                sd a7, {a7_offset}(a0)
                sd s2, {s2_offset}(a0)
                sd s3, {s3_offset}(a0)
                sd s4, {s4_offset}(a0)
                sd s5, {s5_offset}(a0)
                sd s6, {s6_offset}(a0)
                sd s7, {s7_offset}(a0)
                sd s8, {s8_offset}(a0)
                sd s9, {s9_offset}(a0)
                sd s10, {s10_offset}(a0)
                sd s11, {s11_offset}(a0)
                sd t3, {t3_offset}(a0)
                sd t4, {t4_offset}(a0)
                sd t5, {t5_offset}(a0)
                sd t6, {t6_offset}(a0)

                csrr a1, sepc
                sd a1, {sepc_offset}(a0)
                csrr a1, sstatus
                sd a1, {sstatus_offset}(a0)

                csrrw a1, sscratch, tp
                sd a1, {tp_offset}(a0)

                ld a1, {a0_scratch_offset}(tp)
                sd a1, {a0_offset}(a0)

                ld sp, {kernel_sp_offset}(tp)
                j {interrupt_handler}
            "#,
            context_offset = const offset_of!(CpuVar, context),
            a0_scratch_offset = const offset_of!(CpuVar, a0_scratch),
            kernel_sp_offset = const offset_of!(CpuVar, kernel_sp),
            sepc_offset = const offset_of!(Context, sepc),
            sstatus_offset = const offset_of!(Context, sstatus),
            ra_offset = const offset_of!(Context, ra),
            sp_offset = const offset_of!(Context, sp),
            gp_offset = const offset_of!(Context, gp),
            tp_offset = const offset_of!(Context, tp),
            t0_offset = const offset_of!(Context, t0),
            t1_offset = const offset_of!(Context, t1),
            t2_offset = const offset_of!(Context, t2),
            s0_offset = const offset_of!(Context, s0),
            s1_offset = const offset_of!(Context, s1),
            a0_offset = const offset_of!(Context, a0),
            a1_offset = const offset_of!(Context, a1),
            a2_offset = const offset_of!(Context, a2),
            a3_offset = const offset_of!(Context, a3),
            a4_offset = const offset_of!(Context, a4),
            a5_offset = const offset_of!(Context, a5),
            a6_offset = const offset_of!(Context, a6),
            a7_offset = const offset_of!(Context, a7),
            s2_offset = const offset_of!(Context, s2),
            s3_offset = const offset_of!(Context, s3),
            s4_offset = const offset_of!(Context, s4),
            s5_offset = const offset_of!(Context, s5),
            s6_offset = const offset_of!(Context, s6),
            s7_offset = const offset_of!(Context, s7),
            s8_offset = const offset_of!(Context, s8),
            s9_offset = const offset_of!(Context, s9),
            s10_offset = const offset_of!(Context, s10),
            s11_offset = const offset_of!(Context, s11),
            t3_offset = const offset_of!(Context, t3),
            t4_offset = const offset_of!(Context, t4),
            t5_offset = const offset_of!(Context, t5),
            t6_offset = const offset_of!(Context, t6),
            interrupt_handler = sym interrupt_handler,
        )
    }
}
```
## kernel/arch/riscv64/vmspace.rs
```
use core::arch::asm;
use core::mem;

use starina_types::address::PAddr;
use starina_types::address::VAddr;
use starina_types::error::ErrorCode;
use starina_types::vmspace::PageProtect;
use starina_utils::alignment::is_aligned;

use crate::arch::PAGE_SIZE;
use crate::arch::paddr2vaddr;
use crate::folio::Folio;
use crate::spinlock::SpinLock;

const ENTRIES_PER_TABLE: usize = 512;
const PPN_SHIFT: usize = 12;

const PTE_V: u64 = 1 << 0;
const PTE_R: u64 = 1 << 1;
const PTE_W: u64 = 1 << 2;
const PTE_X: u64 = 1 << 3;
const PTE_U: u64 = 1 << 4;
const PTE_PPN_SHIFT: usize = 10;

const SATP_MODE_SV48: u64 = 9 << 60;

pub const USERSPACE_START: VAddr = VAddr::new(0x0000_000a_0000_0000);
pub const USERSPACE_END: VAddr = VAddr::new(0x0000_000a_ffff_ffff);
const VALLOC_START: VAddr = VAddr::new(0x0000_000b_0000_0000);
const VALLOC_END: VAddr = VAddr::new(0x0000_000b_ffff_ffff);

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
#[repr(transparent)]
struct Entry(u64);

impl Entry {
    pub fn new(paddr: PAddr, flags: u64) -> Self {
        assert!(is_aligned(paddr.as_usize(), PAGE_SIZE));

        let ppn = paddr.as_usize() as u64 >> PPN_SHIFT;
        Self(ppn << PTE_PPN_SHIFT | flags)
    }

    pub fn is_valid(&self) -> bool {
        self.0 & PTE_V != 0
    }

    pub fn is_leaf(&self) -> bool {
        self.0 & (PTE_R | PTE_W | PTE_X) != 0
    }

    pub fn ppn(&self) -> u64 {
        self.0 >> PTE_PPN_SHIFT
    }

    pub fn paddr(&self) -> PAddr {
        let raw = self.ppn() << PPN_SHIFT;
        PAddr::new(raw as usize)
    }
}

#[repr(transparent)]
struct Table([Entry; ENTRIES_PER_TABLE]);

impl Table {
    pub fn get_mut_by_vaddr(&mut self, vaddr: VAddr, level: usize) -> &mut Entry {
        let index = (vaddr.as_usize() >> (12 + 9 * level)) & 0x1ff;
        &mut self.0[index]
    }
}

fn is_large_page_aligned(
    vaddr: VAddr,
    paddr: PAddr,
    remaining: usize,
    level: usize,
) -> Option<usize> {
    let page_size = match level {
        1 => 2 * 1024 * 1024,        // 2MiB pages (level 1)
        2 => 1 * 1024 * 1024 * 1024, // 1GiB pages (level 2)
        3 => return None,            // Not supported in Sv48
        _ => unreachable!(),
    };

    if page_size > remaining {
        return None;
    }

    if !is_aligned(vaddr.as_usize(), page_size) {
        return None;
    }

    if !is_aligned(paddr.as_usize(), page_size) {
        return None;
    }

    Some(page_size)
}

struct PageTable {
    l0_table: Folio,
}

impl PageTable {
    pub fn new() -> Result<PageTable, ErrorCode> {
        let l0_table = Folio::alloc(size_of::<Table>())?;
        let mut table = PageTable { l0_table };
        table.map_kernel_space()?;
        Ok(table)
    }

    // FIXME: Move to machine-specific code.
    pub fn map_kernel_space(&mut self) -> Result<(), ErrorCode> {
        // Kernel memory
        self.do_map(
            VAddr::new(0x8020_0000),
            PAddr::new(0x8020_0000),
            0x8ff00000 - 0x8020_0000,
            PageProtect::READABLE | PageProtect::WRITEABLE | PageProtect::EXECUTABLE,
            true,
        )?;
        // PLIC
        self.do_map(
            VAddr::new(0x0c00_0000),
            PAddr::new(0x0c00_0000),
            0x400000,
            PageProtect::READABLE | PageProtect::WRITEABLE,
            true,
        )?;
        // UART
        self.do_map(
            VAddr::new(0x1000_0000),
            PAddr::new(0x1000_0000),
            0x1000,
            PageProtect::READABLE | PageProtect::WRITEABLE,
            true,
        )?;
        Ok(())
    }

    pub fn map(
        &mut self,
        vaddr: VAddr,
        paddr: PAddr,
        len: usize,
        prot: PageProtect,
    ) -> Result<(), ErrorCode> {
        self.do_map(vaddr, paddr, len, prot, false)
    }

    pub fn do_map(
        &mut self,
        vaddr: VAddr,
        paddr: PAddr,
        len: usize,
        prot: PageProtect,
        allow_large_pages: bool,
    ) -> Result<(), ErrorCode> {
        // trace!("map: {:08x} -> {:08x}", vaddr.as_usize(), paddr.as_usize());
        assert!(is_aligned(vaddr.as_usize(), PAGE_SIZE));
        assert!(is_aligned(paddr.as_usize(), PAGE_SIZE));
        assert!(is_aligned(len, PAGE_SIZE));

        let mut offset = 0;
        while offset < len {
            let remaining = len - offset;
            let page_size = self.map_page(
                vaddr.add(offset),
                paddr.add(offset),
                prot,
                remaining,
                allow_large_pages,
            )?;
            offset += page_size;
        }

        // FIXME: Invalidate TLB
        Ok(())
    }

    fn paddr2table(&mut self, paddr: PAddr) -> Result<&mut Table, ErrorCode> {
        let vaddr = paddr2vaddr(paddr)?;
        Ok(unsafe { &mut *vaddr.as_mut_ptr() })
    }

    fn map_page(
        &mut self,
        vaddr: VAddr,
        paddr: PAddr,
        prot: PageProtect,
        remaining: usize,
        allow_large_pages: bool,
    ) -> Result<usize, ErrorCode> {
        assert!(is_aligned(vaddr.as_usize(), PAGE_SIZE));
        assert!(is_aligned(paddr.as_usize(), PAGE_SIZE));

        let mut leaf_flags = PTE_V;
        if prot.contains(PageProtect::READABLE) {
            leaf_flags |= PTE_R;
        }
        if prot.contains(PageProtect::WRITEABLE) {
            leaf_flags |= PTE_W;
        }
        if prot.contains(PageProtect::EXECUTABLE) {
            leaf_flags |= PTE_X;
        }
        if prot.contains(PageProtect::USER) {
            leaf_flags |= PTE_U;
        }

        if leaf_flags & (PTE_R | PTE_W | PTE_X) == 0 {
            // Invalid leaf entry pattern: this does not mean an inaccessible leaf page,
            // but it is a pointer to the next level table!
            debug_warn!(
                "map_page: {:08x} -> {:08x} has no permissions",
                vaddr.as_usize(),
                paddr.as_usize()
            );
            return Err(ErrorCode::InvalidArg);
        }

        let mut table = self.paddr2table(self.l0_table.paddr())?;
        for level in (1..=3).rev() {
            let entry = table.get_mut_by_vaddr(vaddr, level);
            if !entry.is_valid() {
                if allow_large_pages {
                    if let Some(page_size) = is_large_page_aligned(vaddr, paddr, remaining, level) {
                        // Allocate a large page.
                        *entry = Entry::new(paddr, PTE_V | leaf_flags);
                        return Ok(page_size);
                    }
                }

                // Allocate a new table.
                let new_table = Folio::alloc(size_of::<Table>())?;
                *entry = Entry::new(new_table.paddr(), PTE_V);

                // This vmspace object owns the allocated folio.
                // TODO: deallocate on Drop
                mem::forget(new_table);
            }

            if entry.is_leaf() {
                return Err(ErrorCode::AlreadyMapped);
            }

            // Traverse to the next table.
            let next_table_paddr = entry.paddr();
            table = self.paddr2table(next_table_paddr)?;
        }

        let entry = table.get_mut_by_vaddr(vaddr, 0);
        if entry.is_valid() {
            return Err(ErrorCode::AlreadyMapped);
        }

        *entry = Entry::new(paddr, leaf_flags);
        Ok(4096)
    }
}

struct VAlloc {
    next_vaddr: VAddr,
}

impl VAlloc {
    pub const fn new() -> VAlloc {
        VAlloc {
            next_vaddr: VALLOC_START,
        }
    }

    pub fn alloc(&mut self, len: usize) -> Result<VAddr, ErrorCode> {
        let vaddr = self.next_vaddr;
        if vaddr.add(len) > VALLOC_END {
            return Err(ErrorCode::TooLarge);
        }

        self.next_vaddr = vaddr.add(len);
        Ok(vaddr)
    }
}

struct Mutable {
    table: PageTable,
    valloc: VAlloc,
}

pub struct VmSpace {
    mutable: SpinLock<Mutable>,
    satp: u64,
}

impl VmSpace {
    pub fn new() -> Result<VmSpace, ErrorCode> {
        let mut table = PageTable::new()?;
        let table_paddr = table.l0_table.paddr().as_usize() as u64;
        let satp = SATP_MODE_SV48 | (table_paddr >> PPN_SHIFT);
        Ok(VmSpace {
            satp,
            mutable: SpinLock::new(Mutable {
                table,
                valloc: VAlloc::new(),
            }),
        })
    }

    pub fn map_fixed(
        &self,
        vaddr: VAddr,
        paddr: PAddr,
        len: usize,
        prot: PageProtect,
    ) -> Result<(), ErrorCode> {
        self.mutable.lock().table.map(vaddr, paddr, len, prot)
    }

    pub fn map_anywhere(
        &self,
        paddr: PAddr,
        len: usize,
        prot: PageProtect,
    ) -> Result<VAddr, ErrorCode> {
        assert!(is_aligned(len, PAGE_SIZE));

        let mut mutable = self.mutable.lock();
        let vaddr = mutable.valloc.alloc(len)?;
        mutable.table.map(vaddr, paddr, len, prot)?;
        Ok(vaddr)
    }

    pub fn switch(&self) {
        unsafe {
            // Do sfeence.vma before and even before switching the page
            // table to ensure all changes prior to this switch are visible.
            //
            // (The RISC-V Instruction Set Manual Volume II, Version 1.10, p. 58)
            asm!("
                sfence.vma
                csrw satp, {}
                sfence.vma
            ", in(reg) self.satp);
        }
    }
}
```
## kernel/channel.rs
```
use alloc::collections::vec_deque::VecDeque;
use alloc::vec::Vec;
use core::fmt;

use arrayvec::ArrayVec;
use starina::message::MESSAGE_DATA_LEN_MAX;
use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
use starina_types::message::MESSAGE_NUM_HANDLES_MAX;
use starina_types::message::MessageInfo;
use starina_types::poll::Readiness;

use crate::cpuvar::current_thread;
use crate::handle::AnyHandle;
use crate::handle::HandleTable;
use crate::handle::Handleable;
use crate::isolation::IsolationHeap;
use crate::isolation::IsolationHeapMut;
use crate::poll::Listener;
use crate::poll::ListenerSet;
use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;

pub const MESSAGE_QUEUE_MAX_LEN: usize = 128;

/// A message queue entry.
struct MessageEntry {
    msginfo: MessageInfo,
    data: Vec<u8>,
    handles: ArrayVec<AnyHandle, MESSAGE_NUM_HANDLES_MAX>,
}

/// Channel object fields that are mutable.
struct Mutable {
    /// The peer channel. If it's `None`, the peer is not connected anymore
    /// and sending a message will fail.
    peer: Option<SharedRef<Channel>>,
    /// The received message queue.
    queue: VecDeque<MessageEntry>,
    listeners: ListenerSet,
}

impl Mutable {
    pub fn new() -> Self {
        Self {
            peer: None,
            queue: VecDeque::new(),
            listeners: ListenerSet::new(),
        }
    }
}

pub struct Channel {
    mutable: SpinLock<Mutable>,
}

impl Channel {
    /// Creates a channel pair.
    pub fn new() -> Result<(SharedRef<Channel>, SharedRef<Channel>), ErrorCode> {
        let ch0 = SharedRef::new(Channel {
            mutable: SpinLock::new(Mutable::new()),
        })?;
        let ch1 = SharedRef::new(Channel {
            mutable: SpinLock::new(Mutable::new()),
        })?;

        // TODO: Can we avoid this mutate-after-construct?
        ch0.mutable.lock().peer = Some(ch1.clone());
        ch1.mutable.lock().peer = Some(ch0.clone());

        Ok((ch0, ch1))
    }

    pub fn do_send(
        &self,
        msginfo: MessageInfo,
        msgbuffer: Vec<u8>,
        handles: ArrayVec<AnyHandle, MESSAGE_NUM_HANDLES_MAX>,
    ) -> Result<(), ErrorCode> {
        debug_assert_eq!(msgbuffer.len(), msginfo.data_len());
        debug_assert_eq!(msginfo.num_handles(), handles.len());

        let mutable = self.mutable.lock();
        let peer_ch = mutable.peer.as_ref().ok_or(ErrorCode::NoPeer)?;
        let mut peer_mutable = peer_ch.mutable.lock();

        // Check if the peer's queue is full.
        if peer_mutable.queue.len() >= MESSAGE_QUEUE_MAX_LEN {
            return Err(ErrorCode::Full);
        }

        // Allocate space for the message in the peer's queue so that
        // `VecDeque::push_back` won't panic.
        if peer_mutable.queue.try_reserve_exact(1).is_err() {
            return Err(ErrorCode::OutOfMemory);
        }

        // The message is ready to be sent. Enqueue it.
        peer_mutable.queue.push_back(MessageEntry {
            msginfo,
            data: msgbuffer,
            handles: handles,
        });

        // So the peer has at least one message to read. Wake up a listener if any.
        peer_mutable.listeners.notify_all(Readiness::READABLE);
        Ok(())
    }

    pub fn send(
        &self,
        handle_table: &mut HandleTable,
        msginfo: MessageInfo,
        msgbuffer: &IsolationHeap,
        handles: &IsolationHeap,
    ) -> Result<(), ErrorCode> {
        let current_thread = current_thread();
        let isolation = current_thread.process().isolation();

        if msginfo.data_len() > MESSAGE_DATA_LEN_MAX {
            debug_warn!("too large message data: {}", msginfo.data_len());
            return Err(ErrorCode::TooLarge);
        }

        // Copy message data into the kernel memory. Do this before locking
        // the peer channel for better performance. This memory copy might
        // take a long time.
        let data = msgbuffer.read_to_vec(isolation, 0, msginfo.data_len())?;

        // Move handles.
        //
        // In this phase, since we don't know the receiver process, we don't
        // move to the desination process, but keep ownership of them (AnyHandle)
        // in the message entry.
        let num_handles = msginfo.num_handles();
        let mut moved_handles = ArrayVec::new();
        if num_handles > 0 {
            // Note: Don't release this lock until we've moved all handles
            //       to guarantee that the second loop never fails.

            // First loop: make sure moving handles won't fail and there are
            //             not too many ones.
            let mut handle_ids: ArrayVec<HandleId, MESSAGE_NUM_HANDLES_MAX> = ArrayVec::new();
            for i in 0..num_handles {
                let handle_id = handles.read(isolation, i * size_of::<HandleId>())?;

                // SAFETY: unwrap() won't panic because it should have enough
                //         capacity up to MESSAGE_HANDLES_MAX_COUNT.
                handle_ids.try_push(handle_id).unwrap();

                if !handle_table.is_movable(handle_id) {
                    return Err(ErrorCode::HandleNotMovable);
                }
            }

            // Second loop: Remove handles from the current process.
            for i in 0..num_handles {
                // Note: Don't read the handle from the buffer again - user
                //       might have changed it.
                let handle_id = handle_ids[i];

                // SAFETY: unwrap() won't panic because we've checked the handle
                //         is movable in the previous loop.
                let handle = handle_table.take(handle_id).unwrap();

                // SAFETY: unwrap() won't panic because `handles` should have
                //         enough capacity up to MESSAGE_NUM_HANDLES_MAX.
                moved_handles.try_push(handle).unwrap();
            }
        }

        self.do_send(msginfo, data, moved_handles)?;
        Ok(())
    }

    pub fn recv(
        self: &SharedRef<Channel>,
        handle_table: &mut HandleTable,
        msgbuffer: &mut IsolationHeapMut,
        handles: &mut IsolationHeapMut,
    ) -> Result<MessageInfo, ErrorCode> {
        let current_thread = current_thread();
        let isolation = current_thread.process().isolation();
        let mut entry = {
            let mut mutable = self.mutable.lock();
            let entry = match mutable.queue.pop_front() {
                Some(entry) => entry,
                None => {
                    // Check if the peer is still connected only if the queue is
                    // empty. This is to allow the peer to close the channel before
                    // waiting for us to read all messages.
                    return if mutable.peer.is_some() {
                        // We have no message to read *for now*. The peer might
                        // send a message later.
                        Err(ErrorCode::Empty)
                    } else {
                        // We'll never receive a message anymore. Tell the caller
                        // that you're done.
                        Err(ErrorCode::NoPeer)
                    };
                }
            };

            if !mutable.queue.is_empty() {
                // There are more messages in the queue. Mark this channel as
                // still readable.
                mutable.listeners.notify_all(Readiness::READABLE);
            }

            if let Some(peer) = &mutable.peer {
                // The peer is still connected. Notify the peer channel's
                // listeners that we're ready to receive at least one message.
                peer.mutable
                    .lock()
                    .listeners
                    .notify_all(Readiness::WRITABLE);
            }

            entry
        };

        // Install handles into the current (receiver) process.
        for (i, any_handle) in entry.handles.drain(..).enumerate() {
            // TODO: Define the expected behavior when it fails to add a handle.
            let handle_id = handle_table.insert(any_handle)?;
            handles.write(isolation, i * size_of::<HandleId>(), handle_id)?;
        }

        // Copy message data into the buffer.
        msgbuffer.write_bytes(isolation, 0, &entry.data[0..entry.msginfo.data_len()])?;

        Ok(entry.msginfo)
    }
}

impl Handleable for Channel {
    fn close(&self) {
        let mutable = self.mutable.lock();
        if let Some(peer) = &mutable.peer {
            peer.mutable.lock().peer = None;
        }
    }

    fn add_listener(&self, listener: Listener) -> Result<(), ErrorCode> {
        self.mutable.lock().listeners.add_listener(listener)?;
        Ok(())
    }

    fn remove_listener(&self, poll: &crate::poll::Poll) -> Result<(), ErrorCode> {
        self.mutable.lock().listeners.remove_listener(poll);
        Ok(())
    }

    fn readiness(&self) -> Result<Readiness, ErrorCode> {
        let mut readiness = Readiness::new();
        let mutable = self.mutable.lock();
        if !mutable.queue.is_empty() {
            readiness |= Readiness::READABLE;
        }

        if let Some(peer) = mutable.peer.as_ref() {
            let peer_mutable = peer.mutable.lock();
            if peer_mutable.queue.len() < MESSAGE_QUEUE_MAX_LEN {
                readiness |= Readiness::WRITABLE;
            }
        }

        Ok(readiness)
    }
}

impl fmt::Debug for Channel {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "Channel")
    }
}
```
## kernel/cpuvar.rs
```
//! Per-CPU variables.
use core::cell::Ref;
use core::cell::RefCell;
use core::fmt;

use arrayvec::ArrayVec;

use crate::arch;
use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;
use crate::thread::Thread;

/// CPU identifier.
///
/// Do not confuse with CPUID instruction in x64!
#[derive(Clone, Copy, PartialEq, Eq, Hash, Debug)]
pub struct CpuId(pub u8);

impl CpuId {
    pub const fn new(id: u8) -> CpuId {
        CpuId(id)
    }

    pub fn as_usize(self) -> usize {
        self.0 as usize
    }
}

impl fmt::Display for CpuId {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        write!(f, "#{}", self.0)
    }
}

/// Per-CPU variables.
///
/// It's `#[repr(C)]` to guarantee the arch's `CpuVar` comes first and the
/// addresses of both `arch::CpuVar` and this `CpuVar` are the same for
/// convenience.
#[repr(C)]
pub struct CpuVar {
    pub arch: arch::CpuVar,
    pub cpu_id: CpuId,
    pub current_thread: RefCell<SharedRef<Thread>>,
    pub idle_thread: SharedRef<Thread>,
}

// SAFETY: `CpuVar` is a per-CPU storage. Will never be shared between CPUs
//         and thus won't be accessed at once.
unsafe impl Sync for CpuVar {}

/// A dirty workaround to make `CpuVar` Send-able only when initializing it.
/// This is because in `percpu_init`, we'll initialize cpu vars for other
/// CPUs too.
#[repr(transparent)]
struct CpuVarInit(CpuVar);

unsafe impl Send for CpuVarInit {}

pub fn current_thread() -> Ref<'static, SharedRef<Thread>> {
    arch::get_cpuvar().current_thread.borrow()
}

// Note: SpinLock is to serialize its initialization. Once initialized, it's
//       safe to access `CpuVar` without holding the lock because it's a
//       per-CPU storage. We still need a RefCell in mutable fields though.
static CPUVARS: SpinLock<ArrayVec<CpuVarInit, { arch::NUM_CPUS_MAX }>> =
    SpinLock::new(ArrayVec::new_const());

/// Initializes Per-CPU variables for the current CPU.
pub fn percpu_init(cpu_id: CpuId) {
    let mut cpuvars = CPUVARS.lock();
    let index = cpu_id.as_usize();
    if cpuvars.len() <= index {
        // Initialize CpuVar slots until the CPU.
        for _ in 0..=index {
            let idle_thread = Thread::new_idle().expect("failed to create an idle thread");
            let cpuvar = CpuVar {
                arch: arch::CpuVar::new(&idle_thread),
                cpu_id,
                current_thread: RefCell::new(idle_thread.clone()),
                idle_thread,
            };

            if cpuvars.try_push(CpuVarInit(cpuvar)).is_err() {
                panic!("too many CPUs");
            }
        }
    }

    arch::set_cpuvar(&mut cpuvars[cpu_id.as_usize()].0 as *mut CpuVar);
}
```
## kernel/device_tree.rs
```
use alloc::borrow::ToOwned;
use alloc::string::String;
use alloc::vec;
use alloc::vec::Vec;
use core::slice;

use fdt_rs::base::*;
use fdt_rs::index::DevTreeIndex;
use fdt_rs::prelude::*;
use fdt_rs::spec::fdt_header;
use hashbrown::HashMap;
use starina::device_tree::BusNode;
use starina::device_tree::DeviceNode;
use starina::device_tree::DeviceTree;
use starina::device_tree::Reg;
use starina::interrupt::IrqMatcher;

use crate::arch::INTERRUPT_CONTROLLER;

fn stringlist_to_vec(
    prop: &fdt_rs::index::DevTreeIndexProp<'_, '_, '_>,
) -> Result<Vec<String>, fdt_rs::error::DevTreeError> {
    let mut values = Vec::new();
    let mut iter = prop.iter_str();
    while let Some(s) = iter.next()? {
        values.push(s.to_owned());
    }

    Ok(values)
}

fn parse_reg(
    regs: &mut Vec<Reg>,
    prop: &fdt_rs::index::DevTreeIndexProp<'_, '_, '_>,
    found_bus: &mut FoundBus,
) -> Result<(), fdt_rs::error::DevTreeError> {
    let mut i = 0;
    loop {
        if prop.u32(i).is_err() {
            // End of the regs.
            break;
        }

        let addr = match found_bus.address_cells {
            1 => prop.u32(i)? as u64,
            2 => {
                let high = prop.u32(i)? as u64;
                let low = prop.u32(i + 1)? as u64;
                (high << 32) | low
            }
            _ => {
                panic!("unsupported address cells: {}", found_bus.address_cells);
            }
        };
        i += found_bus.address_cells as usize;

        let size = match found_bus.size_cells {
            1 => prop.u32(i)? as u64,
            2 => {
                let high = prop.u32(i)? as u64;
                let low = prop.u32(i + 1)? as u64;
                (high << 32) | low
            }
            _ => {
                panic!("unsupported size cells: {}", found_bus.size_cells);
            }
        };
        i += found_bus.size_cells as usize;

        regs.push(Reg { addr, size });
    }

    Ok(())
}

#[derive(Debug)]
struct FoundBus {
    is_referenced: bool,
    bus: BusNode,
    address_cells: u32,
    size_cells: u32,
}

#[derive(Debug)]
struct FoundInterruptController {
    name: String,
    is_compatible: bool,
    interrupt_cells: u32,
}

pub fn parse(dtb: *const u8) -> Result<DeviceTree, fdt_rs::error::DevTreeError> {
    let devtree = unsafe {
        // Check  the magic number and read the size of the device tree.
        let dtb_magic = { slice::from_raw_parts(dtb, size_of::<fdt_header>()) };
        let size = DevTree::read_totalsize(dtb_magic)?;

        // Parse the device tree.
        let dtb = { slice::from_raw_parts(dtb, size) };
        DevTree::new(dtb)?
    };

    let layout = DevTreeIndex::get_layout(&devtree)?;
    let mut vec = vec![0u8; layout.size() + layout.align()];
    let devtree_index = DevTreeIndex::new(devtree, vec.as_mut_slice())?;

    // Enumerate all buses.
    let mut found_buses = HashMap::new();
    for node in devtree_index.nodes() {
        let node_name = node.name()?;
        let mut compatible = None;
        let mut address_cells = None;
        let mut size_cells = None;

        for prop in node.props() {
            let prop_name = prop.name()?;
            match prop_name {
                "compatible" => {
                    compatible = Some(stringlist_to_vec(&prop)?);
                }
                "#address-cells" => {
                    let value = prop.u32(0)?;
                    address_cells = Some(value);
                }
                "#size-cells" => {
                    let value = prop.u32(0)?;
                    size_cells = Some(value);
                }
                _ => {}
            }
        }

        let Some(compatible) = compatible else {
            continue;
        };
        let Some(address_cells) = address_cells else {
            continue;
        };
        let Some(size_cells) = size_cells else {
            continue;
        };

        if compatible.iter().any(|c| c == "simple-bus") {
            found_buses.insert(
                node_name.to_owned(),
                FoundBus {
                    is_referenced: false,
                    bus: BusNode::NoMmu,
                    address_cells,
                    size_cells,
                },
            );
        }
    }

    // Enumerate all interrupt controllers.
    let mut found_intcs = HashMap::new();
    for node in devtree_index.nodes() {
        let Some(parent_name) = node.parent().and_then(|p| p.name().ok()) else {
            continue;
        };

        let Some(found_bus) = found_buses.get_mut(parent_name) else {
            // Not connected to a bus.
            continue;
        };

        let node_name = node.name()?;
        let mut is_interrupt_controller = false;
        let mut interrupt_cells = None;
        let mut compatible = Vec::new();
        let mut reg = Vec::new();
        let mut phandle = None;
        for prop in node.props() {
            let prop_name = prop.name()?;
            match prop_name {
                "compatible" => {
                    compatible = stringlist_to_vec(&prop)?;
                }
                "reg" => {
                    parse_reg(&mut reg, &prop, found_bus)?;
                }
                "interrupt-controller" => {
                    is_interrupt_controller = true;
                }
                "#interrupt-cells" => {
                    interrupt_cells = Some(prop.u32(0)?);
                }
                "phandle" => {
                    phandle = Some(prop.u32(0)?);
                }
                _ => {}
            }
        }

        if !is_interrupt_controller {
            continue;
        }

        let Some(phandle) = phandle else {
            continue;
        };

        let Some(interrupt_cells) = interrupt_cells else {
            continue;
        };

        if compatible.is_empty() {
            continue;
        }

        let is_compatible = INTERRUPT_CONTROLLER.try_init(&compatible, &reg).is_ok();
        found_intcs.insert(
            phandle,
            FoundInterruptController {
                name: node_name.to_owned(),
                is_compatible,
                interrupt_cells,
            },
        );
    }

    // Enumerate all devices.
    let mut devices = HashMap::new();
    for node in devtree_index.nodes() {
        let Some(parent_name) = node.parent().and_then(|p| p.name().ok()) else {
            continue;
        };

        let Some(found_bus) = found_buses.get_mut(parent_name) else {
            // Not connected to a bus.
            continue;
        };

        let node_name = node.name()?;
        let mut compatible = Vec::new();
        let mut reg = Vec::new();
        let mut interrupts = Vec::new();
        for prop in node.props() {
            let prop_name = prop.name()?;
            match prop_name {
                "compatible" => {
                    let mut iter = prop.iter_str();
                    while let Some(s) = iter.next()? {
                        compatible.push(s.to_owned());
                    }
                }
                "reg" => {
                    parse_reg(&mut reg, &prop, found_bus)?;
                }
                "interrupts" => {
                    let mut cell = Vec::new();
                    for i in 0.. {
                        if let Ok(value) = prop.u32(i) {
                            cell.push(value);
                        } else {
                            break;
                        }
                    }

                    let irq_matcher = match INTERRUPT_CONTROLLER.parse_interrupts_cell(&cell) {
                        Ok(irq) => irq,
                        Err(e) => {
                            panic!("{}: failed to parse interrupts cell: {:?}", node_name, e);
                        }
                    };

                    interrupts.push(irq_matcher);
                }
                "interrupt-parent" => {
                    let value = prop.phandle(0)?;
                    let Some(intc) = found_intcs.get_mut(&value) else {
                        panic!("{}: interrupt parent not found: {}", node_name, value);
                    };

                    if !intc.is_compatible {
                        warn!(
                            "{}: unsupported interrupt controller ({})",
                            node_name, intc.name
                        );
                    }
                }
                _ => {}
            }
        }

        found_bus.is_referenced = true;
        devices.insert(
            node_name.to_owned(),
            DeviceNode {
                compatible,
                bus: parent_name.to_owned(),
                reg,
                interrupts,
            },
        );
    }

    let mut buses = HashMap::new();
    for (name, bus) in found_buses {
        if bus.is_referenced {
            buses.insert(name, bus.bus);
        }
    }

    Ok(DeviceTree { devices, buses })
}
```
## kernel/folio.rs
```
//! Folio, a physically-contiguous memory region.
use core::alloc::GlobalAlloc;
use core::alloc::Layout;

use starina::address::DAddr;
use starina::error::ErrorCode;
use starina::poll::Readiness;
use starina_types::address::PAddr;
use starina_types::address::VAddr;
use starina_utils::alignment::is_aligned;

use crate::allocator::GLOBAL_ALLOCATOR;
use crate::arch;
use crate::arch::PAGE_SIZE;
use crate::arch::vaddr2paddr;
use crate::handle::Handleable;
use crate::poll::Listener;
use crate::poll::Poll;

pub struct Folio {
    paddr: PAddr,
    daddr: Option<DAddr>,
    len: usize,
}

impl Folio {
    pub fn alloc(len: usize) -> Result<Folio, ErrorCode> {
        if len == 0 || !is_aligned(len, PAGE_SIZE) {
            return Err(ErrorCode::InvalidArg);
        }

        let layout = match Layout::from_size_align(len, PAGE_SIZE) {
            Ok(layout) => layout,
            Err(_) => {
                return Err(ErrorCode::InvalidArg);
            }
        };

        // SAFETY: `len` is not zero as checked above.
        let ptr = unsafe { GLOBAL_ALLOCATOR.alloc(layout) };

        // Fill the allocated memory with zeros.
        unsafe {
            core::ptr::write_bytes(ptr, 0, len);
        }

        let folio = Self {
            paddr: vaddr2paddr(VAddr::new(ptr as usize)).unwrap(),
            daddr: None,
            len,
        };

        Ok(folio)
    }

    pub fn alloc_for_device(len: usize) -> Result<Folio, ErrorCode> {
        let mut folio = Self::alloc(len)?;
        let daddr = arch::map_daddr(folio.paddr())?;
        folio.daddr = Some(daddr);
        Ok(folio)
    }

    pub fn alloc_at(paddr: PAddr, len: usize) -> Result<Folio, ErrorCode> {
        if len == 0 || !is_aligned(len, PAGE_SIZE) {
            return Err(ErrorCode::InvalidArg);
        }

        if !is_aligned(paddr.as_usize(), PAGE_SIZE) {
            return Err(ErrorCode::InvalidArg);
        }

        // TODO: Make sure the paddr range is not owned by any other folio.
        // TODO: Check if the paddr is mappable - should not point to the kernel memory.

        let folio = Self {
            paddr,
            daddr: None,
            len,
        };

        Ok(folio)
    }

    pub fn len(&self) -> usize {
        self.len
    }

    pub fn paddr(&self) -> PAddr {
        self.paddr
    }

    pub fn daddr(&self) -> Option<DAddr> {
        self.daddr
    }
}

impl Drop for Folio {
    fn drop(&mut self) {
        if let Some(daddr) = self.daddr {
            if let Err(e) = arch::unmap_daddr(daddr) {
                debug_warn!("failed to unmap daddr: {:?}", e);
            }
        }
    }
}

impl Handleable for Folio {
    fn close(&self) {
        // Do nothing
    }

    fn add_listener(&self, _listener: Listener) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }

    fn remove_listener(&self, _poll: &Poll) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }

    fn readiness(&self) -> Result<Readiness, ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }
}
```
## kernel/handle.rs
```
use alloc::collections::btree_map::BTreeMap;
use core::any::Any;
use core::ops::Deref;

use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
use starina_types::handle::HandleRights;
use starina_types::poll::Readiness;

use crate::poll::Listener;
use crate::poll::Poll;
use crate::refcount::SharedRef;

const NUM_HANDLES_MAX: usize = 128;

/// Handle, a reference-counted pointer to a kernel object with allowed
/// operations on it, aka *"capability"*.
pub struct Handle<T: Handleable + ?Sized> {
    object: SharedRef<T>,
    rights: HandleRights,
}

impl<T: Handleable + ?Sized> Handle<T> {
    pub fn new(object: SharedRef<T>, rights: HandleRights) -> Handle<T> {
        Handle { object, rights }
    }

    pub fn into_object(self) -> SharedRef<T> {
        self.object
    }

    pub fn is_capable(&self, required: HandleRights) -> bool {
        self.rights.is_capable(required)
    }
}

impl<T: Handleable + ?Sized> Deref for Handle<T> {
    type Target = SharedRef<T>;

    fn deref(&self) -> &SharedRef<T> {
        &self.object
    }
}

impl<T: Handleable + ?Sized> Clone for Handle<T> {
    fn clone(&self) -> Self {
        Handle {
            object: self.object.clone(),
            rights: self.rights,
        }
    }
}

#[derive(Clone)]
pub struct AnyHandle(Handle<dyn Handleable>);

impl AnyHandle {
    pub fn downcast<T: Handleable>(self) -> Option<Handle<T>> {
        let object = self.0.object.downcast().ok()?;
        let rights = self.0.rights;
        Some(Handle { object, rights })
    }
}

impl<T: Handleable> From<Handle<T>> for AnyHandle {
    fn from(h: Handle<T>) -> AnyHandle {
        Self(Handle {
            object: h.object, // upcasting happens here (thanks to CoerceUnsized)
            rights: h.rights,
        })
    }
}

impl Deref for AnyHandle {
    type Target = dyn Handleable;

    fn deref(&self) -> &Self::Target {
        &**self.0
    }
}
pub trait Handleable: Any + Send + Sync {
    fn close(&self);
    fn add_listener(&self, listener: Listener) -> Result<(), ErrorCode>;
    fn remove_listener(&self, poll: &Poll) -> Result<(), ErrorCode>;
    fn readiness(&self) -> Result<Readiness, ErrorCode>;
}

pub struct HandleTable {
    handles: BTreeMap<HandleId, AnyHandle>,
    next_id: i32,
}

impl HandleTable {
    pub const fn new() -> HandleTable {
        HandleTable {
            handles: BTreeMap::new(),
            next_id: 1,
        }
    }

    pub fn insert<H: Into<AnyHandle>>(&mut self, object: H) -> Result<HandleId, ErrorCode> {
        if self.handles.len() >= NUM_HANDLES_MAX {
            return Err(ErrorCode::TooManyHandles);
        }

        let handle_id = HandleId::from_raw(self.next_id);
        let value = object.into();

        if self.handles.try_insert(handle_id, value).is_err() {
            return Err(ErrorCode::AlreadyExists);
        }

        self.next_id += 1;
        Ok(handle_id)
    }

    pub fn is_movable(&self, handle: HandleId) -> bool {
        let exists = self.handles.get(&handle).is_some();
        exists
    }

    pub fn get_any(&self, handle: HandleId) -> Result<AnyHandle, ErrorCode> {
        self.handles
            .get(&handle)
            .cloned()
            .ok_or(ErrorCode::NotFound)
    }

    pub fn get<T: Handleable>(&self, handle: HandleId) -> Result<Handle<T>, ErrorCode> {
        let any_handle = self.get_any(handle)?;
        let handle = any_handle.downcast().ok_or(ErrorCode::UnexpectedType)?;
        Ok(handle)
    }

    pub fn take(&mut self, handle: HandleId) -> Option<AnyHandle> {
        self.handles.remove(&handle)
    }

    pub fn close(&mut self, handle: HandleId) -> Result<(), ErrorCode> {
        let handle = self.handles.remove(&handle).ok_or(ErrorCode::NotFound)?;
        handle.close();
        Ok(())
    }
}
```
## kernel/interrupt.rs
```
use starina::interrupt::IrqMatcher;
use starina::poll::Readiness;
use starina_types::error::ErrorCode;
use starina_types::interrupt::Irq;

use crate::arch;
use crate::arch::INTERRUPT_CONTROLLER;
use crate::handle::Handleable;
use crate::poll::Listener;
use crate::poll::ListenerSet;
use crate::poll::Poll;
use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;

struct Mutable {
    listeners: ListenerSet,
    active: bool,
}

pub struct Interrupt {
    irq: Irq,
    mutable: SpinLock<Mutable>,
}

impl Interrupt {
    pub fn attach(irq_matcher: IrqMatcher) -> Result<SharedRef<Interrupt>, ErrorCode> {
        let irq = INTERRUPT_CONTROLLER.acquire_irq(irq_matcher)?;

        let interrupt = SharedRef::new(Interrupt {
            irq,
            mutable: SpinLock::new(Mutable {
                listeners: ListenerSet::new(),
                active: false,
            }),
        })?;

        INTERRUPT_CONTROLLER.enable_irq(interrupt.clone());
        Ok(interrupt)
    }

    pub fn irq(&self) -> Irq {
        self.irq
    }

    pub fn trigger(&self) -> Result<(), ErrorCode> {
        let mut mutable = self.mutable.lock();
        mutable.active = true;
        mutable.listeners.notify_all(Readiness::READABLE);
        Ok(())
    }

    pub fn acknowledge(&self) -> Result<(), ErrorCode> {
        self.mutable.lock().active = false;
        INTERRUPT_CONTROLLER.acknowledge_irq(self.irq);
        Ok(())
    }
}

impl Handleable for Interrupt {
    fn close(&self) {
        // Do nothing
    }

    fn add_listener(&self, listener: Listener) -> Result<(), ErrorCode> {
        self.mutable.lock().listeners.add_listener(listener)?;
        Ok(())
    }

    fn remove_listener(&self, poll: &Poll) -> Result<(), ErrorCode> {
        self.mutable.lock().listeners.remove_listener(poll);
        Ok(())
    }

    fn readiness(&self) -> Result<Readiness, ErrorCode> {
        let mut readiness = Readiness::new();
        let active = self.mutable.lock().active;
        if active {
            readiness |= Readiness::READABLE;
        }

        Ok(readiness)
    }
}
```
## kernel/iobus.rs
```
use starina::address::DAddr;
use starina::address::PAddr;
use starina::error::ErrorCode;
use starina::poll::Readiness;
use starina_utils::alignment::is_aligned;
use starina_utils::static_assert;

use crate::arch::PAGE_SIZE;
use crate::folio::Folio;
use crate::handle::Handleable;
use crate::poll::Listener;
use crate::poll::Poll;
use crate::refcount::RefCounted;
use crate::refcount::SharedRef;

pub static NOMMU_IOBUS: SharedRef<IoBus> = {
    static INNER: RefCounted<IoBus> = RefCounted::new(IoBus::NoMmu);
    unsafe { SharedRef::new_static(&INNER) }
};

/// A device memory address space.
pub enum IoBus {
    NoMmu,
}

impl IoBus {
    pub fn map(&self, daddr: Option<DAddr>, len: usize) -> Result<Folio, ErrorCode> {
        // In No MMU bus, we don't need to configure the IOMMU. Just allocate
        // a folio accordingly.
        debug_assert!(matches!(self, IoBus::NoMmu));

        if let Some(daddr) = daddr {
            let paddr = PAddr::new(daddr.as_usize());
            if !is_aligned(paddr.as_usize(), PAGE_SIZE) {
                return Err(ErrorCode::InvalidArg);
            }

            if !is_aligned(len, PAGE_SIZE) {
                return Err(ErrorCode::InvalidArg);
            }

            Folio::alloc_at(paddr, len)
        } else {
            Folio::alloc_for_device(len)
        }
    }
}

impl Handleable for IoBus {
    fn close(&self) {
        // Do nothing
    }

    fn add_listener(&self, _listener: Listener) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }
    fn remove_listener(&self, _poll: &Poll) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }
    fn readiness(&self) -> Result<Readiness, ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }
}
```
## kernel/isolation/mod.rs
```
use alloc::vec::Vec;

use starina_types::error::ErrorCode;

pub enum Isolation {
    InKernel,
}

pub enum IsolationHeap {
    InKernel { ptr: *const u8, len: usize },
}

pub enum IsolationHeapMut {
    InKernel { ptr: *mut u8, len: usize },
}
impl IsolationHeap {
    pub fn read_to_vec(
        &self,
        isolation: &Isolation,
        offset: usize,
        len: usize,
    ) -> Result<Vec<u8>, ErrorCode> {
        assert!(matches!(isolation, Isolation::InKernel));
        let IsolationHeap::InKernel { ptr, .. } = self;
        let slice = unsafe { core::slice::from_raw_parts(ptr.add(offset), len) };

        let mut buf = Vec::new();
        buf.try_reserve_exact(len)
            .map_err(|_| ErrorCode::OutOfMemory)?;
        buf.extend_from_slice(slice);

        Ok(buf)
    }

    pub fn read<T: Copy>(&self, isolation: &Isolation, offset: usize) -> Result<T, ErrorCode> {
        assert!(matches!(isolation, Isolation::InKernel));
        let IsolationHeap::InKernel { ptr, .. } = self;
        unsafe { Ok(core::ptr::read(ptr.add(offset) as *const T)) }
    }
}

impl IsolationHeapMut {
    pub fn write<T: Copy>(
        &mut self,
        isolation: &Isolation,
        offset: usize,
        value: T,
    ) -> Result<(), ErrorCode> {
        assert!(matches!(isolation, Isolation::InKernel));
        let IsolationHeapMut::InKernel { ptr, .. } = self;
        // TODO: size check
        // TODO: wraparound check
        // TODO: alignment check
        unsafe {
            core::ptr::write(ptr.add(offset) as *mut T, value);
        }

        Ok(())
    }

    pub fn write_bytes(
        &mut self,
        isolation: &Isolation,
        offset: usize,
        slice: &[u8],
    ) -> Result<(), ErrorCode> {
        assert!(matches!(isolation, Isolation::InKernel));
        let IsolationHeapMut::InKernel { ptr, .. } = self;
        unsafe {
            core::ptr::copy(slice.as_ptr(), ptr.add(offset), slice.len());
        }
        Ok(())
    }
}
```
## kernel/main.rs
```
#![cfg_attr(target_os = "none", no_std)]
#![cfg_attr(target_os = "none", no_main)]
#![cfg_attr(test, feature(test))]
#![feature(naked_functions)]
#![feature(arbitrary_self_types)]
#![feature(coerce_unsized)]
#![feature(unsize)]
#![feature(allocator_api)]
#![feature(fn_align)]
#![feature(map_try_insert)]
#![allow(unused)]

extern crate alloc;

use allocator::GLOBAL_ALLOCATOR;
use arrayvec::ArrayVec;
use channel::Channel;
use cpuvar::CpuId;
use handle::Handle;
use starina::device_tree::DeviceTree;
use starina_types::handle::HandleRights;

#[macro_use]
mod print;

mod allocator;
mod arch;
mod channel;
mod cpuvar;
mod device_tree;
mod folio;
mod handle;
mod interrupt;
mod iobus;
mod isolation;
mod panic;
mod poll;
mod process;
mod refcount;
mod scheduler;
mod spinlock;
mod startup;
mod syscall;
mod thread;
mod utils;
mod vmspace;

pub struct FreeRam {
    addr: *mut u8,
    size: usize,
}

pub struct BootInfo {
    dtb: *const u8,
    cpu_id: CpuId,
    free_rams: ArrayVec<FreeRam, 8>,
}

pub fn boot(bootinfo: BootInfo) -> ! {
    info!("Booting Starina...");
    for free_ram in bootinfo.free_rams {
        debug!(
            "Free RAM: {:x} ({} MB)",
            free_ram.addr as usize,
            free_ram.size / 1024 / 1024
        );
        GLOBAL_ALLOCATOR.add_region(free_ram.addr, free_ram.size);
    }

    let device_tree = device_tree::parse(bootinfo.dtb).expect("failed to parse device tree");

    cpuvar::percpu_init(bootinfo.cpu_id);
    arch::percpu_init();
    startup::load_inkernel_apps(device_tree);
    thread::switch_thread();
}
```
## kernel/panic.rs
```
use core::panic::PanicInfo;
use core::sync::atomic::AtomicU8;
use core::sync::atomic::Ordering;

use starina_types::error;

use crate::arch;

/// Panic counter. Every time the kernel panics, this counter is incremented.
static PANIC_COUNTER: AtomicU8 = AtomicU8::new(0);

/// Kernel panic handler.
#[cfg_attr(target_os = "none", panic_handler)]
#[cfg_attr(not(target_os = "none"), allow(unused))]
fn panic(info: &PanicInfo) -> ! {
    // In case it panics while handling a panic, this panic handler implements
    // some fallback logic to try to at least print the panic details.
    match PANIC_COUNTER.fetch_add(1, Ordering::SeqCst) {
        0 => {
            // First panic: Try whatever we can do including complicated stuff
            // which may panic again.
            error!("kernel panic: {}", info);
            arch::halt();
        }
        1 => {
            // Double panics: paniked while handling a panic. Keep it simple.
            println!("double kernel panic: {:?}", info);
            arch::halt();
        }
        _ => {
            // Triple panics: println! seems to be broken. Spin forever.
            arch::halt();
        }
    }
}
```
## kernel/poll.rs
```
use alloc::collections::btree_map::BTreeMap;
use alloc::collections::vec_deque::VecDeque;
use alloc::vec::Vec;
use core::fmt;
use core::hash::Hash;

use hashbrown::HashSet;
use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
use starina_types::poll::Readiness;

use crate::handle::AnyHandle;
use crate::handle::Handleable;
use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;
use crate::syscall::SyscallResult;
use crate::thread::Thread;
use crate::thread::ThreadState;

struct UniqueQueue<T> {
    queue: VecDeque<T>,
    set: HashSet<T>,
}

impl<T> UniqueQueue<T> {
    pub fn new() -> UniqueQueue<T> {
        UniqueQueue {
            queue: VecDeque::new(),
            set: HashSet::new(),
        }
    }
}

impl<T: Eq + Ord + Copy + Hash> UniqueQueue<T> {
    pub fn enqueue(&mut self, value: T) -> Result<(), ErrorCode> {
        if self.set.contains(&value) {
            return Ok(());
        }

        self.queue
            .try_reserve(1)
            .map_err(|_| ErrorCode::OutOfMemory)?;
        self.set
            .try_reserve(1)
            .map_err(|_| ErrorCode::OutOfMemory)?;

        self.queue.push_back(value);
        self.set.insert(value);
        Ok(())
    }

    pub fn pop(&mut self) -> Option<T> {
        let value = self.queue.pop_front();
        if let Some(value) = &value {
            let deleted = self.set.remove(value);
            debug_assert!(deleted);
        }

        value
    }
}

pub struct Listener {
    poll: SharedRef<Poll>,
    id: HandleId,
    interests: Readiness,
}

impl Listener {
    pub fn notify(&self, readiness: Readiness) {
        let mut mutable = self.poll.mutable.lock();
        if mutable.ready_handles.enqueue(self.id).is_err() {
            debug_warn!("failed to notify listener due to out-of-memory");
            return;
        }

        // If the event is what we listen for, wake up a single thread. We haven't
        // yet encountered a case where multiple processes are listening for the
        // same object, so it's totally fine.
        //
        // IDEA: Should we wake up the most-recently-added thread? It's not fair,
        //       but it might perform better if its working set is in the cache.
        if self.interests.contains(readiness) {
            if let Some(waiter) = mutable.waiters.pop_front() {
                waiter.wake();
            }
        }
    }
}

pub struct ListenerSet {
    listeners: Vec<Listener>,
}

impl ListenerSet {
    pub fn new() -> ListenerSet {
        ListenerSet {
            listeners: Vec::new(),
        }
    }

    pub fn notify_all(&self, readiness: Readiness) {
        for listener in &self.listeners {
            listener.notify(readiness);
        }
    }

    pub fn add_listener(&mut self, listener: Listener) -> Result<(), ErrorCode> {
        self.listeners
            .try_reserve(1)
            .map_err(|_| ErrorCode::OutOfMemory)?;

        self.listeners.push(listener);
        Ok(())
    }

    pub fn remove_listener(&mut self, poll: &Poll) {
        self.listeners
            .retain(|listener| SharedRef::ptr_eq_self(&listener.poll, poll));
    }
}

struct Listenee {
    handle: AnyHandle,
    interests: Readiness,
}

struct Mutable {
    listenee: BTreeMap<HandleId, Listenee>,
    ready_handles: UniqueQueue<HandleId>,
    waiters: VecDeque<SharedRef<Thread>>,
}

pub struct Poll {
    mutable: SharedRef<SpinLock<Mutable>>,
}

impl Poll {
    pub fn new() -> Result<SharedRef<Poll>, ErrorCode> {
        let mutable = SharedRef::new(SpinLock::new(Mutable {
            listenee: BTreeMap::new(),
            ready_handles: UniqueQueue::new(),
            waiters: VecDeque::new(),
        }))?;

        let poll = SharedRef::new(Poll { mutable })?;
        Ok(poll)
    }

    pub fn add(
        self: &SharedRef<Poll>,
        handle: AnyHandle,
        id: HandleId,
        interests: Readiness,
    ) -> Result<(), ErrorCode> {
        let mut mutable = self.mutable.lock();
        if mutable.listenee.contains_key(&id) {
            return Err(ErrorCode::AlreadyExists);
        }

        // Add the listener to the listener object.
        handle.add_listener(Listener {
            poll: self.clone(),
            interests,
            id,
        })?;

        let listenee = Listenee {
            handle: handle.clone(),
            interests,
        };

        if mutable.listenee.try_insert(id, listenee).is_err() {
            return Err(ErrorCode::AlreadyExists);
        }

        let readiness = handle.readiness()?;
        if readiness.contains(interests) {
            // Are there any waiters waiting for an event?
            if let Some(waiter) = mutable.waiters.pop_front() {
                waiter.wake();
            } else {
                // No threads are ready to receive the event. Deliver it later once
                // a thread enters the wait state.
                if mutable.ready_handles.enqueue(id).is_err() {
                    debug_warn!("failed to enqueue a ready handle due to out-of-memory");
                }
            }
        }

        Ok(())
    }

    pub fn remove(self: &SharedRef<Poll>, id: HandleId) -> Result<(), ErrorCode> {
        let mut mutable = self.mutable.lock();
        let listenee = mutable.listenee.remove(&id).ok_or(ErrorCode::NotFound)?;
        listenee.handle.remove_listener(self)?;
        mutable.ready_handles.set.remove(&id);
        Ok(())
    }

    pub fn try_wait(self: &SharedRef<Poll>, current: &SharedRef<Thread>) -> SyscallResult {
        let mut mutable = self.mutable.lock();

        // Check if there are any ready events.
        while let Some(id) = mutable.ready_handles.pop() {
            let Some(listenee) = mutable.listenee.get_mut(&id) else {
                // The handle was removed from the poll. Try the next one.
                continue;
            };

            let readiness = match listenee.handle.readiness() {
                Ok(readiness) => readiness,
                Err(e) => {
                    debug_warn!("failed to get readiness for handle: {:?}", e);
                    return SyscallResult::Err(e);
                }
            };

            let interested = listenee.interests & readiness;
            if !interested.is_empty() {
                return SyscallResult::Done((id, interested).into());
            }
        }

        // No events are ready. Block the current thread.
        //
        // WARNING: Thread::switch will never return. Clean up all resources
        //          before calling it!

        if mutable.waiters.try_reserve(1).is_err() {
            return SyscallResult::Err(ErrorCode::OutOfMemory);
        }

        mutable.waiters.push_back(current.clone());
        SyscallResult::Block(ThreadState::BlockedByPoll(self.clone()))
    }
}

impl Handleable for Poll {
    fn close(&self) {
        // Nothing to do.
    }

    fn add_listener(&self, _listener: Listener) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }

    fn remove_listener(&self, _poll: &Poll) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }

    fn readiness(&self) -> Result<Readiness, ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }
}

impl fmt::Debug for Poll {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("Poll").finish()
    }
}

impl Drop for Poll {
    fn drop(&mut self) {
        let mut mutable = self.mutable.lock();
        for waiter in mutable.waiters.drain(..) {
            waiter.set_state(ThreadState::Runnable(Some(ErrorCode::Closed.into())));
        }

        for listenee in mutable.listenee.values_mut() {
            if let Err(err) = listenee.handle.remove_listener(self) {
                debug_warn!("failed to remove listener from handle: {:?}", err);
            }
        }
    }
}
```
## kernel/print.rs
```
/// The console output writer.
///
/// This is an internal implementation detail of the `print!` and `println!`
/// macros. You should use those macros, not this struct directly.
pub struct Printer;

impl core::fmt::Write for Printer {
    fn write_str(&mut self, s: &str) -> core::fmt::Result {
        crate::arch::console_write(s.as_bytes());
        Ok(())
    }
}

/// Prints a string without a newline.
#[macro_export]
macro_rules! print {
    ($($arg:tt)*) => {{
        #![allow(unused_imports)]
        use core::fmt::Write;
        write!($crate::print::Printer, $($arg)*).ok();
    }};
}

/// Prints a string and a newline.
#[macro_export]
macro_rules! println {
    () => {{
        $crate::print!(
            "\n"
        );
    }};
    ($fmt:expr) => {{
        $crate::print!(
            concat!($fmt, "\n")
        );
    }};
    ($fmt:expr, $($arg:tt)*) => {{
        $crate::print!(
            concat!($fmt, "\n"),
            $($arg)*
        );
    }};
}

#[derive(Clone, Copy, PartialEq, Eq, Ord, PartialOrd)]
#[allow(dead_code)]
pub enum LogLevel {
    Error,
    Warn,
    Info,
    Debug,
    Trace,
}

#[macro_export]
macro_rules! log {
    ($level:expr, $($arg:tt)+) => {{
        use $crate::print::LogLevel;

        const RESET_COLOR: &str = "\x1b[0m";

        if cfg!(debug_assertions) || $level <= LogLevel::Info {
            let (color, level_str) = match $level {
                LogLevel::Error => ("\x1b[91m", "ERR"),
                LogLevel::Warn =>  ("\x1b[33m", "WARN"),
                LogLevel::Info =>  ("\x1b[96m", "INFO"),
                LogLevel::Debug => ("\x1b[0m", "DEBUG"),
                LogLevel::Trace => ("\x1b[0m", "TRACE"),
            };

            $crate::println!(
                "[kernel      ] {}{:6}{} {}",
                color,
                level_str,
                RESET_COLOR,
                format_args!($($arg)+)
            );
        }
    }};
}

#[macro_export]
macro_rules! error {
    ($($arg:tt)+) => { $crate::log!($crate::print::LogLevel::Error, $($arg)+) }
}

#[macro_export]
macro_rules! warn {
    ($($arg:tt)+) => { $crate::log!($crate::print::LogLevel::Warn, $($arg)+) }
}

#[macro_export]
macro_rules! info {
    ($($arg:tt)+) => { $crate::log!($crate::print::LogLevel::Info, $($arg)+) }
}

#[macro_export]
macro_rules! debug {
    ($($arg:tt)+) => { $crate::log!($crate::print::LogLevel::Debug, $($arg)+) }
}

#[macro_export]
macro_rules! trace {
    ($($arg:tt)+) => { $crate::log!($crate::print::LogLevel::Trace, $($arg)+) }
}

/// Print kernel message with backtraces.
#[macro_export]
macro_rules! oops {
    ($($args:tt)*) => {{
        $crate::println!($($args)*);
    }};
}

#[macro_export]
macro_rules! debug_warn {
    ($($arg:tt)+) => {
        if cfg!(debug_assertions) {
            $crate::warn!($($arg)+);
        }
    };
}
```
## kernel/process.rs
```
//! Process management.
use core::fmt;

use crate::handle::HandleTable;
use crate::isolation::Isolation;
use crate::refcount::RefCounted;
use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;
use crate::vmspace::KERNEL_VMSPACE;
use crate::vmspace::VmSpace;

pub struct Process {
    vmspace: SharedRef<VmSpace>,
    handles: SpinLock<HandleTable>,
    isolation: Isolation,
}

impl Process {
    pub const fn create(vmspace: SharedRef<VmSpace>, isolation: Isolation) -> Process {
        Process {
            vmspace,
            handles: SpinLock::new(HandleTable::new()),
            isolation,
        }
    }

    pub fn handles(&self) -> &SpinLock<HandleTable> {
        &self.handles
    }

    pub fn vmspace(&self) -> &SharedRef<VmSpace> {
        &self.vmspace
    }

    pub fn isolation(&self) -> &Isolation {
        &self.isolation
    }
}

impl fmt::Debug for Process {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "Process")
    }
}

pub static KERNEL_PROCESS: spin::Lazy<SharedRef<Process>> = spin::Lazy::new(|| {
    let process = Process::create(KERNEL_VMSPACE.clone(), Isolation::InKernel);
    SharedRef::new(process).unwrap()
});
```
## kernel/refcount.rs
```
//! Reference counting.

use alloc::boxed::Box;
use core::any::Any;
use core::fmt;
use core::marker::Unsize;
use core::mem;
use core::ops::CoerceUnsized;
use core::ops::Deref;
use core::ptr::NonNull;
use core::sync::atomic;
use core::sync::atomic::AtomicUsize;
use core::sync::atomic::Ordering;

use starina_types::error::ErrorCode;

use crate::handle::Handleable;

pub struct RefCounted<T: ?Sized> {
    counter: AtomicUsize,
    value: T,
}

impl<T> RefCounted<T> {
    pub const fn new(value: T) -> Self {
        Self {
            counter: AtomicUsize::new(1),
            value,
        }
    }
}

/// A reference-counted object.
///
/// # Why not `Arc`?
///
/// Rust's standard library provides `Arc` for reference counting. However, we
/// generally prefer rolling our own primitives in kernel to use what we really
/// need.
///
/// In reference counting, we have some properties:
///
/// - We'll never need weak references. Instead, the userland will delete each
///   object explicitly through a system call (LMK if you noticed counter-examples!).
///
/// # Atomic Operations on counters
///
/// [`Ordering`] parameters are chosen to be as relaxed as possible in the fast
/// path, inspired by Rust's `Arc` implementation.
pub struct SharedRef<T: ?Sized> {
    ptr: NonNull<RefCounted<T>>,
}

impl<T> SharedRef<T> {
    /// Creates a new reference-counted object.
    pub fn new(value: T) -> Result<Self, ErrorCode> {
        let boxed = Box::try_new(RefCounted::new(value)).map_err(|_| ErrorCode::OutOfMemory)?;
        let ptr = Box::leak(boxed);

        Ok(Self {
            // SAFETY: Box always returns a valid non-null pointer.
            ptr: unsafe { NonNull::new_unchecked(ptr) },
        })
    }

    /// Creates a new reference-counted object from a static reference.
    ///
    /// # Safety
    ///
    /// The created object must not be dropped for the lifetime of the program.
    pub const unsafe fn new_static(inner: &'static RefCounted<T>) -> Self {
        let ptr = inner as *const RefCounted<T> as *mut RefCounted<T>;
        Self {
            ptr: unsafe { NonNull::new_unchecked(ptr) },
        }
    }

    pub fn ptr_eq(a: &SharedRef<T>, b: &SharedRef<T>) -> bool {
        a.ptr == b.ptr
    }

    pub fn ptr_eq_self(a: &SharedRef<T>, this: &T) -> bool {
        let this_ptr: *const T = this;
        let inner_ptr: *const T = &a.inner().value;
        core::ptr::eq(this_ptr, inner_ptr)
    }
}

impl<T: ?Sized> SharedRef<T> {
    /// Returns a reference to the inner object.
    fn inner(&self) -> &RefCounted<T> {
        // SAFETY: The object will be kept alive as long as `self` is alive.
        //         The compiler will guarantee `&RefCounted<T>` can't outlive
        //         `self`.
        unsafe { self.ptr.as_ref() }
    }
}

impl<T: ?Sized> Drop for SharedRef<T> {
    fn drop(&mut self) {
        debug_assert!(self.inner().counter.load(Ordering::Relaxed) > 0);

        // Release the reference count.
        if self.inner().counter.fetch_sub(1, Ordering::Release) == 1 {
            // The reference counter reached zero. Free the memory.

            // "Prevent reordering of use of the data and deletion of the data",
            // as the standard library's `Arc` does [1].
            //
            // [1]: https://github.com/rust-lang/rust/blob/da159eb331b27df528185c616b394bb0e1d2a4bd/library/alloc/src/sync.rs#L2469-L2497
            atomic::fence(Ordering::Acquire);

            // SAFETY: This reference was the last one, so we can safely
            //         free the memory.
            mem::drop(unsafe { Box::from_raw(self.ptr.as_ptr()) });
        }
    }
}

impl<T: ?Sized> Clone for SharedRef<T> {
    fn clone(&self) -> Self {
        debug_assert!(self.inner().counter.load(Ordering::Relaxed) > 0);

        // Increment the reference count.
        //
        // Theoretically, the counter can overflow, but it's not a problem
        // in practice because having 2^B references (where B is 32 or 64
        // depending on the CPU) means you have at least 2^B * size_of(NonNull)
        // bytes of space. Who would have that much memory to store references
        // to only single object?
        //
        // If you don't agree with this, please open a PR with a nice
        // explanation. It must be fun to read :)
        self.inner().counter.fetch_add(1, Ordering::Relaxed);

        Self { ptr: self.ptr }
    }
}

impl<T: ?Sized> Deref for SharedRef<T> {
    type Target = T;

    fn deref(&self) -> &Self::Target {
        &self.inner().value
    }
}

impl<T> fmt::Debug for SharedRef<T>
where
    T: fmt::Debug,
{
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_tuple("SharedRef")
            .field(&self.inner().value)
            .finish()
    }
}

impl SharedRef<dyn Handleable> {
    pub fn downcast<T>(self) -> Result<SharedRef<T>, Self>
    where
        T: Handleable,
    {
        if <dyn Any>::is::<T>(&self.inner().value) {
            let ptr = self.ptr.cast();
            mem::forget(self);
            Ok(SharedRef { ptr })
        } else {
            Err(self)
        }
    }
}

unsafe impl<T: Sync + Send + ?Sized> Sync for SharedRef<T> {}
unsafe impl<T: Sync + Send + ?Sized> Send for SharedRef<T> {}

impl<T: ?Sized + Unsize<U>, U: ?Sized> CoerceUnsized<SharedRef<U>> for SharedRef<T> {}
```
## kernel/scheduler.rs
```
use alloc::collections::VecDeque;

use starina_types::error::ErrorCode;

use crate::refcount::SharedRef;
use crate::spinlock::SpinLock;
use crate::thread::Thread;

pub static GLOBAL_SCHEDULER: Scheduler = Scheduler::new();

pub struct Scheduler {
    runqueue: SpinLock<VecDeque<SharedRef<Thread>>>,
}

impl Scheduler {
    pub const fn new() -> Scheduler {
        Scheduler {
            runqueue: SpinLock::new(VecDeque::new()),
        }
    }

    pub fn push(&self, new_thread: SharedRef<Thread>) {
        // SAFETY: This should not panic because we've already reserved the
        //         capacity in `try_reserve`.
        self.runqueue.lock().push_back(new_thread);
    }

    pub fn try_reserve_cap(&self, new_cap: usize) -> Result<(), ErrorCode> {
        let mut runqueue = self.runqueue.lock();
        if let Some(additional) = new_cap.checked_sub(runqueue.capacity()) {
            runqueue
                .try_reserve(additional)
                .map_err(|_| ErrorCode::OutOfMemory)?;
        }

        Ok(())
    }

    pub fn schedule(&self) -> Option<SharedRef<Thread>> {
        self.runqueue.lock().pop_front()
    }
}
```
## kernel/spinlock.rs
```
//! Spinlock implementation.
use core::cell::UnsafeCell;
use core::ops::Deref;
use core::ops::DerefMut;
use core::sync::atomic::AtomicBool;
use core::sync::atomic::Ordering;

/// A simple spinlock.
pub struct SpinLock<T: ?Sized> {
    lock: AtomicBool,
    value: UnsafeCell<T>,
}

impl<T> SpinLock<T> {
    pub const fn new(value: T) -> SpinLock<T> {
        SpinLock {
            value: UnsafeCell::new(value),
            lock: AtomicBool::new(false),
        }
    }

    pub fn lock(&self) -> SpinLockGuard<T> {
        if self.lock.load(Ordering::Relaxed) {
            oops!(
                "spinlock: {:x}: deadlock detected - mutex will never be left locked in single CPU!",
                self as *const _ as usize
            );
        }

        while self
            .lock
            .compare_exchange(false, true, Ordering::Acquire, Ordering::Relaxed)
            .is_err()
        {
            core::hint::spin_loop();
        }

        SpinLockGuard { this: self }
    }
}

pub struct SpinLockGuard<'a, T: ?Sized + 'a> {
    this: &'a SpinLock<T>,
}

impl<T: ?Sized> Drop for SpinLockGuard<'_, T> {
    fn drop(&mut self) {
        self.this.lock.store(false, Ordering::Release);
    }
}

impl<T> Deref for SpinLockGuard<'_, T> {
    type Target = T;

    fn deref(&self) -> &T {
        // SAFETY: The dereference is safe because this lock guard has
        // exclusive access to the data and the pointer is always valid.
        unsafe { &*self.this.value.get() }
    }
}

impl<T> DerefMut for SpinLockGuard<'_, T> {
    fn deref_mut(&mut self) -> &mut T {
        // SAFETY: The dereference is safe because this lock guard has
        // exclusive access to the data and the pointer is always valid.
        unsafe { &mut *self.this.value.get() }
    }
}

unsafe impl<T: ?Sized + Send> Sync for SpinLock<T> {}
unsafe impl<T: ?Sized + Send> Send for SpinLock<T> {}

unsafe impl<T: ?Sized + Sync> Sync for SpinLockGuard<'_, T> {}
unsafe impl<T: ?Sized + Send> Send for SpinLockGuard<'_, T> {}
```
## kernel/startup.rs
```
use alloc::boxed::Box;
use alloc::string::String;
use alloc::sync::Arc;
use alloc::vec;
use alloc::vec::Vec;

use arrayvec::ArrayVec;
use hashbrown::HashMap;
use starina::device_tree::BusNode;
use starina::device_tree::DeviceTree;
use starina::handle::HandleId;
use starina::handle::HandleRights;
use starina::message::MessageInfo;
use starina::message::MessageKind;
use starina::spec::DeviceMatch;
use starina::spec::EnvType;
use starina::spec::ExportItem;
use starina::syscall::VsyscallPage;
use starina_types::spec::AppSpec;

use crate::channel::Channel;
use crate::handle::Handle;
use crate::iobus::NOMMU_IOBUS;
use crate::isolation::IsolationHeap;
use crate::process::KERNEL_PROCESS;
use crate::scheduler::GLOBAL_SCHEDULER;
use crate::spinlock::SpinLock;
use crate::thread::Thread;

struct InKernelApp {
    name: &'static str,
    main: fn(vsyscall: *const VsyscallPage),
    spec: AppSpec,
}

const INKERNEL_APPS: &[InKernelApp] = &[
    InKernelApp {
        name: "virtio_net",
        main: virtio_net::autogen::app_main,
        spec: virtio_net::autogen::APP_SPEC,
    },
    InKernelApp {
        name: "tcpip",
        main: tcpip::autogen::app_main,
        spec: tcpip::autogen::APP_SPEC,
    },
    InKernelApp {
        name: "http_server",
        main: http_server::autogen::app_main,
        spec: http_server::autogen::APP_SPEC,
    },
];

static INSTANCES: SpinLock<Vec<Instance>> = SpinLock::new(Vec::new());

struct Instance {
    vsyscall_page: Box<VsyscallPage>,
    environ_str: String,
}

pub fn load_inkernel_apps(device_tree: DeviceTree) {
    let mut instances = INSTANCES.lock();
    let mut server_channels = HashMap::new();
    let mut client_channels = HashMap::new();
    for app in INKERNEL_APPS {
        for export in app.spec.exports {
            match export {
                ExportItem::Service { name } => {
                    let (ch1, ch2) = Channel::new().unwrap();
                    assert!(
                        server_channels.insert(app.name, ch1).is_none(),
                        "multiple exports are not yet supported"
                    );
                    client_channels.insert(*name, ch2);
                }
            }
        }
    }

    for app in INKERNEL_APPS {
        info!("startup: starting \"{}\"", app.name);
        let mut env = serde_json::Map::new();
        for item in app.spec.env {
            let value = match item.ty {
                EnvType::IoBusMap => {
                    let mut buses = HashMap::new();
                    for (name, node) in &device_tree.buses {
                        let bus = match node {
                            BusNode::NoMmu => NOMMU_IOBUS.clone(),
                        };

                        let handle = Handle::new(bus, HandleRights::WRITE);
                        let handle_id = KERNEL_PROCESS
                            .handles()
                            .lock()
                            .insert(handle)
                            .expect("failed to insert iobus");
                        buses.insert(name, handle_id.as_raw());
                    }

                    serde_json::json!(buses)
                }
                EnvType::DeviceTree { matches } => {
                    let mut devices = HashMap::new();
                    for (name, node) in &device_tree.devices {
                        let should_add = matches.iter().any(|m| {
                            match m {
                                DeviceMatch::Compatible(compatible) => {
                                    node.compatible.iter().any(|c| c == compatible)
                                }
                            }
                        });

                        if should_add {
                            devices.insert(name, node);
                        }
                    }

                    serde_json::json!({
                        "devices": devices,
                        "buses": device_tree.buses,
                    })
                }
                EnvType::Service { name } => {
                    let ch = match client_channels.get(name) {
                        Some(ch) => ch.clone(),
                        None => panic!("service not found: {} (requested by {})", name, app.name),
                    };

                    // Enqueue a connect message to the server.
                    let (server_ch, client_ch) = Channel::new().unwrap();
                    {
                        let server_handles = KERNEL_PROCESS.handles();
                        let server_ch_handle =
                            Handle::new(server_ch, HandleRights::READ | HandleRights::WRITE);

                        let mut handles = ArrayVec::new();
                        handles.push(server_ch_handle.into());

                        ch.do_send(
                            MessageInfo::new(MessageKind::Connect as i32, 0, 1),
                            vec![],
                            handles,
                        )
                        .expect("failed to send connect message");
                    }

                    // Add the client channel to the environment.
                    let handle_id = {
                        let handles = KERNEL_PROCESS.handles();
                        let handle =
                            Handle::new(client_ch, HandleRights::READ | HandleRights::WRITE);
                        handles
                            .lock()
                            .insert(handle)
                            .expect("failed to insert channel")
                    };

                    serde_json::json!(handle_id.as_raw())
                }
            };

            env.insert(item.name.into(), value);
        }

        let startup_ch = if let Some(ch) = server_channels.get(app.name) {
            let handle = Handle::new(ch.clone(), HandleRights::READ | HandleRights::WRITE);
            let handle_id = KERNEL_PROCESS.handles().lock().insert(handle).unwrap();
            handle_id
        } else {
            HandleId::from_raw(0)
        };

        let env_str = serde_json::to_string(&env).unwrap();
        let vsyscall_page = Box::new(VsyscallPage {
            environ_ptr: env_str.as_ptr(),
            environ_len: env_str.len(),
            startup_ch,
        });

        let arg = unsafe { &*vsyscall_page as *const VsyscallPage } as usize;
        let thread = Thread::new_inkernel(app.main as usize, arg as usize).unwrap();
        GLOBAL_SCHEDULER.push(thread);
        instances.push(Instance {
            vsyscall_page,
            environ_str: env_str,
        });
    }
}
```
## kernel/syscall.rs
```
use starina::address::DAddr;
use starina::address::VAddr;
use starina::interrupt::Irq;
use starina::interrupt::IrqMatcher;
use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
use starina_types::handle::HandleRights;
use starina_types::message::MESSAGE_DATA_LEN_MAX;
use starina_types::message::MESSAGE_NUM_HANDLES_MAX;
use starina_types::message::MessageInfo;
use starina_types::poll::Readiness;
use starina_types::syscall::*;
use starina_types::vmspace::PageProtect;

use crate::arch;
use crate::arch::enter_kernelland;
use crate::channel::Channel;
use crate::cpuvar::current_thread;
use crate::folio::Folio;
use crate::handle::Handle;
use crate::interrupt::Interrupt;
use crate::iobus::IoBus;
use crate::isolation::IsolationHeap;
use crate::isolation::IsolationHeapMut;
use crate::poll::Poll;
use crate::refcount::SharedRef;
use crate::thread::Thread;
use crate::thread::ThreadState;
use crate::thread::switch_thread;
use crate::vmspace::VmSpace;

pub enum SyscallResult {
    Done(RetVal),
    Err(ErrorCode),
    Block(ThreadState),
}

fn handle_close(current: &SharedRef<Thread>, handle: HandleId) -> Result<(), ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    handle_table.close(handle)?;
    Ok(())
}

fn poll_create(current: &SharedRef<Thread>) -> Result<HandleId, ErrorCode> {
    let poll = Poll::new()?;
    let handle = Handle::new(poll, HandleRights::POLL | HandleRights::WRITE);
    let poll_id = current.process().handles().lock().insert(handle)?;
    Ok(poll_id)
}

fn poll_add(
    current: &SharedRef<Thread>,
    poll: HandleId,
    object: HandleId,
    interests: Readiness,
) -> Result<(), ErrorCode> {
    let handles = current.process().handles().lock();
    let poll = handles.get::<Poll>(poll)?;
    let object_handle = handles.get_any(object)?;

    if !poll.is_capable(HandleRights::WRITE) {
        return Err(ErrorCode::NotAllowed);
    }

    poll.add(object_handle, object, interests)?;
    Ok(())
}

fn poll_remove(
    current: &SharedRef<Thread>,
    poll: HandleId,
    object: HandleId,
) -> Result<(), ErrorCode> {
    let handles = current.process().handles().lock();
    let poll = handles.get::<Poll>(poll)?;

    if !poll.is_capable(HandleRights::WRITE) {
        return Err(ErrorCode::NotAllowed);
    }

    poll.remove(object)?;
    Ok(())
}

fn poll_wait(current: &SharedRef<Thread>, poll: HandleId) -> SyscallResult {
    let handles = current.process().handles().lock();
    let poll = match handles.get::<Poll>(poll) {
        Ok(poll) => poll,
        Err(e) => {
            return SyscallResult::Err(e);
        }
    };

    if !poll.is_capable(HandleRights::POLL) {
        return SyscallResult::Err(ErrorCode::NotAllowed);
    }

    poll.try_wait(current)
}

fn channel_create(current: &SharedRef<Thread>) -> Result<HandleId, ErrorCode> {
    let (ch1, ch2) = Channel::new()?;
    let handle_table = &mut current.process().handles().lock();
    let ch1_handle = Handle::new(ch1, HandleRights::READ | HandleRights::WRITE);
    let ch2_handle = Handle::new(ch2, HandleRights::READ | HandleRights::WRITE);
    let ch1_id = handle_table.insert(ch1_handle)?;
    let ch2_id = handle_table.insert(ch2_handle)?;
    assert!((ch1_id.as_raw() + 1) == ch2_id.as_raw()); // FIXME: guarantee this in HandleTable
    Ok((ch1_id))
}

fn channel_send(
    current: &SharedRef<Thread>,
    ch: HandleId,
    msginfo: MessageInfo,
    data: *const u8,
    handles: *const HandleId,
) -> Result<(), ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    let ch = handle_table.get::<Channel>(ch)?;

    if !ch.is_capable(HandleRights::WRITE) {
        return Err(ErrorCode::NotAllowed);
    }

    let data = IsolationHeap::InKernel {
        ptr: data,
        len: msginfo.data_len(),
    };
    let handles = IsolationHeap::InKernel {
        ptr: handles as *const u8,
        len: msginfo.num_handles(),
    };
    ch.send(&mut handle_table, msginfo, &data, &handles)
}

fn channel_recv(
    current: &SharedRef<Thread>,
    handle: HandleId,
    data: *mut u8,
    handles: *mut HandleId,
) -> Result<MessageInfo, ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    let ch = handle_table.get::<Channel>(handle)?;

    if !ch.is_capable(HandleRights::READ) {
        return Err(ErrorCode::NotAllowed);
    }

    let mut data = IsolationHeapMut::InKernel {
        ptr: data,
        len: MESSAGE_DATA_LEN_MAX,
    };
    let mut handles = IsolationHeapMut::InKernel {
        ptr: handles as *mut u8,
        len: MESSAGE_NUM_HANDLES_MAX,
    };
    let msginfo = ch.recv(&mut handle_table, &mut data, &mut handles)?;
    Ok(msginfo)
}

pub fn vmspace_map(
    current: &SharedRef<Thread>,
    handle: HandleId,
    folio: HandleId,
    prot: PageProtect,
) -> Result<VAddr, ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    let vmspace = if handle.as_raw() == 0 {
        current.process().vmspace().clone()
    } else {
        let handle = handle_table.get::<VmSpace>(handle)?;
        if !handle.is_capable(HandleRights::WRITE) {
            return Err(ErrorCode::NotAllowed);
        }

        handle.into_object()
    };

    let folio = handle_table.get::<Folio>(folio)?;
    if !folio.is_capable(HandleRights::MAP) {
        return Err(ErrorCode::NotAllowed);
    }

    let vaddr = vmspace.map_anywhere(folio.into_object(), prot)?;
    Ok(vaddr)
}

pub fn folio_daddr(current: &SharedRef<Thread>, handle: HandleId) -> Result<DAddr, ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    let folio = handle_table.get::<Folio>(handle)?;
    let daddr = folio.daddr().ok_or(ErrorCode::NotADevice)?;
    Ok(daddr)
}

fn busio_map(
    current: &SharedRef<Thread>,
    handle: HandleId,
    daddr: Option<DAddr>,
    len: usize,
) -> Result<HandleId, ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    let busio = handle_table.get::<IoBus>(handle)?;
    if !busio.is_capable(HandleRights::WRITE) {
        return Err(ErrorCode::NotAllowed);
    }

    let folio = busio.map(daddr, len)?;
    let handle = Handle::new(SharedRef::new(folio)?, HandleRights::MAP);
    let folio_id = handle_table.insert(handle)?;
    Ok(folio_id)
}

fn interrupt_create(
    current: &SharedRef<Thread>,
    irq_matcher: IrqMatcher,
) -> Result<HandleId, ErrorCode> {
    let interrupt = Interrupt::attach(irq_matcher)?;
    let handle = Handle::new(interrupt, HandleRights::READ | HandleRights::WRITE);
    let handle_id = current.process().handles().lock().insert(handle)?;
    Ok(handle_id)
}

fn interrupt_ack(current: &SharedRef<Thread>, handle: HandleId) -> Result<(), ErrorCode> {
    let mut handle_table = current.process().handles().lock();
    let interrupt = handle_table.get::<Interrupt>(handle)?;
    interrupt.acknowledge()?;
    Ok(())
}

fn do_syscall(
    a0: isize,
    a1: isize,
    a2: isize,
    a3: isize,
    a4: isize,
    n: isize,
    current: &SharedRef<Thread>,
) -> Result<SyscallResult, ErrorCode> {
    match n as u8 {
        SYS_HANDLE_CLOSE => {
            let handle = HandleId::from_raw_isize(a0)?;
            let ret = handle_close(&current, handle)?;
            Ok(SyscallResult::Done(RetVal::new(0)))
        }
        SYS_CONSOLE_WRITE => {
            // FIXME: use isolation heap
            let buf = unsafe { core::slice::from_raw_parts(a0 as *const u8, a1 as usize) };
            arch::console_write(buf);
            Ok(SyscallResult::Done(RetVal::new(0)))
        }
        SYS_POLL_CREATE => {
            let poll = poll_create(&current)?;
            Ok(SyscallResult::Done(poll.into()))
        }
        SYS_POLL_ADD => {
            let poll = HandleId::from_raw_isize(a0)?;
            let object = HandleId::from_raw_isize(a1)?;
            let interests = Readiness::from_raw_isize(a2)?;
            poll_add(&current, poll, object, interests)?;
            Ok(SyscallResult::Done(RetVal::new(0)))
        }
        SYS_POLL_REMOVE => {
            let poll = HandleId::from_raw_isize(a0)?;
            let object = HandleId::from_raw_isize(a1)?;
            poll_remove(&current, poll, object)?;
            Ok(SyscallResult::Done(RetVal::new(0)))
        }
        SYS_POLL_WAIT => {
            let poll = HandleId::from_raw_isize(a0)?;
            let ret = poll_wait(&current, poll);
            Ok(ret)
        }
        SYS_CHANNEL_CREATE => {
            let ch1 = channel_create(&current)?;
            Ok(SyscallResult::Done((ch1.into())))
        }
        SYS_CHANNEL_SEND => {
            let ch = HandleId::from_raw_isize(a0)?;
            let msginfo = MessageInfo::from_raw_isize(a1)?;
            let data = a2 as *const u8;
            let handles = a3 as *const HandleId;
            channel_send(&current, ch, msginfo, data, handles)?;
            Ok(SyscallResult::Done(RetVal::new(0)))
        }
        SYS_CHANNEL_RECV => {
            let handle = HandleId::from_raw_isize(a0)?;
            let data = a1 as *mut u8;
            let handles = a2 as *mut HandleId;
            let msginfo = channel_recv(&current, handle, data, handles)?;
            Ok(SyscallResult::Done(msginfo.into()))
        }
        SYS_VMSPACE_MAP => {
            let handle = HandleId::from_raw_isize(a0)?;
            let folio = HandleId::from_raw_isize(a1)?;
            let prot = PageProtect::from_raw_isize(a2)?;
            let ret = vmspace_map(&current, handle, folio, prot)?;
            Ok(SyscallResult::Done(ret.into()))
        }
        SYS_FOLIO_DADDR => {
            let handle = HandleId::from_raw_isize(a0)?;
            let daddr = folio_daddr(&current, handle)?;
            Ok(SyscallResult::Done(daddr.into()))
        }
        SYS_BUSIO_MAP => {
            let handle = HandleId::from_raw_isize(a0)?;
            let daddr = if a1 == 0 {
                None
            } else {
                Some(DAddr::new(a1 as usize))
            };
            let len = a2 as usize;
            let ret = busio_map(&current, handle, daddr, len)?;
            Ok(SyscallResult::Done(ret.into()))
        }
        SYS_INTERRUPT_CREATE => {
            let irq_matcher = IrqMatcher::from_raw_isize(a0)?;
            let ret = interrupt_create(&current, irq_matcher)?;
            Ok(SyscallResult::Done(ret.into()))
        }
        SYS_INTERRUPT_ACK => {
            let handle = HandleId::from_raw_isize(a0)?;
            interrupt_ack(&current, handle)?;
            Ok(SyscallResult::Done(RetVal::new(0)))
        }
        _ => {
            debug_warn!("unknown syscall: {}", n);
            Err(ErrorCode::InvalidSyscall)
        }
    }
}

pub extern "C" fn syscall_inkernel_handler(
    a0: isize,
    a1: isize,
    a2: isize,
    a3: isize,
    a4: isize,
    n: isize,
) -> ! {
    arch::kernel_scope(|| {
        let current = current_thread();
        let new_state = match do_syscall(a0, a1, a2, a3, a4, n, &current) {
            Ok(SyscallResult::Done(value)) => ThreadState::Runnable(Some(value.into())),
            Ok(SyscallResult::Err(err)) => ThreadState::Runnable(Some(err.into())),
            Ok(SyscallResult::Block(state)) => state,
            Err(err) => ThreadState::Runnable(Some(err.into())),
        };
        current.set_state(new_state);
    });

    switch_thread();
}
```
## kernel/thread.rs
```
use core::sync::atomic::AtomicUsize;
use core::sync::atomic::Ordering;

use starina_types::error::ErrorCode;
use starina_types::syscall::RetVal;

use crate::arch;
use crate::poll::Poll;
use crate::process::KERNEL_PROCESS;
use crate::process::Process;
use crate::refcount::SharedRef;
use crate::scheduler::GLOBAL_SCHEDULER;
use crate::spinlock::SpinLock;
use crate::syscall::SyscallResult;

static NUM_THREADS: AtomicUsize = AtomicUsize::new(0);

#[derive(Debug)]
pub enum ThreadState {
    Runnable(Option<RetVal>),
    BlockedByPoll(SharedRef<Poll>),
}

struct Mutable {
    state: ThreadState,
    arch: arch::Thread,
}

impl Mutable {
    unsafe fn arch_thread_ptr(&self) -> *mut arch::Thread {
        &raw const self.arch as *mut _
    }
}

pub struct Thread {
    mutable: SpinLock<Mutable>,
    process: SharedRef<Process>,
}

impl Thread {
    pub fn new_idle() -> Result<SharedRef<Thread>, ErrorCode> {
        SharedRef::new(Thread {
            mutable: SpinLock::new(Mutable {
                state: ThreadState::Runnable(None),
                arch: arch::Thread::new_idle(),
            }),
            process: KERNEL_PROCESS.clone(),
        })
    }

    pub fn new_inkernel(pc: usize, arg: usize) -> Result<SharedRef<Thread>, ErrorCode> {
        let thread = SharedRef::new(Thread {
            mutable: SpinLock::new(Mutable {
                state: ThreadState::Runnable(None), // TODO: Mark as blocked by default.
                arch: arch::Thread::new_inkernel(pc, arg),
            }),
            process: KERNEL_PROCESS.clone(),
        })?;

        let old_num_threads = NUM_THREADS.fetch_add(1, Ordering::Relaxed);
        GLOBAL_SCHEDULER.try_reserve_cap(old_num_threads + 1)?;

        GLOBAL_SCHEDULER.push(thread.clone());
        Ok(thread)
    }

    pub unsafe fn arch_thread_ptr(&self) -> *mut arch::Thread {
        let mutable = self.mutable.lock();
        unsafe { mutable.arch_thread_ptr() }
    }

    pub fn process(&self) -> &SharedRef<Process> {
        &self.process
    }

    pub fn wake(self: &SharedRef<Self>) {
        GLOBAL_SCHEDULER.push(self.clone());
    }

    pub fn set_state(self: &SharedRef<Thread>, new_state: ThreadState) {
        let mut mutable = self.mutable.lock();
        let was_blocked = !matches!(mutable.state, ThreadState::Runnable(_));

        // Update the thread's state.
        mutable.state = new_state;

        // If the thread is now runnable, push it to the scheduler.
        if was_blocked && matches!(mutable.state, ThreadState::Runnable(_)) {
            GLOBAL_SCHEDULER.push(self.clone());
        }
    }
}

impl Drop for Thread {
    fn drop(&mut self) {
        NUM_THREADS.fetch_sub(1, Ordering::Relaxed);
    }
}

/// Switches to the thread execution: save the current thread, picks the next
/// thread to run, and restores the next thread's context.
pub fn switch_thread() -> ! {
    'next_thread: loop {
        let (mut current_thread, is_idle, is_runnable) = {
            // Borrow the cpvuar inside a brace not to forget to drop it.
            let cpuvar = arch::get_cpuvar();

            let current_thread = cpuvar.current_thread.borrow_mut();
            let is_idle = SharedRef::ptr_eq(&*current_thread, &cpuvar.idle_thread);
            let is_runnable = matches!(
                current_thread.mutable.lock().state,
                ThreadState::Runnable(_)
            );
            (current_thread, is_idle, is_runnable)
        };

        let next = if is_runnable && !is_idle {
            // If the current thread is still runnable, prioritize it because
            // it might be sending multiple messages in a row.
            current_thread.clone()
        } else if let Some(next) = GLOBAL_SCHEDULER.schedule() {
            // Get the next thread to run. If the runqueue is empty, run the
            // idle thread.
            next
        } else {
            drop(current_thread);
            arch::idle();
        };

        // Try unblocking the next thread.
        let arch_thread = {
            let mut next_mutable = next.mutable.lock();
            let retval = match &next_mutable.state {
                ThreadState::BlockedByPoll(poll) => {
                    match poll.try_wait(&next) {
                        SyscallResult::Done(result) => {
                            // We've got an event. Resume the thread with a return
                            // value.
                            Some(result.into())
                        }
                        SyscallResult::Err(err) => {
                            // The poll is no longer valid. Return the error as a
                            // syscall result.
                            Some(err.into())
                        }
                        SyscallResult::Block(new_state) => {
                            // The thread is still blocked. We'll retry when the
                            // poll wakes us up again...
                            next_mutable.state = new_state;
                            continue 'next_thread;
                        }
                    }
                }
                ThreadState::Runnable(retval) => *retval,
            };

            // The thread is runnable. Get ready to restore the thread's context.
            unsafe {
                let arch = next_mutable.arch_thread_ptr();

                // If we're returning from a system call, set the return value.
                if let Some(retval) = retval {
                    (*arch).set_retval(retval);
                }

                arch
            }
        };

        // Switch to the next thread's address space.
        next.process().vmspace().switch();

        // Make the next thread the current thread.
        *current_thread = next;

        // Execute the pending continuation if any.
        drop(current_thread);
        arch::enter_userland(arch_thread);
    }
}
```
## kernel/utils/mmio.rs
```
#![allow(unused)]

use core::marker::PhantomData;

use starina::error::ErrorCode;
use starina_types::address::PAddr;
use starina_types::address::VAddr;

use crate::arch::paddr2vaddr;
use crate::folio::Folio;

#[allow(unused)]
pub trait Endianess {
    fn into_host_u16(&self, n: u16) -> u16;
    fn into_host_u32(&self, n: u32) -> u32;
    fn into_host_u64(&self, n: u64) -> u64;
    fn from_host_u16(&self, n: u16) -> u16;
    fn from_host_u32(&self, n: u32) -> u32;
    fn from_host_u64(&self, n: u64) -> u64;
}

pub struct LittleEndian;

impl Endianess for LittleEndian {
    fn into_host_u16(&self, n: u16) -> u16 {
        u16::from_le(n)
    }
    fn into_host_u32(&self, n: u32) -> u32 {
        u32::from_le(n)
    }
    fn into_host_u64(&self, n: u64) -> u64 {
        u64::from_le(n)
    }
    fn from_host_u16(&self, n: u16) -> u16 {
        u16::to_le(n)
    }
    fn from_host_u32(&self, n: u32) -> u32 {
        u32::to_le(n)
    }
    fn from_host_u64(&self, n: u64) -> u64 {
        u64::to_le(n)
    }
}

pub struct BigEndian;

impl Endianess for BigEndian {
    fn into_host_u16(&self, n: u16) -> u16 {
        u16::from_be(n)
    }
    fn into_host_u32(&self, n: u32) -> u32 {
        u32::from_be(n)
    }
    fn into_host_u64(&self, n: u64) -> u64 {
        u64::from_be(n)
    }
    fn from_host_u16(&self, n: u16) -> u16 {
        u16::to_be(n)
    }
    fn from_host_u32(&self, n: u32) -> u32 {
        u32::to_be(n)
    }
    fn from_host_u64(&self, n: u64) -> u64 {
        u64::to_be(n)
    }
}

pub trait Access {}
pub struct ReadOnly;
pub struct WriteOnly;
pub struct ReadWrite;

impl Access for ReadOnly {}
impl Access for WriteOnly {}
impl Access for ReadWrite {}

pub struct MmioReg<E: Endianess, A: Access, T: Copy> {
    offset: usize,
    _pd1: PhantomData<E>,
    _pd2: PhantomData<A>,
    _pd3: PhantomData<T>,
}

impl<E: Endianess, A: Access, T: Copy> MmioReg<E, A, T> {
    pub const fn new(offset: usize) -> MmioReg<E, A, T> {
        MmioReg {
            offset,
            _pd1: PhantomData,
            _pd2: PhantomData,
            _pd3: PhantomData,
        }
    }

    /// Reads a value from the MMIO region.
    ///
    /// # Why is `&mut F` required?
    ///
    /// This is to ensure that the caller has exclusive access to the MMIO
    /// region. This is important because reads from MMIO may have side effects
    /// (e.g. clearing an interrupt) and concurrent access to the same MMIO
    /// region might lead to unexpected behavior.
    ///
    /// TODO: What about memory ordering?
    fn do_read(&self, folio: &mut MmioFolio) -> T {
        self.do_read_with_offset(folio, 0)
    }

    pub fn do_read_with_offset(&self, folio: &mut MmioFolio, index: usize) -> T {
        let byte_offset = self.offset + index * size_of::<T>();
        assert!(byte_offset + size_of::<T>() <= folio.folio.len());

        let vaddr = folio.vaddr.as_usize() + byte_offset;

        unsafe { core::ptr::read_volatile(vaddr as *const T) }
    }

    fn do_write_with_offset(&self, folio: &mut MmioFolio, index: usize, value: T) {
        let byte_offset = self.offset + index * size_of::<T>();
        assert!(byte_offset + size_of::<T>() <= folio.folio.len());

        let vaddr = folio.vaddr.as_usize() + byte_offset;
        unsafe { core::ptr::write_volatile(vaddr as *mut T, value) };
    }

    fn do_write(&self, folio: &mut MmioFolio, value: T) {
        self.do_write_with_offset(folio, 0, value);
    }
}

impl<E: Endianess, T: Copy> MmioReg<E, ReadOnly, T> {
    pub fn read(&self, folio: &mut MmioFolio) -> T {
        self.do_read(folio)
    }

    pub fn read_with_offset(&self, folio: &mut MmioFolio, offset: usize) -> T {
        self.do_read_with_offset(folio, offset)
    }
}

impl<E: Endianess, T: Copy> MmioReg<E, WriteOnly, T> {
    pub fn write(&self, folio: &mut MmioFolio, value: T) {
        self.do_write(folio, value)
    }
}

impl<E: Endianess, T: Copy> MmioReg<E, ReadWrite, T> {
    pub fn read(&self, folio: &mut MmioFolio) -> T {
        self.do_read(folio)
    }

    pub fn read_with_offset(&self, folio: &mut MmioFolio, offset: usize) -> T {
        self.do_read_with_offset(folio, offset)
    }

    pub fn write(&self, folio: &mut MmioFolio, value: T) {
        self.do_write(folio, value)
    }

    pub fn write_with_offset(&self, folio: &mut MmioFolio, offset: usize, value: T) {
        self.do_write_with_offset(folio, offset, value)
    }
}

pub struct MmioFolio {
    folio: Folio,
    vaddr: VAddr,
}

impl MmioFolio {
    /// # Note
    ///
    /// `folio` must be already mapped to the kernel address space.
    pub fn from_folio(folio: Folio) -> Result<MmioFolio, ErrorCode> {
        let vaddr = paddr2vaddr(folio.paddr())?;
        Ok(MmioFolio { folio, vaddr })
    }

    pub fn paddr(&self) -> PAddr {
        self.folio.paddr()
    }
}
```
## kernel/utils/mod.rs
```
pub mod mmio;
```
## kernel/vmspace.rs
```
//! Virtual memory space management.
use starina::error::ErrorCode;
use starina::poll::Readiness;
use starina_types::address::PAddr;
use starina_types::address::VAddr;
use starina_types::vmspace::PageProtect;

use crate::arch;
use crate::folio::Folio;
use crate::handle::Handleable;
use crate::poll::Listener;
use crate::refcount::SharedRef;

pub static KERNEL_VMSPACE: spin::Lazy<SharedRef<VmSpace>> = spin::Lazy::new(|| {
    let vmspace = VmSpace::new().expect("failed to create kernel vmspace");
    SharedRef::new(vmspace).unwrap()
});

pub struct VmSpace {
    arch: arch::VmSpace,
}

impl VmSpace {
    pub fn new() -> Result<VmSpace, ErrorCode> {
        let arch = arch::VmSpace::new()?;
        Ok(VmSpace { arch })
    }

    pub fn arch(&self) -> &arch::VmSpace {
        &self.arch
    }

    pub fn map_anywhere(
        &self,
        folio: SharedRef<Folio>,
        prot: PageProtect,
    ) -> Result<VAddr, ErrorCode> {
        let paddr = folio.paddr();
        let len = folio.len();

        // The arch's page table will own an reference to the folio.
        core::mem::forget(folio);

        self.arch.map_anywhere(paddr, len, prot)
    }

    pub fn switch(&self) {
        self.arch.switch();
    }
}

impl Handleable for VmSpace {
    fn close(&self) {
        // Do nothing
    }

    fn add_listener(&self, _listener: Listener) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }

    fn remove_listener(&self, _poll: &crate::poll::Poll) -> Result<(), ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }

    fn readiness(&self) -> Result<Readiness, ErrorCode> {
        debug_warn!("unsupported method at {}:{}", file!(), line!());
        Err(ErrorCode::NotSupported)
    }
}
```
## libs/rust/driver_sdk/Cargo.toml
```
[package]
name = "starina_driver_sdk"
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "./lib.rs"

[dependencies]
starina = { workspace = true }
starina_utils = { workspace = true }
```
## libs/rust/driver_sdk/dma_buffer_pool.rs
```
//! A DMA buffer allocator.
//!
//! This module provides a buffer pool for DMA operations.
use starina::address::DAddr;
use starina::address::VAddr;
use starina::folio::MmioFolio;
use starina::iobus::IoBus;
use starina::prelude::vec::Vec;
use starina_utils::alignment::align_up;

/// A buffer identifier.
#[derive(Copy, Clone)]
pub struct BufferId(usize);

/// A DMA buffer pool.
///
/// This struct manages a pool of buffers. Unlike a `Vec`-based buffers, this
/// struct provides a way to know the physical memory address of a buffer so
/// that it can be passed to a device for DMA operations.
///
/// # Future Work
///
/// - Distinguish the physical memory address and device memory address. Some
///   computers might have different address spaces for devices, and some might
///   have IOMMU to translate the addresses.
///
/// # Example
///
/// ```no_run
/// use starina_driver_sdk::DmaBufferPool;
///
/// let iobus = todo!();
/// const BUFFER_SIZE: usize = 4096;
/// const NUM_BUFFERS: usize = 16;
///
/// let mut pool = DmaBufferPool::new(iobus, BUFFER_SIZE, NUM_BUFFERS);
/// let buffer_id = pool.allocate().unwrap();
///
/// let daddr = pool.daddr(buffer_id);
/// let vaddr = pool.vaddr(buffer_id);
///
/// // Do DMA operations here!
///
/// pool.free(buffer_id);
/// ```
pub struct DmaBufferPool {
    folio: MmioFolio,
    free_indices: Vec<BufferId>,
    buffer_size: usize,
    num_buffers: usize,
}

pub struct BufferWriter {
    vaddr: VAddr,
    daddr: DAddr,
    byte_offset: usize,
    size: usize,
}

impl BufferWriter {
    pub fn write_bytes(&mut self, data: &[u8]) -> Result<(), Error> {
        let dest = self.reserve(data.len())?;
        dest.copy_from_slice(data);
        Ok(())
    }

    /// Finishes the writes, and returns the start device address of the buffer.
    ///
    /// This requires `self` to ensure you won't write to the buffer anymore
    /// when telling the address to the device. In other words, the buffer will
    /// be moved to the device.
    pub fn finish(self) -> DAddr {
        self.daddr
    }

    pub fn write<T: Copy>(&mut self, value: T) -> Result<(), Error> {
        let dest = self.reserve(1)?;
        dest[0] = value;
        Ok(())
    }

    fn reserve<T: Copy>(&mut self, count: usize) -> Result<&mut [T], Error> {
        if self.byte_offset + count * size_of::<T>() > self.size {
            return Err(Error::OutOfMemory);
        }

        let slice = unsafe {
            let ptr = self.vaddr.add(self.byte_offset).as_mut_ptr();
            core::slice::from_raw_parts_mut(ptr, count)
        };

        self.byte_offset += size_of::<T>() * count;
        Ok(slice)
    }
}

pub struct BufferReader<'a> {
    slice: &'a [u8],
    byte_offset: usize,
}

impl<'a> BufferReader<'a> {
    pub fn read<T: Copy>(&mut self) -> Result<&T, Error> {
        let slice = self.reserve::<T>(1)?;
        Ok(&slice[0])
    }

    pub fn read_bytes(&mut self, count: usize) -> Result<&[u8], Error> {
        let slice = self.reserve::<u8>(count)?;
        Ok(slice)
    }

    fn reserve<T: Copy>(&mut self, count: usize) -> Result<&[T], Error> {
        let slice = unsafe {
            let bytes_ptr = self.slice.as_ptr().add(self.byte_offset);
            let ptr = bytes_ptr.cast::<T>();
            if !ptr.is_aligned() {
                return Err(Error::AlignmentError);
            }

            core::slice::from_raw_parts(ptr, count)
        };

        self.byte_offset += size_of::<T>() * count;
        Ok(slice)
    }
}

#[derive(Debug)]
pub enum Error {
    OutOfMemory,
    AlignmentError,
}

impl DmaBufferPool {
    pub fn new(iobus: &IoBus, buffer_size: usize, num_buffers: usize) -> DmaBufferPool {
        let len = align_up(buffer_size * num_buffers, 4096);
        let folio = MmioFolio::create(iobus, len).unwrap();
        let mut free_indices = Vec::new();
        for i in 0..num_buffers {
            free_indices.push(BufferId(i));
        }

        DmaBufferPool {
            folio,
            free_indices,
            buffer_size,
            num_buffers,
        }
    }

    /// Allocates a buffer.
    pub fn allocate(&mut self) -> Option<BufferId> {
        let id = self.free_indices.pop();
        id
    }

    /// Frees a buffer.
    pub fn free(&mut self, index: BufferId) {
        assert!(index.0 < self.num_buffers, "Invalid buffer index");
        self.free_indices.push(index);
    }

    /// Converts a physical memory address to a buffer index.
    pub fn daddr_to_id(&self, daddr: DAddr) -> Option<BufferId> {
        debug_assert!(
            daddr.as_usize() % self.buffer_size == 0,
            "daddr is not aligned"
        );

        // TODO: daddr may not be in the same folio
        let offset = daddr.as_usize() - self.folio.daddr().as_usize();
        let index = offset / self.buffer_size;
        if index < self.num_buffers {
            Some(BufferId(index))
        } else {
            None
        }
    }

    /// Returns the virtual memory address of a buffer.
    pub fn vaddr(&self, index: BufferId) -> VAddr {
        debug_assert!(index.0 < self.num_buffers);
        self.folio.vaddr().add(index.0 * self.buffer_size)
    }

    /// Returns the device memory address of a buffer.
    pub fn daddr(&self, index: BufferId) -> DAddr {
        debug_assert!(index.0 < self.num_buffers);
        self.folio.daddr().add(index.0 * self.buffer_size)
    }

    pub fn from_device(&mut self, daddr: DAddr) -> Option<BufferReader<'_>> {
        let id = self.daddr_to_id(daddr)?;

        let slice = unsafe {
            let ptr = self.vaddr(id).as_ptr();
            core::slice::from_raw_parts(ptr, self.buffer_size)
        };

        Some(BufferReader {
            slice,
            byte_offset: 0,
        })
    }

    pub fn to_device(&mut self) -> Result<BufferWriter, Error> {
        let index = self.allocate().ok_or(Error::OutOfMemory)?;
        let vaddr = self.vaddr(index);
        let daddr = self.daddr(index);

        Ok(BufferWriter {
            vaddr,
            daddr,
            byte_offset: 0,
            size: self.buffer_size,
        })
    }
}
```
## libs/rust/driver_sdk/lib.rs
```
#![no_std]

mod dma_buffer_pool;
pub mod mmio;

pub use dma_buffer_pool::DmaBufferPool;
```
## libs/rust/driver_sdk/mmio.rs
```
//! Type-safe MMIO register access.
//!
//! MMIO (Memory-Mapped I/O) is a mechanism to access hardware devices using
//! memory read and write operations. Unlike normal memory accesses, in MMIO,
//! you need to carefully handle endianness and unexpected compiler/CPU
//! optimizations. This module will help you.
//!
//! # Why is `&mut MmioFolio` required in `read` methods?
//!
//! This is to ensure that the caller has exclusive access to the MMIO
//! region. This is important because reads from MMIO may have side effects
//! (e.g. clearing an interrupt) and concurrent access to the same MMIO
//! region might lead to unexpected behavior.
//!
//! # Example (Goldfish RTC driver)
//!
//! In this example, two MMIO registers are defined: `TIME_LOW_REG` and
//! `TIME_HIGH_REG` and prints the current time read from the [Goldfish RTC](https://github.com/qemu/qemu/blob/master/hw/rtc/goldfish_rtc.c)
//! device.
//!
//! To access the MMIO registers, you need to acquire and map the MMIO region
//! using `MmioFolio::create_pinned`. Then, pass the mutable reference of
//! the `MmioFolio` to the `read` method of the MMIO register:
//!
//! ```no_run
//! use starina::prelude::*;
//! use starina::folio::MmioFolio;
//! use starina::address::DAddr;
//! use starina_driver_sdk::mmio::{LittleEndian, MmioReg, ReadOnly};
//!
//! let iobus = todo!();
//! const MMIO_BASE: DAddr = DAddr::new(0x101000);
//! const MMIO_SIZE: usize = 4096;
//!
//! static TIME_LOW_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x00);
//! static TIME_HIGH_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x04);
//!
//! let mut folio = MmioFolio::create_pinned(iobus, MMIO_BASE, MMIO_SIZE).unwrap();
//! let low: u32 = TIME_LOW_REG.read(&mut folio);
//! let high: u32 = TIME_HIGH_REG.read(&mut folio);
//! let now: u64 = (high as u64) << 32 | (low as u64);
//!
//! // If you want to convert the time to a human-readable format:
//! // date = chrono::DateTime::from_timestamp_nanos(now);
//! let now: i64 = now.try_into().unwrap();
//! info!("now: {now}");
//! ```
use core::marker::PhantomData;

use starina::folio::MmioFolio;

/// A trait for endianness conversion.
pub trait Endianess {
    /// Converts a device-endian `u16` to host-endian `u16`.
    fn into_host_u16(&self, n: u16) -> u16;
    /// Converts a device-endian `u32` to host-endian `u32`.
    fn into_host_u32(&self, n: u32) -> u32;
    /// Converts a device-endian `u64` to host-endian `u64`.
    fn into_host_u64(&self, n: u64) -> u64;
    /// Converts a host-endian `u16` to device-endian `u16`.
    fn from_host_u16(&self, n: u16) -> u16;
    /// Converts a host-endian `u32` to device-endian `u32`.
    fn from_host_u32(&self, n: u32) -> u32;
    /// Converts a host-endian `u64` to device-endian `u64`.
    fn from_host_u64(&self, n: u64) -> u64;
}

/// Little-endian endianness.
pub struct LittleEndian;

impl Endianess for LittleEndian {
    fn into_host_u16(&self, n: u16) -> u16 {
        u16::from_le(n)
    }
    fn into_host_u32(&self, n: u32) -> u32 {
        u32::from_le(n)
    }
    fn into_host_u64(&self, n: u64) -> u64 {
        u64::from_le(n)
    }
    fn from_host_u16(&self, n: u16) -> u16 {
        u16::to_le(n)
    }
    fn from_host_u32(&self, n: u32) -> u32 {
        u32::to_le(n)
    }
    fn from_host_u64(&self, n: u64) -> u64 {
        u64::to_le(n)
    }
}

/// Big-endian endianness.
pub struct BigEndian;

impl Endianess for BigEndian {
    fn into_host_u16(&self, n: u16) -> u16 {
        u16::from_be(n)
    }
    fn into_host_u32(&self, n: u32) -> u32 {
        u32::from_be(n)
    }
    fn into_host_u64(&self, n: u64) -> u64 {
        u64::from_be(n)
    }
    fn from_host_u16(&self, n: u16) -> u16 {
        u16::to_be(n)
    }
    fn from_host_u32(&self, n: u32) -> u32 {
        u32::to_be(n)
    }
    fn from_host_u64(&self, n: u64) -> u64 {
        u64::to_be(n)
    }
}

/// A trait for defining allowed access types.
pub trait Access {}

/// Read-only MMIO register.
pub struct ReadOnly;

/// Write-only MMIO register.
pub struct WriteOnly;

/// Read-write MMIO register.
pub struct ReadWrite;

impl Access for ReadOnly {}
impl Access for WriteOnly {}
impl Access for ReadWrite {}

/// A memory-mapped I/O register.
///
/// This struct defines a memory-mapped I/O register. It is parameterized by:
///
/// - `E`: Endianness of the register ([`LittleEndian`], [`BigEndian`]).
/// - `A`: Access type of the register ([`ReadOnly`], [`WriteOnly`], [`ReadWrite`]).
/// - `T`: Type of the register (`u8`, `u16`, `u32`, `u64`).
pub struct MmioReg<E: Endianess, A: Access, T: Copy> {
    offset: usize,
    _pd1: PhantomData<E>,
    _pd2: PhantomData<A>,
    _pd3: PhantomData<T>,
}

impl<E: Endianess, A: Access, T: Copy> MmioReg<E, A, T> {
    /// Defines a MMIO register.
    pub const fn new(offset: usize) -> MmioReg<E, A, T> {
        MmioReg {
            offset,
            _pd1: PhantomData,
            _pd2: PhantomData,
            _pd3: PhantomData,
        }
    }

    /// Reads a value from the MMIO register with an offset.
    ///
    /// This is useful when the MMIO register spans multiple words or unaligned
    /// length, such as MAC address (6 bytes).
    pub fn do_read_with_offset(&self, folio: &mut MmioFolio, offset: usize) -> T {
        let vaddr = folio.vaddr().as_usize() + self.offset + offset * size_of::<T>();
        unsafe { core::ptr::read_volatile(vaddr as *const T) }
    }

    fn do_write_with_offset(&self, folio: &mut MmioFolio, offset: usize, value: T) {
        let vaddr = folio.vaddr().as_usize() + self.offset + offset * size_of::<T>();
        unsafe { core::ptr::write_volatile(vaddr as *mut T, value) };
    }
}

impl<E: Endianess, T: Copy> MmioReg<E, ReadOnly, T> {
    /// Reads a value from the MMIO register.
    pub fn read(&self, folio: &mut MmioFolio) -> T {
        self.do_read_with_offset(folio, 0)
    }

    pub fn read_with_offset(&self, folio: &mut MmioFolio, offset: usize) -> T {
        self.do_read_with_offset(folio, offset)
    }
}

impl<E: Endianess, T: Copy> MmioReg<E, WriteOnly, T> {
    /// Writes a value to the MMIO register.
    pub fn write(&self, folio: &mut MmioFolio, value: T) {
        self.do_write_with_offset(folio, 0, value)
    }
}

impl<E: Endianess, T: Copy> MmioReg<E, ReadWrite, T> {
    /// Reads a value from the MMIO register.
    pub fn read(&self, folio: &mut MmioFolio) -> T {
        self.do_read_with_offset(folio, 0)
    }

    /// Writes a value to the MMIO register with an offset.
    pub fn read_with_offset(&self, folio: &mut MmioFolio, offset: usize) -> T {
        self.do_read_with_offset(folio, offset)
    }

    /// Writes a value to the MMIO register.
    pub fn write(&self, folio: &mut MmioFolio, value: T) {
        self.do_write_with_offset(folio, 0, value)
    }

    /// Writes a value to the MMIO register with an offset.
    pub fn write_with_offset(&self, folio: &mut MmioFolio, offset: usize, value: T) {
        self.do_write_with_offset(folio, offset, value)
    }
}
```
## libs/rust/starina/Cargo.toml
```
[package]
name = "starina"
publish = false
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
hashbrown = { workspace = true }
spin = { workspace = true }
starina_types = { workspace = true }
starina_utils = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }

[features]
in-kernel = []
```
## libs/rust/starina/channel.rs
```
use alloc::sync::Arc;

use crate::error::ErrorCode;
use crate::handle::HandleId;
use crate::handle::Handleable;
use crate::handle::OwnedHandle;
use crate::message::AnyMessage;
use crate::message::Messageable;
use crate::message::OwnedMessageBuffer;
use crate::syscall;

#[derive(Debug)]
pub struct Channel(OwnedHandle);

impl Channel {
    pub fn new() -> Result<(Self, Self), ErrorCode> {
        let (first, second) = syscall::channel_create()?;
        let first = Channel(OwnedHandle::from_raw(first));
        let second = Channel(OwnedHandle::from_raw(second));
        Ok((first, second))
    }

    pub fn from_handle(handle: OwnedHandle) -> Self {
        Self(handle)
    }

    pub fn send<'a>(&self, msg: impl Messageable<'a>) -> Result<(), ErrorCode> {
        let mut buffer = OwnedMessageBuffer::alloc();
        let msginfo = msg.write(&mut buffer)?;

        syscall::channel_send(
            self.0.id(),
            msginfo,
            buffer.data().as_ptr(),
            buffer.handles().as_ptr(),
        )?;

        buffer.mark_as_sent();

        Ok(())
    }

    pub fn recv(&self) -> Result<AnyMessage, ErrorCode> {
        let mut buffer = OwnedMessageBuffer::alloc();
        let msginfo = syscall::channel_recv(
            self.0.id(),
            buffer.data_mut().as_mut_ptr(),
            buffer.handles_mut().as_mut_ptr(),
        )?;

        let msg = unsafe { AnyMessage::new(buffer, msginfo) };
        Ok(msg)
    }

    pub fn split(self) -> (ChannelSender, ChannelReceiver) {
        let ch = Arc::new(self);
        let sender = ChannelSender(ch.clone());
        let receiver = ChannelReceiver(ch);
        (sender, receiver)
    }
}

impl Handleable for Channel {
    fn handle_id(&self) -> HandleId {
        self.0.id()
    }
}

impl<'de> serde::Deserialize<'de> for Channel {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let handle_id: i32 = serde::Deserialize::deserialize(deserializer)?;
        let handle = OwnedHandle::from_raw(HandleId::from_raw(handle_id));
        Ok(Channel(handle))
    }
}

#[derive(Debug, Clone)]
pub struct ChannelSender(Arc<Channel>);

#[derive(Debug)]
pub struct ChannelReceiver(Arc<Channel>);

impl ChannelSender {
    pub fn send<'a>(&self, writer: impl Messageable<'a>) -> Result<(), ErrorCode> {
        self.0.send(writer)
    }

    pub fn handle(&self) -> &OwnedHandle {
        &self.0.0
    }
}

impl ChannelReceiver {
    pub fn recv(&self) -> Result<AnyMessage, ErrorCode> {
        self.0.recv()
    }

    pub fn handle(&self) -> &OwnedHandle {
        &self.0.0
    }
}
```
## libs/rust/starina/collections.rs
```
pub use hash_map::HashMap;
pub use hash_set::HashSet;
pub use vec_deque::VecDeque;

pub mod hash_map {
    pub use hashbrown::hash_map::*;
}

pub mod hash_set {
    pub use hashbrown::hash_set::*;
}

pub mod vec_deque {
    pub use alloc::collections::vec_deque::*;
}
```
## libs/rust/starina/eventloop.rs
```
use alloc::sync::Arc;

use hashbrown::HashMap;
use serde::de::DeserializeOwned;
use starina_types::syscall::VsyscallPage;

use crate::channel::Channel;
use crate::channel::ChannelReceiver;
use crate::channel::ChannelSender;
use crate::error::ErrorCode;
use crate::handle::HandleId;
use crate::handle::Handleable;
use crate::handle::OwnedHandle;
use crate::interrupt::Interrupt;
use crate::message::AnyMessage;
use crate::message::ConnectMsg;
use crate::message::FramedDataMsg;
use crate::message::MessageKind;
use crate::message::Messageable;
use crate::message::OpenMsg;
use crate::message::OpenReplyMsg;
use crate::message::StreamDataMsg;
use crate::poll::Poll;
use crate::poll::Readiness;
use crate::tls;

pub trait EventLoop<E>: Send + Sync {
    fn init(dispatcher: &Dispatcher, env: E) -> Self
    where
        Self: Sized;

    #[allow(unused_variables)]
    fn on_connect(&self, ctx: &Context, msg: ConnectMsg) {
        debug_warn!("ignored connect message");
    }

    #[allow(unused_variables)]
    fn on_open(&self, ctx: &Context, msg: OpenMsg<'_>) {
        debug_warn!("ignored open message");
    }

    #[allow(unused_variables)]
    fn on_open_reply(&self, ctx: &Context, msg: OpenReplyMsg) {
        debug_warn!("ignored open-reply message");
    }

    #[allow(unused_variables)]
    fn on_framed_data(&self, _ctx: &Context, _msg: FramedDataMsg<'_>) {
        debug_warn!("ignored framed data message");
    }

    #[allow(unused_variables)]
    fn on_stream_data(&self, _ctx: &Context, _msg: StreamDataMsg<'_>) {
        debug_warn!("ignored stream data message");
    }

    #[allow(unused_variables)]
    fn on_unknown_message(&self, ctx: &Context, msg: AnyMessage) {
        debug_warn!("ignored message: {}", msg.msginfo.kind());
    }

    #[allow(unused_variables)]
    fn on_interrupt(&self, interrupt: &Interrupt) {
        debug_warn!("ignored interrupt");
    }
}

pub enum Object {
    Channel {
        receiver: ChannelReceiver,
        sender: ChannelSender,
    },
    Interrupt {
        interrupt: Interrupt,
    },
}

pub struct Context<'a> {
    pub sender: &'a ChannelSender,
    pub dispatcher: &'a Dispatcher,
}

pub struct Dispatcher {
    poll: Poll,
    objects: spin::RwLock<HashMap<HandleId, Arc<spin::Mutex<Object>>>>,
}

impl Dispatcher {
    pub fn new(poll: Poll) -> Self {
        Self {
            poll,
            objects: spin::RwLock::new(HashMap::new()),
        }
    }

    pub fn split_and_add_channel(&self, channel: Channel) -> Result<ChannelSender, ErrorCode> {
        let handle_id = channel.handle_id();

        // Tell the kernel to notify us when the channel is readable.
        self.poll.add(handle_id, Readiness::READABLE)?;

        // Register the channel in the dispatcher.
        let (sender, receiver) = channel.split();
        let object = Object::Channel {
            sender: sender.clone(),
            receiver,
        };
        self.objects
            .write()
            .insert(handle_id, Arc::new(spin::Mutex::new(object)));

        Ok(sender)
    }

    pub fn close_channel(&self, handle: HandleId) -> Result<(), ErrorCode> {
        // Remove the channel from the dispatcher.
        self.objects.write().remove(&handle);

        // Tell the kernel to stop notifying us about this channel.
        self.poll.remove(handle)?;

        Ok(())
    }

    pub fn add_channel(&self, channel: Channel) -> Result<(), ErrorCode> {
        let handle_id = channel.handle_id();

        // Tell the kernel to notify us when the channel is readable.
        self.poll.add(handle_id, Readiness::READABLE)?;

        // Register the channel in the dispatcher.
        let (sender, receiver) = channel.split();
        let object = Object::Channel { sender, receiver };
        self.objects
            .write()
            .insert(handle_id, Arc::new(spin::Mutex::new(object)));

        Ok(())
    }

    pub fn add_interrupt(&self, interrupt: Interrupt) -> Result<(), ErrorCode> {
        let handle_id = interrupt.handle_id();
        self.poll.add(handle_id, Readiness::READABLE)?;
        let object = Object::Interrupt { interrupt };
        self.objects
            .write()
            .insert(handle_id, Arc::new(spin::Mutex::new(object)));

        Ok(())
    }

    fn wait_and_dispatch<E>(&self, app: &impl EventLoop<E>) {
        let (handle, readiness) = self.poll.wait().unwrap();

        // TODO: Let poll API return an opaque pointer to the object so that
        //       we don't need to have this read-write lock.
        let object_lock = {
            let objects = self.objects.read();
            objects.get(&handle).cloned().expect("object not found")
        };

        let object = object_lock.lock();
        match &*object {
            Object::Channel { receiver, sender } => {
                if readiness.contains(Readiness::READABLE) {
                    let mut msg = receiver.recv().unwrap();
                    let ctx = Context {
                        sender,
                        dispatcher: self,
                    };

                    match msg.msginfo.kind() {
                        kind @ _ if kind == MessageKind::Connect as usize => {
                            match unsafe {
                                ConnectMsg::parse_unchecked(msg.msginfo, &mut msg.buffer)
                            } {
                                Some(msg) => app.on_connect(&ctx, msg),
                                None => {
                                    app.on_unknown_message(&ctx, msg);
                                }
                            };
                        }
                        kind @ _ if kind == MessageKind::Open as usize => {
                            match unsafe { OpenMsg::parse_unchecked(msg.msginfo, &mut msg.buffer) }
                            {
                                Some(msg) => app.on_open(&ctx, msg),
                                None => {
                                    app.on_unknown_message(&ctx, msg);
                                }
                            };
                        }
                        kind @ _ if kind == MessageKind::OpenReply as usize => {
                            match unsafe {
                                OpenReplyMsg::parse_unchecked(msg.msginfo, &mut msg.buffer)
                            } {
                                Some(msg) => app.on_open_reply(&ctx, msg),
                                None => {
                                    app.on_unknown_message(&ctx, msg);
                                }
                            };
                        }
                        kind @ _ if kind == MessageKind::FramedData as usize => {
                            match unsafe {
                                FramedDataMsg::parse_unchecked(msg.msginfo, &mut msg.buffer)
                            } {
                                Some(msg) => app.on_framed_data(&ctx, msg),
                                None => {
                                    app.on_unknown_message(&ctx, msg);
                                }
                            };
                        }
                        kind @ _ if kind == MessageKind::StreamData as usize => {
                            match unsafe {
                                StreamDataMsg::parse_unchecked(msg.msginfo, &mut msg.buffer)
                            } {
                                Some(msg) => app.on_stream_data(&ctx, msg),
                                None => {
                                    app.on_unknown_message(&ctx, msg);
                                }
                            };
                        }
                        _ => panic!("unexpected message kind: {}", msg.msginfo.kind()),
                    }
                }
            }
            Object::Interrupt { interrupt } => {
                if readiness.contains(Readiness::READABLE) {
                    app.on_interrupt(interrupt);
                }
            }
        }
    }
}

pub fn app_loop<E: DeserializeOwned, A: EventLoop<E>>(
    program_name: &'static str,
    vsyscall: *const VsyscallPage,
) {
    tls::init_thread_local(program_name);

    let env_json = unsafe {
        let ptr = (*vsyscall).environ_ptr;
        let len = (*vsyscall).environ_len;
        core::slice::from_raw_parts(ptr, len)
    };

    let startup_ch = unsafe {
        let id = (*vsyscall).startup_ch;
        if id.as_raw() == 0 {
            None
        } else {
            Some(Channel::from_handle(OwnedHandle::from_raw(id)))
        }
    };

    let env: E = serde_json::from_slice(&env_json).expect("failed to parse env");

    let poll = Poll::create().unwrap();
    let dispatcher = Dispatcher::new(poll);

    if let Some(ch) = startup_ch {
        dispatcher.add_channel(ch).unwrap();
    }

    let app = A::init(&dispatcher, env);

    loop {
        dispatcher.wait_and_dispatch(&app);
    }
}
```
## libs/rust/starina/folio.rs
```
//! A contiguous page-aliged memory block.
use starina_types::address::DAddr;
use starina_types::address::VAddr;
use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
use starina_types::vmspace::PageProtect;
use starina_utils::alignment::is_aligned;

use crate::handle::OwnedHandle;
use crate::iobus::IoBus;
use crate::syscall;

/// The ownership of a contiguous page-aliged memory region.
///
/// To summarize:
///
/// - The memory block address is page-aligned (typically 4KB).
/// - The memory block size is also page-aligned.
/// - The memory block is *physically* contiguous.
///
/// # When to use
///
/// Use folio when you need a *physically contiguous* memory region. The common
/// case is when you need to allocate a DMA buffer in a device driver (strictly
/// speaking, when IOMMU is not available).
///
/// # Prefer [`Box<T>`](crate::prelude::Box) over folio
///
/// Unless you need low-level control over memory allocation, use containers
/// like [`Vec<T>`](crate::prelude::Vec) or [`Box<T>`](crate::prelude::Box)
/// memory regions directly, such as DMA buffers, MMIO regions, and shared
/// instead of folio. Folio is intended for OS services that need to manage
/// memory between processes.
///
/// # You may want [`MappedFolio`] instead
///
/// If you want to access the memory region, use [`MappedFolio`] instead.
///
/// # Why "folio"?
///
/// Because it's *a sheet of paper (pages)*.
pub struct Folio {
    handle: OwnedHandle,
}

impl Folio {
    pub const fn from_handle(handle: OwnedHandle) -> Self {
        Self { handle }
    }

    pub fn daddr(&self) -> Result<DAddr, ErrorCode> {
        syscall::folio_daddr(self.handle.id())
    }
}

const SELF_VMSPACE: HandleId = HandleId::from_raw(0);

pub struct MmioFolio {
    _folio: Folio,
    daddr: DAddr,
    vaddr: VAddr,
    len: usize,
}

impl MmioFolio {
    /// Allocates a folio at an arbitrary physical address, and maps it to the
    /// current process's address space.
    pub fn create(bus: &IoBus, len: usize) -> Result<MmioFolio, ErrorCode> {
        debug_assert!(is_aligned(len, 0x1000));

        let folio = bus.map(None, len)?;
        let vaddr = syscall::vmspace_map(
            SELF_VMSPACE,
            folio.handle.id(),
            PageProtect::READABLE | PageProtect::WRITEABLE,
        )?;

        let daddr = folio.daddr()?;

        Ok(MmioFolio {
            _folio: folio,
            daddr,
            vaddr,
            len,
        })
    }

    /// Allocates a folio at a specific physical address (`paddr`), and maps it to the
    /// current process's address space.
    pub fn create_pinned(bus: &IoBus, daddr: DAddr, len: usize) -> Result<MmioFolio, ErrorCode> {
        debug_assert!(is_aligned(daddr.as_usize(), 0x1000));
        debug_assert!(is_aligned(len, 0x1000));

        let folio = bus.map(Some(daddr), len)?;
        let vaddr = syscall::vmspace_map(
            SELF_VMSPACE,
            folio.handle.id(),
            PageProtect::READABLE | PageProtect::WRITEABLE,
        )?;

        Ok(MmioFolio {
            _folio: folio,
            daddr,
            vaddr,
            len,
        })
    }

    //// # Safety
    ///
    /// <https://doc.rust-lang.org/std/ptr/index.html#pointer-to-reference-conversion>
    pub unsafe fn as_ref<T: Copy>(&self, byte_offset: usize) -> &T {
        assert!(byte_offset + size_of::<T>() <= self.len);
        assert!(is_aligned(byte_offset, align_of::<T>()));

        let ptr = unsafe { self.vaddr.add(byte_offset).as_ptr::<T>() };
        unsafe { &*ptr }
    }

    //// # Safety
    ///
    /// <https://doc.rust-lang.org/std/ptr/index.html#pointer-to-reference-conversion>
    pub unsafe fn as_mut<T: Copy>(&mut self, byte_offset: usize) -> &mut T {
        assert!(byte_offset + size_of::<T>() <= self.len);
        assert!(is_aligned(byte_offset, align_of::<T>()));

        let ptr = unsafe { self.vaddr.add(byte_offset).as_mut_ptr::<T>() };
        unsafe { &mut *ptr }
    }

    pub fn vaddr(&self) -> VAddr {
        self.vaddr
    }

    /// Returns the start address of the folio in device memory space.
    pub fn daddr(&self) -> DAddr {
        self.daddr
    }
}

/// Returns the page size.
///
/// # Why not a constant?
///
/// To make it easy to support non-4KB pages, reading it from the kernel
/// (ala `sysconf(_SC_PAGESIZE)`) in the future.
pub fn page_size() -> usize {
    4096
}
```
## libs/rust/starina/handle.rs
```
pub use starina_types::handle::*;

#[derive(Debug)]
pub struct OwnedHandle(HandleId);

impl OwnedHandle {
    pub const fn from_raw(raw: HandleId) -> Self {
        Self(raw)
    }

    pub fn id(&self) -> HandleId {
        self.0
    }
}

impl Drop for OwnedHandle {
    fn drop(&mut self) {
        warn!("dropping handle {:?}", self.0);
    }
}

pub trait Handleable {
    fn handle_id(&self) -> HandleId;
}
```
## libs/rust/starina/interrupt.rs
```
//! A hardware interrupt object.
use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
pub use starina_types::interrupt::*;

use crate::handle::Handleable;
use crate::handle::OwnedHandle;
use crate::syscall;

/// A hardware interrupt object.
///
/// This object provides functionalities to handle hardware interrupts from devices
/// in device drivers:
///
/// - Enable interrupts by acquiring the object ([`Interrupt::create`]).
/// - Acknowledge the interrupt ([`Interrupt::acknowledge`]).
/// - Wait for interrupts in an event loop ([`Mainloop::add_interrupt`](crate::mainloop::Mainloop::add_interrupt))
pub struct Interrupt {
    handle: OwnedHandle,
}

impl Interrupt {
    /// Creates a new interrupt object for the given IRQ.
    pub fn create(irq_matcher: IrqMatcher) -> Result<Interrupt, ErrorCode> {
        let handle = syscall::interrupt_create(irq_matcher)?;
        let interrupt = Interrupt {
            handle: OwnedHandle::from_raw(handle),
        };

        Ok(interrupt)
    }

    /// Instantiates the object from the given handle.
    pub fn from_handle(handle: OwnedHandle) -> Interrupt {
        Interrupt { handle }
    }

    /// Returns the handle.
    pub fn handle(&self) -> &OwnedHandle {
        &self.handle
    }

    /// Acknowledges the interrupt.
    ///
    /// This tells the CPU (or the interrupt controller) that the interrupt has
    /// been handled and we are ready to receive the next one.
    pub fn acknowledge(&self) -> Result<(), ErrorCode> {
        syscall::interrupt_ack(self.handle().id())
    }
}

impl Handleable for Interrupt {
    fn handle_id(&self) -> HandleId {
        self.handle.id()
    }
}
```
## libs/rust/starina/iobus.rs
```
use starina_types::handle::HandleId;

use crate::address::DAddr;
use crate::error::ErrorCode;
use crate::folio::Folio;
use crate::handle::OwnedHandle;
use crate::syscall;

pub struct IoBus {
    handle: OwnedHandle,
}

impl IoBus {
    pub fn map(&self, daddr: Option<DAddr>, len: usize) -> Result<Folio, ErrorCode> {
        let handle = syscall::iobus_map(self.handle.id(), daddr, len)?;
        Ok(Folio::from_handle(OwnedHandle::from_raw(handle)))
    }
}

impl<'de> serde::Deserialize<'de> for IoBus {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let handle_id: i32 = serde::Deserialize::deserialize(deserializer)?;
        let handle = OwnedHandle::from_raw(HandleId::from_raw(handle_id));
        Ok(IoBus { handle })
    }
}
```
## libs/rust/starina/lib.rs
```
#![no_std]
#![feature(pointer_is_aligned_to)]
#![cfg_attr(test, feature(test))]

extern crate alloc;

pub use starina_types::address;
pub use starina_types::device_tree;
pub use starina_types::error;
pub use starina_types::spec;

#[macro_use]
pub mod log;

pub mod channel;
pub mod collections;
pub mod eventloop;
pub mod folio;
pub mod handle;
pub mod interrupt;
pub mod iobus;
pub mod message;
pub mod poll;
pub mod prelude;
pub mod syscall;
pub mod tls;
```
## libs/rust/starina/log.rs
```
use crate::prelude::Vec;

/// The console output writer.
///
/// This is an internal implementation detail of the `print!` and `println!`
/// macros. You should use those macros, not this struct directly.
struct Printer {
    buf: spin::Mutex<Vec<u8>>,
}

static GLOBAL_PRINTER: Printer = Printer::new();

impl Printer {
    const fn new() -> Printer {
        Printer {
            buf: spin::Mutex::new(Vec::new()),
        }
    }

    fn write_str(&self, s: &str) {
        let mut buf = self.buf.lock();
        for b in s.bytes() {
            buf.push(b);
            if b == b'\n' {
                let old_buf = core::mem::replace(&mut *buf, Vec::with_capacity(128));
                // Do not hold the lock while writing to the console. This
                // printer could be shared between multiple apps/threads,
                // and the kernel may switch to another app/thread.
                drop(buf);
                crate::syscall::console_write(&old_buf);
                buf = self.buf.lock();
            }
        }
    }
}

pub struct GlobalPrinter;

impl core::fmt::Write for GlobalPrinter {
    fn write_str(&mut self, s: &str) -> core::fmt::Result {
        GLOBAL_PRINTER.write_str(s);
        Ok(())
    }
}

/// Prints a string without a newline.
#[macro_export]
macro_rules! print {
    ($($arg:tt)*) => {{
        #![allow(unused_imports)]
        use core::fmt::Write;
        write!($crate::log::GlobalPrinter, $($arg)*).ok();
    }};
}

/// Prints a string and a newline.
#[macro_export]
macro_rules! println {
    () => {{
        $crate::print!(
            "\n"
        );
    }};
    ($fmt:expr) => {{
        $crate::print!(
            concat!($fmt, "\n")
        );
    }};
    ($fmt:expr, $($arg:tt)*) => {{
        $crate::print!(
            concat!($fmt, "\n"),
            $($arg)*
        );
    }};
}

#[derive(Clone, Copy, PartialEq, Eq, Ord, PartialOrd)]
#[allow(dead_code)]
pub enum LogLevel {
    Error,
    Warn,
    Info,
    Debug,
    Trace,
}

#[macro_export]
macro_rules! log {
    ($level:expr, $($arg:tt)+) => {{
        use $crate::log::LogLevel;

        const RESET_COLOR: &str = "\x1b[0m";

        if cfg!(debug_assertions) || $level <= LogLevel::Info {
            let (color, level_str) = match $level {
                LogLevel::Error => ("\x1b[91m", "ERR"),
                LogLevel::Warn =>  ("\x1b[33m", "WARN"),
                LogLevel::Info =>  ("\x1b[96m", "INFO"),
                LogLevel::Debug => ("\x1b[0m", "DEBUG"),
                LogLevel::Trace => ("\x1b[0m", "TRACE"),
            };

            $crate::println!(
                "[{:<12}] {}{:6}{} {}",
                $crate::tls::thread_local().name,
                color,
                level_str,
                RESET_COLOR,
                format_args!($($arg)+)
            );
        }
    }};
}

#[macro_export]
macro_rules! error {
    ($($arg:tt)+) => { $crate::log!($crate::log::LogLevel::Error, $($arg)+) }
}

#[macro_export]
macro_rules! warn {
    ($($arg:tt)+) => { $crate::log!($crate::log::LogLevel::Warn, $($arg)+) }
}

#[macro_export]
macro_rules! info {
    ($($arg:tt)+) => { $crate::log!($crate::log::LogLevel::Info, $($arg)+) }
}

#[macro_export]
macro_rules! debug {
    ($($arg:tt)+) => { $crate::log!($crate::log::LogLevel::Debug, $($arg)+) }
}

#[macro_export]
macro_rules! trace {
    ($($arg:tt)+) => { $crate::log!($crate::log::LogLevel::Trace, $($arg)+) }
}

/// Print kernel message with backtraces.
#[macro_export]
macro_rules! oops {
    ($($args:tt)*) => {{
        $crate::println!($($args)*);
    }};
}

#[macro_export]
macro_rules! debug_warn {
    ($($arg:tt)+) => {
        if cfg!(debug_assertions) {
            $crate::warn!($($arg)+);
        }
    };
}
```
## libs/rust/starina/message.rs
```
use alloc::boxed::Box;
use core::ops::Deref;
use core::ops::DerefMut;

use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
pub use starina_types::message::*;

use crate::channel::Channel;
use crate::handle::Handleable;
use crate::handle::OwnedHandle;
use crate::syscall;

pub struct MessageBuffer {
    data: [u8; MESSAGE_DATA_LEN_MAX],
    handles: [HandleId; MESSAGE_NUM_HANDLES_MAX],
}

impl MessageBuffer {
    pub fn zeroed() -> Self {
        Self {
            data: [0; MESSAGE_DATA_LEN_MAX],
            handles: [HandleId::from_raw(0); MESSAGE_NUM_HANDLES_MAX],
        }
    }

    pub const fn data(&self) -> &[u8] {
        &self.data
    }

    pub const fn handles(&self) -> &[HandleId] {
        &self.handles
    }

    pub fn data_mut(&mut self) -> &mut [u8] {
        &mut self.data
    }

    pub fn handles_mut(&mut self) -> &mut [HandleId] {
        &mut self.handles
    }

    pub unsafe fn data_as_ref<T>(&self) -> &T {
        debug_assert!(size_of::<T>() <= MESSAGE_DATA_LEN_MAX);
        debug_assert!(self.data.as_ptr().is_aligned_to(align_of::<T>()));

        unsafe { &*(self.data.as_ptr() as *const T) }
    }

    pub unsafe fn data_as_mut<T>(&mut self) -> &mut T {
        debug_assert!(size_of::<T>() <= MESSAGE_DATA_LEN_MAX);
        debug_assert!(self.data.as_ptr().is_aligned_to(align_of::<T>()));

        unsafe { &mut *(self.data.as_mut_ptr() as *mut T) }
    }
}

#[derive(Clone, Copy, PartialEq, Eq, Debug)]
#[repr(u8)]
pub enum MessageKind {
    Connect = 1,
    Open = 3,
    OpenReply = 4,
    StreamData = 5,
    FramedData = 6,
}

pub trait Messageable<'a> {
    fn kind() -> MessageKind;
    fn write(self, buffer: &mut MessageBuffer) -> Result<MessageInfo, ErrorCode>;
    unsafe fn parse_unchecked(msginfo: MessageInfo, buffer: &'a mut MessageBuffer) -> Option<Self>
    where
        Self: Sized;
}

pub const URI_LEN_MAX: usize = 1024;

pub struct ConnectMsg {
    pub handle: Channel,
}

impl<'a> Messageable<'a> for ConnectMsg {
    fn kind() -> MessageKind {
        MessageKind::Connect
    }

    fn write(self, buffer: &mut MessageBuffer) -> Result<MessageInfo, ErrorCode> {
        let handle = self.handle;
        buffer.handles[0] = handle.handle_id();

        // Avoid dropping the handle. It will be moved to the channel.
        core::mem::forget(handle);

        Ok(MessageInfo::new(MessageKind::Connect as i32, 0, 1))
    }

    unsafe fn parse_unchecked(
        _msginfo: MessageInfo,
        buffer: &'a mut MessageBuffer,
    ) -> Option<Self> {
        let handle = buffer.handles[0];
        buffer.handles[0] = HandleId::from_raw(0); // Avoid dropping the handle.

        Some(ConnectMsg {
            handle: Channel::from_handle(OwnedHandle::from_raw(handle)),
        })
    }
}

struct RawOpen {
    uri: [u8; URI_LEN_MAX],
}

pub struct OpenMsg<'a> {
    pub uri: &'a str,
}

impl<'a> Messageable<'a> for OpenMsg<'a> {
    fn kind() -> MessageKind {
        MessageKind::Open
    }

    unsafe fn parse_unchecked(msginfo: MessageInfo, buffer: &'a mut MessageBuffer) -> Option<Self> {
        let raw = unsafe { buffer.data_as_ref::<RawOpen>() };
        let uri = unsafe { core::str::from_utf8_unchecked(&raw.uri[..msginfo.data_len()]) };
        Some(OpenMsg { uri })
    }

    fn write(self, buffer: &mut MessageBuffer) -> Result<MessageInfo, ErrorCode> {
        let raw = unsafe { buffer.data_as_mut::<RawOpen>() };
        if self.uri.len() > URI_LEN_MAX {
            return Err(ErrorCode::TooLongUri);
        }

        raw.uri[..self.uri.len()].copy_from_slice(self.uri.as_bytes());
        Ok(MessageInfo::new(
            MessageKind::Open as i32,
            self.uri.len() as u16,
            0,
        ))
    }
}

pub struct OpenReplyMsg {
    pub handle: Channel,
}

impl<'a> Messageable<'a> for OpenReplyMsg {
    fn kind() -> MessageKind {
        MessageKind::OpenReply
    }

    fn write(self, buffer: &mut MessageBuffer) -> Result<MessageInfo, ErrorCode> {
        let handle = self.handle;
        buffer.handles[0] = handle.handle_id();

        // Avoid dropping the handle. It will be moved to the channel.
        core::mem::forget(handle);

        Ok(MessageInfo::new(MessageKind::OpenReply as i32, 0, 1))
    }

    unsafe fn parse_unchecked(
        _msginfo: MessageInfo,
        buffer: &'a mut MessageBuffer,
    ) -> Option<Self> {
        let handle = buffer.handles[0];
        buffer.handles[0] = HandleId::from_raw(0); // Avoid dropping the handle.

        Some(OpenReplyMsg {
            handle: Channel::from_handle(OwnedHandle::from_raw(handle)),
        })
    }
}

pub struct FramedDataMsg<'a> {
    pub data: &'a [u8],
}

impl<'a> Messageable<'a> for FramedDataMsg<'a> {
    fn kind() -> MessageKind {
        MessageKind::FramedData
    }

    unsafe fn parse_unchecked(msginfo: MessageInfo, buffer: &'a mut MessageBuffer) -> Option<Self> {
        let data = &buffer.data[..msginfo.data_len()];
        Some(FramedDataMsg { data })
    }

    fn write(self, buffer: &mut MessageBuffer) -> Result<MessageInfo, ErrorCode> {
        if self.data.len() > buffer.data.len() {
            return Err(ErrorCode::TooLarge);
        }

        buffer.data[..self.data.len()].copy_from_slice(self.data);
        Ok(MessageInfo::new(
            MessageKind::FramedData as i32,
            self.data.len() as u16,
            0,
        ))
    }
}

pub struct StreamDataMsg<'a> {
    pub data: &'a [u8],
}

impl<'a> Messageable<'a> for StreamDataMsg<'a> {
    fn kind() -> MessageKind {
        MessageKind::StreamData
    }

    unsafe fn parse_unchecked(msginfo: MessageInfo, buffer: &'a mut MessageBuffer) -> Option<Self> {
        let data = &buffer.data[..msginfo.data_len()];
        Some(StreamDataMsg { data })
    }

    fn write(self, buffer: &mut MessageBuffer) -> Result<MessageInfo, ErrorCode> {
        if self.data.len() > buffer.data.len() {
            return Err(ErrorCode::TooLarge);
        }

        buffer.data[..self.data.len()].copy_from_slice(self.data);
        Ok(MessageInfo::new(
            MessageKind::StreamData as i32,
            self.data.len() as u16,
            0,
        ))
    }
}

pub struct OwnedMessageBuffer(Box<MessageBuffer>);

impl OwnedMessageBuffer {
    pub fn alloc() -> Self {
        // TODO: Have a thread-local buffer pool.
        // TODO: Use `MaybeUninit` to unnecesarily zero-fill the buffer.
        let buffer = Box::new(MessageBuffer::zeroed());
        OwnedMessageBuffer(buffer)
    }

    pub fn mark_as_sent(&mut self) {
        // Mark the handles as sent.
        for handle in self.0.handles_mut() {
            *handle = HandleId::from_raw(0);
        }
    }
}

impl Deref for OwnedMessageBuffer {
    type Target = MessageBuffer;

    fn deref(&self) -> &Self::Target {
        &self.0
    }
}

impl DerefMut for OwnedMessageBuffer {
    fn deref_mut(&mut self) -> &mut Self::Target {
        &mut self.0
    }
}

impl Drop for OwnedMessageBuffer {
    fn drop(&mut self) {
        // Drop handles.
        for handle in self.0.handles() {
            if handle.as_raw() != 0 {
                if let Err(e) = syscall::handle_close(*handle) {
                    debug_warn!("failed to close handle: {:?}", e);
                }
            }
        }
    }
}

pub struct AnyMessage {
    pub msginfo: MessageInfo,
    pub buffer: OwnedMessageBuffer,
}

impl AnyMessage {
    pub unsafe fn new(buffer: OwnedMessageBuffer, msginfo: MessageInfo) -> Self {
        Self { buffer, msginfo }
    }
}
```
## libs/rust/starina/poll.rs
```
pub use starina_types::poll::*;

use crate::error::ErrorCode;
use crate::handle::HandleId;
use crate::handle::Handleable;
use crate::handle::OwnedHandle;
use crate::syscall;

pub struct Poll(OwnedHandle);

impl Poll {
    pub fn create() -> Result<Self, ErrorCode> {
        let poll = syscall::poll_create()?;
        Ok(Self(OwnedHandle::from_raw(poll)))
    }

    pub fn add(&self, object: HandleId, interests: Readiness) -> Result<(), ErrorCode> {
        syscall::poll_add(self.0.id(), object, interests)
    }

    pub fn remove(&self, object: HandleId) -> Result<(), ErrorCode> {
        syscall::poll_remove(self.0.id(), object)
    }

    pub fn wait(&self) -> Result<(HandleId, Readiness), ErrorCode> {
        syscall::poll_wait(self.0.id())
    }
}

impl Handleable for Poll {
    fn handle_id(&self) -> HandleId {
        self.0.id()
    }
}
```
## libs/rust/starina/prelude.rs
```
//! Frequently used types and traits.
//!
//! This module contains the most common types and traits to import. Here is an
//! idiomatic way to import the prelude:
//!
//! ```
//! use starina::prelude::*;
//!
//! let mut v = Vec::new();
//! v.push(1);
//! ```
//!
//! # What's in the prelude?
//!
//! Since Starina apps are `#![no_std]` crates, this prelude includes types from
//! [`alloc`](https://doc.rust-lang.org/alloc/index.html) so that experienced
//! Rust programmers can use familiar types without asking *"Where is `Vec`?"*.
//!
//! # Why should I use the prelude?
//!
//! You don't have to use the prelude. However, it's a convenient way to
//! reduce the number of your keystrokes.
pub use alloc::borrow::ToOwned;
pub use alloc::boxed::Box;
pub use alloc::format;
pub use alloc::string::String;
pub use alloc::string::ToString;
pub use alloc::vec;
pub use alloc::vec::Vec;

pub use crate::debug;
pub use crate::debug_warn;
pub use crate::error;
pub use crate::info;
pub use crate::trace;
pub use crate::warn;
```
## libs/rust/starina/syscall.rs
```
use starina_types::address::DAddr;
use starina_types::address::VAddr;
use starina_types::error::ErrorCode;
use starina_types::handle::HandleId;
use starina_types::interrupt::IrqMatcher;
use starina_types::message::MessageInfo;
use starina_types::poll::Readiness;
pub use starina_types::syscall::*;
use starina_types::vmspace::PageProtect;

fn syscall(
    n: u8,
    a0: isize,
    a1: isize,
    a2: isize,
    a3: isize,
    a4: isize,
) -> Result<RetVal, ErrorCode> {
    if cfg!(feature = "in-kernel") {
        unsafe extern "C" {
            fn enter_kernelland(
                _a0: isize,
                _a1: isize,
                _a2: isize,
                _a3: isize,
                _a4: isize,
                _a5: isize,
            ) -> RetVal;
        }

        unsafe {
            let ret = enter_kernelland(a0, a1, a2, a3, a4, n as isize);
            if ret.as_isize() < 0 {
                Err(ErrorCode::from(ret.as_isize()))
            } else {
                Ok(ret)
            }
        }
    } else {
        unimplemented!()
    }
}

pub fn console_write(s: &[u8]) {
    let _ = syscall(
        SYS_CONSOLE_WRITE,
        s.as_ptr() as isize,
        s.len().try_into().unwrap(),
        0,
        0,
        0,
    );
}

pub fn poll_create() -> Result<HandleId, ErrorCode> {
    let ret = syscall(SYS_POLL_CREATE, 0, 0, 0, 0, 0)?;
    // SAFETY: The syscall returns a valid handle ID.
    let id = unsafe { HandleId::from_raw_isize(ret.as_isize()).unwrap_unchecked() };
    Ok(id)
}

pub fn poll_add(poll: HandleId, object: HandleId, interests: Readiness) -> Result<(), ErrorCode> {
    syscall(
        SYS_POLL_ADD,
        poll.as_raw() as isize,
        object.as_raw() as isize,
        interests.as_isize(),
        0,
        0,
    )?;
    Ok(())
}

pub fn poll_remove(poll: HandleId, object: HandleId) -> Result<(), ErrorCode> {
    syscall(
        SYS_POLL_REMOVE,
        poll.as_raw() as isize,
        object.as_raw() as isize,
        0,
        0,
        0,
    )?;
    Ok(())
}

pub fn poll_wait(poll: HandleId) -> Result<(HandleId, Readiness), ErrorCode> {
    let ret = syscall(SYS_POLL_WAIT, poll.as_raw() as isize, 0, 0, 0, 0)?;
    let (id, readiness) = ret.into();
    Ok((id, readiness))
}

pub fn channel_create() -> Result<(HandleId, HandleId), ErrorCode> {
    let ret = syscall(SYS_CHANNEL_CREATE, 0, 0, 0, 0, 0)?;
    let first: HandleId = ret.into();
    let second = HandleId::from_raw(first.as_raw() + 1);
    Ok((first, second))
}

pub fn channel_send(
    ch: HandleId,
    msginfo: MessageInfo,
    data: *const u8,
    handles: *const HandleId,
) -> Result<(), ErrorCode> {
    syscall(
        SYS_CHANNEL_SEND,
        ch.as_raw() as isize,
        msginfo.as_raw(),
        data as isize,
        handles as isize,
        0,
    )?;
    Ok(())
}

pub fn channel_recv(
    ch: HandleId,
    data: *mut u8,
    handles: *mut HandleId,
) -> Result<MessageInfo, ErrorCode> {
    let ret = syscall(
        SYS_CHANNEL_RECV,
        ch.as_raw() as isize,
        data as isize,
        handles as isize,
        0,
        0,
    )?;
    // SAFETY: The syscall returns a valid message info.
    let msginfo = unsafe { MessageInfo::from_raw_isize(ret.as_isize()).unwrap_unchecked() };
    Ok(msginfo)
}

pub fn handle_close(handle: HandleId) -> Result<(), ErrorCode> {
    syscall(SYS_HANDLE_CLOSE, handle.as_raw() as isize, 0, 0, 0, 0)?;
    Ok(())
}

pub fn iobus_map(iobus: HandleId, daddr: Option<DAddr>, len: usize) -> Result<HandleId, ErrorCode> {
    let ret = syscall(
        SYS_BUSIO_MAP,
        iobus.as_raw() as isize,
        daddr.map_or(0, |daddr| daddr.as_usize() as isize),
        len.try_into().unwrap(),
        0,
        0,
    )?;

    // SAFETY: The syscall returns a valid handle ID.
    let id = unsafe { HandleId::from_raw_isize(ret.as_isize()).unwrap_unchecked() };
    Ok(id)
}

pub fn folio_daddr(handle: HandleId) -> Result<DAddr, ErrorCode> {
    let ret = syscall(SYS_FOLIO_DADDR, handle.as_raw() as isize, 0, 0, 0, 0)?;
    // SAFETY: The syscall returns a valid device address.
    let daddr = DAddr::new(ret.as_isize() as usize);
    Ok(daddr)
}

pub fn vmspace_map(
    handle: HandleId,
    folio: HandleId,
    prot: PageProtect,
) -> Result<VAddr, ErrorCode> {
    let ret = syscall(
        SYS_VMSPACE_MAP,
        handle.as_raw() as isize,
        folio.as_raw() as isize,
        prot.as_raw() as isize,
        0,
        0,
    )?;
    // SAFETY: The syscall returns a valid virtual address.
    let vaddr = VAddr::new(ret.as_isize() as usize);
    Ok(vaddr)
}

pub fn interrupt_create(irq_matcher: IrqMatcher) -> Result<HandleId, ErrorCode> {
    let ret = syscall(
        SYS_INTERRUPT_CREATE,
        irq_matcher.as_raw() as isize,
        0,
        0,
        0,
        0,
    )?;
    // SAFETY: The syscall returns a valid handle ID.
    let id = unsafe { HandleId::from_raw_isize(ret.as_isize()).unwrap_unchecked() };
    Ok(id)
}

pub fn interrupt_ack(handle: HandleId) -> Result<(), ErrorCode> {
    syscall(SYS_INTERRUPT_ACK, handle.as_raw() as isize, 0, 0, 0, 0)?;
    Ok(())
}
```
## libs/rust/starina/tls.rs
```
//! Thread-local storage.

use alloc::boxed::Box;
use core::arch::asm;

pub struct Storage {
    pub name: &'static str,
}

fn read_register() -> usize {
    if cfg!(target_arch = "riscv64") {
        let mut value: usize;
        unsafe {
            asm!("mv {}, tp", out(reg) value);
        }
        value
    } else {
        unimplemented!();
    }
}

fn set_register(value: usize) {
    if cfg!(target_arch = "riscv64") {
        unsafe {
            asm!("mv tp, {}", in(reg) value);
        }
    } else {
        unimplemented!();
    }
}

pub fn thread_local() -> &'static Storage {
    let reg = read_register();
    let ptr = reg as *const Storage;
    debug_assert!(!ptr.is_null());
    unsafe { &*ptr }
}

pub(crate) fn init_thread_local(name: &'static str) {
    debug_assert_eq!(read_register(), 0, "thread local storage already set");

    let storage = Box::leak(Box::new(Storage { name }));
    set_register(storage as *const _ as usize);
}
```
## libs/rust/starina_types/Cargo.toml
```
[package]
name = "starina_types"
publish = false
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
serde = { workspace = true, features = ["derive"] }
serde_bytes = { workspace = true, features = ["alloc"] }
hashbrown = { workspace = true, features = ["serde"] }

[features]
```
## libs/rust/starina_types/address.rs
```
use core::fmt;

/// Represents a physical memory address.
#[derive(Debug, Copy, Clone, Eq, PartialEq, Ord, PartialOrd, Hash)]
#[repr(transparent)]
pub struct PAddr(usize);

impl PAddr {
    pub const fn new(addr: usize) -> PAddr {
        PAddr(addr)
    }

    #[inline(always)]
    pub const fn as_usize(self) -> usize {
        self.0
    }

    // TODO: Check overflow.
    pub fn add(self, offset: usize) -> PAddr {
        PAddr::new(self.as_usize() + offset)
    }
}

impl fmt::Display for PAddr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if cfg!(target_pointer_width = "64") {
            write!(f, "{:016x}", self.as_usize())
        } else {
            write!(f, "{:08x}", self.as_usize())
        }
    }
}

/// Represents a virtual memory address.
#[derive(Debug, Copy, Clone, Eq, PartialEq, Ord, PartialOrd, Hash)]
#[repr(transparent)]
pub struct VAddr(usize);

impl VAddr {
    pub const fn new(addr: usize) -> VAddr {
        VAddr(addr)
    }

    #[inline(always)]
    pub const fn as_usize(self) -> usize {
        self.0
    }

    pub fn add(self, offset: usize) -> VAddr {
        // TODO: Check overflow.
        VAddr::new(self.as_usize() + offset)
    }

    //// # Safety
    ///
    /// <https://doc.rust-lang.org/std/ptr/index.html#pointer-to-reference-conversion>
    pub unsafe fn as_mut_ptr<T>(self) -> *mut T {
        let ptr = self.as_usize() as *mut T;
        unsafe { &mut *ptr }
    }

    //// # Safety
    ///
    /// <https://doc.rust-lang.org/std/ptr/index.html#pointer-to-reference-conversion>
    pub unsafe fn as_ptr<T>(self) -> *const T {
        let ptr = self.as_usize() as *const T;
        unsafe { &*ptr }
    }
}

impl fmt::Display for VAddr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if cfg!(target_pointer_width = "64") {
            write!(f, "{:016x}", self.as_usize())
        } else {
            write!(f, "{:08x}", self.as_usize())
        }
    }
}

/// Represents a device-visible memory address.
///
/// Typically it is equal to the physical address, but it can be different
/// in some cases, e.g. when using IOMMU.
#[derive(Debug, Copy, Clone, Eq, PartialEq, Ord, PartialOrd, Hash)]
#[repr(transparent)]
pub struct DAddr(usize);

impl DAddr {
    pub const fn new(addr: usize) -> DAddr {
        DAddr(addr)
    }

    #[inline(always)]
    pub const fn as_usize(self) -> usize {
        self.0
    }

    pub fn add(self, offset: usize) -> DAddr {
        // TODO: Check overflow.
        DAddr::new(self.as_usize() + offset)
    }
}

impl fmt::Display for DAddr {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if cfg!(target_pointer_width = "64") {
            write!(f, "{:016x}", self.as_usize())
        } else {
            write!(f, "{:08x}", self.as_usize())
        }
    }
}
```
## libs/rust/starina_types/device_tree.rs
```
use alloc::string::String;
use alloc::vec::Vec;

use hashbrown::HashMap;
use serde::Deserialize;
use serde::Serialize;

use crate::interrupt::IrqMatcher;

/// The device tree. This is the root of the device tree.
#[derive(Serialize, Deserialize, Debug)]
pub struct DeviceTree {
    pub buses: HashMap<String, BusNode>,
    pub devices: HashMap<String, DeviceNode>,
}

/// A node in the device tree.
#[derive(Serialize, Deserialize, Debug)]
pub struct DeviceNode {
    pub compatible: Vec<String>,
    pub bus: String,
    pub reg: Vec<Reg>,
    pub interrupts: Vec<IrqMatcher>,
}

#[derive(Serialize, Deserialize, Debug)]
pub enum BusNode {
    NoMmu,
}

#[derive(Serialize, Deserialize, Debug)]
pub struct Reg {
    pub addr: u64,
    pub size: u64,
}
```
## libs/rust/starina_types/error.rs
```
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
#[repr(isize)]
pub enum ErrorCode {
    NotSupported = -1,
    NotAllowed = -2,
    NotFound = -3,
    InvalidMessageKind = -4,
    InvalidSyscall = -5,
    UnexpectedType = -6,
    AlreadyExists = -7,
    TooManyHandles = -8,
    HandleNotMovable = -9,
    NoPeer = -10,
    OutOfMemory = -11,
    Empty = -12,
    Full = -13,
    Closed = -14,
    InvalidMessage = -15,
    TooLongUri = -16,
    InvalidArg = -17,
    InvalidHandle = -18,
    InvalidErrorCode = -19,
    TooLarge = -20,
    NotADevice = -21,
    AlreadyMapped = -22,
    InvalidState = -23,
}

impl From<isize> for ErrorCode {
    fn from(value: isize) -> Self {
        if -23 <= value && value < 0 {
            unsafe { core::mem::transmute(value) }
        } else {
            ErrorCode::InvalidErrorCode
        }
    }
}
```
## libs/rust/starina_types/handle.rs
```
use core::ops::BitOr;

use crate::error::ErrorCode;
use crate::syscall::RetVal;

/// A handle ID.
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct HandleId(i32);

impl HandleId {
    /// Creates a handle ID from a raw integer.
    pub const fn from_raw(raw: i32) -> HandleId {
        HandleId(raw)
    }

    pub const fn as_raw(&self) -> i32 {
        self.0
    }

    pub fn from_raw_isize(raw: isize) -> Result<HandleId, ErrorCode> {
        if let Ok(raw) = raw.try_into() {
            Ok(HandleId(raw))
        } else {
            Err(ErrorCode::InvalidSyscall)
        }
    }
}

impl From<HandleId> for RetVal {
    fn from(handle: HandleId) -> Self {
        RetVal::new(handle.as_raw() as isize)
    }
}

/// Allowed operations on a handle.
#[derive(Clone, Copy, PartialEq, Eq, Hash)]
pub struct HandleRights(pub u8);

impl HandleRights {
    pub const READ: HandleRights = HandleRights(1 << 0);
    pub const WRITE: HandleRights = HandleRights(1 << 1);
    pub const POLL: HandleRights = HandleRights(1 << 2);
    pub const MAP: HandleRights = HandleRights(1 << 3);

    pub fn is_capable(&self, required: HandleRights) -> bool {
        self.0 & required.0 == required.0
    }
}

impl BitOr for HandleRights {
    type Output = Self;

    fn bitor(self, rhs: Self) -> Self {
        HandleRights(self.0 | rhs.0)
    }
}
```
## libs/rust/starina_types/interrupt.rs
```
use serde::Deserialize;
use serde::Serialize;

use crate::error::ErrorCode;

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Hash, Serialize, Deserialize)]
pub struct Irq(u32);

impl Irq {
    pub const fn from_raw(irq: u32) -> Self {
        Self(irq)
    }

    pub fn from_raw_isize(raw: isize) -> Result<Self, ErrorCode> {
        match u32::try_from(raw) {
            Ok(raw) => Ok(Self(raw as u32)),
            Err(_) => Err(ErrorCode::InvalidArg),
        }
    }

    pub const fn as_raw(&self) -> u32 {
        self.0
    }
}

#[derive(Serialize, Deserialize, Debug, Clone, Copy)]
pub enum IrqMatcher {
    Static(Irq),
}

impl IrqMatcher {
    pub const fn as_raw(&self) -> u32 {
        match self {
            IrqMatcher::Static(irq) => {
                // Upper bits are reserved for future use.
                assert!(irq.as_raw() < 4096);
                irq.as_raw()
            }
        }
    }

    pub fn from_raw_isize(raw: isize) -> Result<Self, ErrorCode> {
        match u32::try_from(raw) {
            Ok(raw) if raw < 4096 => Ok(Self::Static(Irq::from_raw(raw))),
            _ => Err(ErrorCode::InvalidArg),
        }
    }
}
```
## libs/rust/starina_types/lib.rs
```
#![no_std]
#![cfg_attr(test, feature(test))]

extern crate alloc;

pub mod address;
pub mod device_tree;
pub mod error;
pub mod handle;
pub mod interrupt;
pub mod message;
pub mod poll;
pub mod spec;
pub mod syscall;
pub mod vmspace;
```
## libs/rust/starina_types/message.rs
```
use crate::error::ErrorCode;
use crate::syscall::RetVal;

pub const MESSAGE_NUM_HANDLES_MAX: usize = 3;
pub const MESSAGE_DATA_LEN_MAX: usize = 4 * 1024;

/// The message metadata.
#[derive(Clone, Copy, PartialEq, Eq, Debug)]
#[repr(transparent)]
pub struct MessageInfo(i32);

impl MessageInfo {
    pub const fn new(kind: i32, data_len: u16, num_handles: u8) -> Self {
        debug_assert!(num_handles <= MESSAGE_NUM_HANDLES_MAX as u8);
        MessageInfo((kind << 18) | ((num_handles as i32) << 16) | (data_len as i32))
    }

    pub fn from_raw_isize(raw: isize) -> Result<Self, ErrorCode> {
        match i32::try_from(raw) {
            Ok(raw) if raw >= 0 => Ok(MessageInfo(raw)),
            _ => Err(ErrorCode::InvalidArg),
        }
    }

    pub fn as_raw(&self) -> isize {
        self.0 as isize
    }

    pub fn kind(self) -> usize {
        (self.0 >> 18) as usize
    }

    pub fn data_len(self) -> usize {
        (self.0 & 0xffff) as usize
    }

    pub fn num_handles(self) -> usize {
        ((self.0 >> 16) & 0b11) as usize
    }
}

impl From<MessageInfo> for RetVal {
    fn from(msginfo: MessageInfo) -> Self {
        RetVal::new(msginfo.0 as isize)
    }
}
```
## libs/rust/starina_types/poll.rs
```
use core::fmt;
use core::fmt::Write;
use core::ops::BitAnd;
use core::ops::BitAndAssign;
use core::ops::BitOr;
use core::ops::BitOrAssign;

use crate::error::ErrorCode;

#[derive(Clone, Copy, PartialEq, Eq)]
#[repr(transparent)]
pub struct Readiness(i8);

impl Default for Readiness {
    fn default() -> Self {
        Self::new()
    }
}

impl Readiness {
    pub const CLOSED: Readiness = Readiness(1 << 0);
    pub const READABLE: Readiness = Readiness(1 << 1);
    pub const WRITABLE: Readiness = Readiness(1 << 2);

    pub const fn new() -> Readiness {
        Readiness(0)
    }

    pub const fn from_raw(raw: i8) -> Readiness {
        Readiness(raw)
    }

    pub fn from_raw_isize(raw: isize) -> Result<Readiness, ErrorCode> {
        match i8::try_from(raw) {
            Ok(raw) if raw >= 0 => Ok(Readiness::from_raw(raw)),
            _ => Err(ErrorCode::InvalidArg),
        }
    }

    pub fn as_isize(&self) -> isize {
        self.0 as isize
    }

    pub fn is_empty(&self) -> bool {
        self.0 == 0
    }

    pub fn contains(&self, other: Readiness) -> bool {
        self.0 & other.0 != 0
    }
}

impl fmt::Debug for Readiness {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        if self.contains(Readiness::CLOSED) {
            f.write_char('C')?;
        }
        if self.contains(Readiness::READABLE) {
            f.write_char('R')?;
        }
        if self.contains(Readiness::WRITABLE) {
            f.write_char('W')?;
        }

        Ok(())
    }
}

impl BitOr for Readiness {
    type Output = Self;

    fn bitor(self, rhs: Self) -> Self {
        Readiness(self.0 | rhs.0)
    }
}

impl BitAnd for Readiness {
    type Output = Self;

    fn bitand(self, rhs: Self) -> Self {
        Readiness(self.0 & rhs.0)
    }
}

impl BitOrAssign for Readiness {
    fn bitor_assign(&mut self, rhs: Self) {
        self.0 |= rhs.0;
    }
}

impl BitAndAssign for Readiness {
    fn bitand_assign(&mut self, rhs: Self) {
        self.0 &= rhs.0;
    }
}
```
## libs/rust/starina_types/spec.rs
```
pub enum DeviceMatch {
    Compatible(&'static str),
}

pub enum EnvType {
    DeviceTree { matches: &'static [DeviceMatch] },
    IoBusMap,
    Service { name: &'static str },
}

pub struct EnvItem {
    pub name: &'static str,
    pub ty: EnvType,
}

pub enum ExportItem {
    Service { name: &'static str },
}

pub struct AppSpec {
    pub env: &'static [EnvItem],
    pub exports: &'static [ExportItem],
}
```
## libs/rust/starina_types/syscall.rs
```
use crate::address::DAddr;
use crate::address::VAddr;
use crate::error::ErrorCode;
use crate::handle::HandleId;
use crate::poll::Readiness;

pub const SYS_CONSOLE_WRITE: u8 = 0;
pub const SYS_HANDLE_CLOSE: u8 = 1;
pub const SYS_CHANNEL_CREATE: u8 = 2;
pub const SYS_CHANNEL_SEND: u8 = 3;
pub const SYS_CHANNEL_RECV: u8 = 4;
pub const SYS_POLL_CREATE: u8 = 5;
pub const SYS_POLL_ADD: u8 = 6;
pub const SYS_POLL_REMOVE: u8 = 7;
pub const SYS_POLL_WAIT: u8 = 8;
pub const SYS_FOLIO_CREATE: u8 = 9;
pub const SYS_FOLIO_PADDR: u8 = 10;
pub const SYS_FOLIO_CREATE_FIXED: u8 = 11;
pub const SYS_VMSPACE_MAP: u8 = 12;
pub const SYS_BUSIO_MAP: u8 = 13;
pub const SYS_FOLIO_DADDR: u8 = 14;
pub const SYS_INTERRUPT_CREATE: u8 = 15;
pub const SYS_INTERRUPT_ACK: u8 = 16;

#[repr(C)]
pub struct VsyscallPage {
    pub environ_ptr: *const u8,
    pub environ_len: usize,
    pub startup_ch: HandleId,
}

/// SAFETY: VsyscallPage is pre-allocated, the same across threads, and immutable.
unsafe impl Send for VsyscallPage {}

#[derive(Debug, Clone, Copy)]
#[repr(transparent)]
pub struct RetVal(isize);

impl RetVal {
    pub const fn new(value: isize) -> RetVal {
        RetVal(value)
    }

    pub fn as_isize(&self) -> isize {
        self.0
    }
}

impl<T> From<Result<T, ErrorCode>> for RetVal
where
    T: Into<RetVal>,
{
    fn from(value: Result<T, ErrorCode>) -> Self {
        match value {
            Ok(value) => value.into(),
            Err(err) => RetVal(err as isize),
        }
    }
}

impl From<(HandleId, Readiness)> for RetVal {
    fn from(value: (HandleId, Readiness)) -> Self {
        let handle_raw = value.0.as_raw() as isize;
        assert!(handle_raw < 0x10000);
        let readiness = value.1.as_isize();
        RetVal((readiness << 24) | handle_raw)
    }
}

impl From<VAddr> for RetVal {
    fn from(value: VAddr) -> Self {
        RetVal(value.as_usize() as isize)
    }
}

impl From<DAddr> for RetVal {
    fn from(value: DAddr) -> Self {
        RetVal(value.as_usize() as isize)
    }
}

impl From<ErrorCode> for RetVal {
    fn from(value: ErrorCode) -> Self {
        RetVal(value as isize)
    }
}

impl<T> From<RetVal> for Result<T, ErrorCode>
where
    T: From<RetVal>,
{
    fn from(value: RetVal) -> Self {
        if value.0 >= 0 {
            let value = value.into();
            Ok(value)
        } else {
            let code = unsafe { core::mem::transmute_copy(&value.0) };
            Err(code)
        }
    }
}

impl From<RetVal> for (HandleId, Readiness) {
    fn from(value: RetVal) -> Self {
        let handle_raw = value.0 & 0x00ff_ffff;
        let readiness = value.0 >> 24;
        (
            HandleId::from_raw(handle_raw as i32),
            Readiness::from_raw(readiness as i8),
        )
    }
}

impl From<RetVal> for HandleId {
    fn from(value: RetVal) -> Self {
        HandleId::from_raw(value.0 as i32)
    }
}
```
## libs/rust/starina_types/vmspace.rs
```
use core::ops;

use crate::error::ErrorCode;

#[derive(Debug, Copy, Clone, Eq, PartialEq)]
#[repr(transparent)]
pub struct PageProtect(u8);

impl PageProtect {
    pub const READABLE: PageProtect = PageProtect::from_raw(1 << 1);
    pub const WRITEABLE: PageProtect = PageProtect::from_raw(1 << 2);
    pub const EXECUTABLE: PageProtect = PageProtect::from_raw(1 << 3);
    pub const USER: PageProtect = PageProtect::from_raw(1 << 4);

    pub const fn zeroed() -> PageProtect {
        PageProtect(0)
    }

    pub const fn from_raw(value: u8) -> PageProtect {
        PageProtect(value)
    }

    pub fn from_raw_isize(value: isize) -> Result<PageProtect, ErrorCode> {
        let value: u8 = value.try_into().map_err(|_| ErrorCode::InvalidArg)?;
        Ok(PageProtect::from_raw(value))
    }

    pub fn contains(&self, other: PageProtect) -> bool {
        (self.0 & other.0) != 0
    }

    pub fn user_allowed_flags(&self) -> bool {
        let allowed = Self::READABLE | Self::WRITEABLE | Self::EXECUTABLE;
        (self.0 & allowed.0) == self.0
    }

    pub fn as_raw(&self) -> u8 {
        self.0
    }
}

impl ops::BitOr for PageProtect {
    type Output = Self;

    fn bitor(self, rhs: Self) -> Self {
        PageProtect(self.0 | rhs.0)
    }
}

impl ops::BitAnd for PageProtect {
    type Output = Self;

    fn bitand(self, rhs: Self) -> Self {
        PageProtect(self.0 & rhs.0)
    }
}

impl ops::BitOrAssign for PageProtect {
    fn bitor_assign(&mut self, rhs: Self) {
        self.0 |= rhs.0;
    }
}

impl ops::BitAndAssign for PageProtect {
    fn bitand_assign(&mut self, rhs: Self) {
        self.0 &= rhs.0;
    }
}
```
## libs/rust/starina_utils/Cargo.toml
```
[package]
name = "starina_utils"
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
```
## libs/rust/starina_utils/alignment.rs
```
/// Aligns a value down to the nearest multiple of `align`.
///
/// `align` must be a power of two.
///
/// # Example
///
/// ```
/// use starina_utils::alignment::align_down;
///
/// assert_eq!(align_down(0x0000, 0x1000), 0x0000);
/// assert_eq!(align_down(0x0001, 0x1000), 0x0000);
/// assert_eq!(align_down(0x1000, 0x1000), 0x1000);
/// assert_eq!(align_down(0x1001, 0x1000), 0x1000);
/// assert_eq!(align_down(0x2000, 0x1000), 0x2000);
/// ```
pub const fn align_down(value: usize, align: usize) -> usize {
    debug_assert!(align.is_power_of_two());

    (value) & !(align - 1)
}

/// Aligns a value up to the nearest multiple of `align`.
///
/// `align` must be a power of two.
///
/// # Example
///
/// ```
/// use starina_utils::alignment::align_up;
///
/// assert_eq!(align_up(0x0000, 0x1000), 0x0000);
/// assert_eq!(align_up(0x0001, 0x1000), 0x1000);
/// assert_eq!(align_up(0x1000, 0x1000), 0x1000);
/// assert_eq!(align_up(0x1001, 0x1000), 0x2000);
/// assert_eq!(align_up(0x2000, 0x1000), 0x2000);
/// ```
pub const fn align_up(value: usize, align: usize) -> usize {
    debug_assert!(align.is_power_of_two());

    align_down(value + align - 1, align)
}

/// Returns `true` if `value` is aligned to `align`.
///
/// `align` must be a power of two.
///
/// # Example
///
/// ```
/// use starina_utils::alignment::is_aligned;
///
/// assert_eq!(is_aligned(0x0000, 0x1000), true);
/// assert_eq!(is_aligned(0x0001, 0x1000), false);
/// assert_eq!(is_aligned(0x1000, 0x1000), true);
/// assert_eq!(is_aligned(0x1001, 0x1000), false);
/// assert_eq!(is_aligned(0x2000, 0x1000), true);
/// ```
pub const fn is_aligned(value: usize, align: usize) -> bool {
    debug_assert!(align.is_power_of_two());

    value & (align - 1) == 0
}
```
## libs/rust/starina_utils/assertions.rs
```
/// Static (aka compile-time) assertion macro.
///
/// Ported from rust-lang/rust (MIT/Apache-2.0): <https://github.com/rust-lang/rust/blob/432fffa8afb8fcfe658e6548e5e8f10ad2001329/library/std/src/io/error/repr_bitpacked.rs#L352>
#[macro_export]
macro_rules! static_assert {
    ($condition:expr) => {
        const _: () = assert!(
            $condition,
            concat!(
                "\n\nSTATIC ASSERTION FAILURE: the following condition is not met:\n\n    ",
                file!(),
                ":",
                stringify!(line!()),
                "\n\n"
            )
        );
    };
}
```
## libs/rust/starina_utils/byte_size.rs
```
use core::fmt;

/// A pretty printer for byte sizes.
///
/// # Example
///
/// ```
/// use starina_utils::byte_size::ByteSize;
///
/// assert_eq!(format!("{}", ByteSize(128)), "128 B");
/// assert_eq!(format!("{}", ByteSize(1024)), "1 KiB");
/// assert_eq!(format!("{}", ByteSize(16 * 1024 * 1024)), "16 MiB");
/// ```
#[repr(transparent)]
pub struct ByteSize(pub usize);

impl ByteSize {
    pub const fn from_kib(kib: usize) -> Self {
        Self(kib * 1024)
    }

    pub fn in_bytes(&self) -> usize {
        self.0
    }

    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let units = &["B", "KiB", "MiB", "GiB", "TiB"];
        let mut value = self.0;
        let mut i = 0;
        let mut unit = units[0];
        while value >= 1024 && i + 1 < units.len() {
            value /= 1024;
            unit = units[i + 1];
            i += 1;
        }

        write!(f, "{} {}", value, unit)
    }
}

impl fmt::Debug for ByteSize {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.fmt(f)
    }
}

impl fmt::Display for ByteSize {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        self.fmt(f)
    }
}
```
## libs/rust/starina_utils/lib.rs
```
#![no_std]

pub mod alignment;
pub mod assertions;
pub mod byte_size;
```
## libs/rust/virtio/Cargo.toml
```
[package]
name = "virtio"
version = { workspace = true }
authors = { workspace = true }
edition = { workspace = true }

[lib]
path = "lib.rs"

[dependencies]
starina = { workspace = true }
starina_driver_sdk = { workspace = true }
starina_utils = { workspace = true }
```
## libs/rust/virtio/lib.rs
```
#![no_std]

pub mod transports;
pub mod virtqueue;

#[derive(Debug, PartialEq, Eq)]
pub enum DeviceType {
    Net,
    Blk,
    Console,
    Unknown(u32),
}

#[derive(Debug)]
pub enum VirtioAttachError {
    UnexpectedDeviceType(DeviceType),
    MissingFeatures,
    MissingPciCommonCfg,
    MissingPciDeviceCfg,
    MissingPciIsrCfg,
    MissingPciNotifyCfg,
    FeatureNegotiationFailure,
    NotSupportedBarType,
}
```
## libs/rust/virtio/transports/mmio.rs
```
use starina::address::DAddr;
use starina::folio::MmioFolio;
use starina::prelude::*;
use starina_driver_sdk::mmio::LittleEndian;
use starina_driver_sdk::mmio::MmioReg;
use starina_driver_sdk::mmio::ReadOnly;
use starina_driver_sdk::mmio::ReadWrite;
use starina_driver_sdk::mmio::WriteOnly;

use super::VirtioTransport;
use crate::DeviceType;
use crate::transports::IsrStatus;

// "All register values are organized as Little Endian."
// (4.2.2 MMIO Device Register Layout).
const MAGIC_VALUE_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x00);
const DEVICE_VERSION_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x04);
const DEVICE_ID_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x08);
const DEVICE_FEATURES_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x10);
const DEVICE_FEATURES_SEL_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x14);
const DRIVER_FEATURES_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x20);
const DRIVER_FEATURES_SEL_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x24);
const QUEUE_SEL_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x30);
const QUEUE_NUM_MAX_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x34);
const QUEUE_NUM_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x38);
const QUEUE_READY_REG: MmioReg<LittleEndian, ReadWrite, u32> = MmioReg::new(0x44);
const QUEUE_NOTIFY_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x50);
const INTERRUPT_STATUS_REG: MmioReg<LittleEndian, ReadOnly, u32> = MmioReg::new(0x60);
const INTERRUPT_ACK_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x64);
const DEVICE_STATUS_REG: MmioReg<LittleEndian, ReadWrite, u32> = MmioReg::new(0x70);
const QUEUE_DESC_LOW_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x80);
const QUEUE_DESC_HIGH_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x84);
const QUEUE_DRIVER_LOW_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x90);
const QUEUE_DRIVER_HIGH_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0x94);
const QUEUE_DEVICE_LOW_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0xa0);
const QUEUE_DEVICE_HIGH_REG: MmioReg<LittleEndian, WriteOnly, u32> = MmioReg::new(0xa4);
const CONFIG_REG_BASE: MmioReg<LittleEndian, ReadWrite, u8> = MmioReg::new(0x100);

pub struct VirtioMmio {
    mmio: MmioFolio,
}

impl VirtioMmio {
    pub fn new(mmio: MmioFolio) -> VirtioMmio {
        VirtioMmio { mmio }
    }
}

impl VirtioTransport for VirtioMmio {
    fn probe(&mut self) -> Option<DeviceType> {
        // Check if the device is present by checking t he magic value
        // ("virt" in little-endian).
        if MAGIC_VALUE_REG.read(&mut self.mmio) != 0x74726976 {
            return None;
        }

        let version = DEVICE_VERSION_REG.read(&mut self.mmio);
        if version != 2 {
            warn!("virtio-mmio: unsupported device version: {}", version);
            return None;
        }

        let device_type = DEVICE_ID_REG.read(&mut self.mmio);
        match device_type {
            1 => Some(DeviceType::Net),
            2 => Some(DeviceType::Blk),
            3 => Some(DeviceType::Console),
            _ => Some(DeviceType::Unknown(device_type)),
        }
    }

    fn is_modern(&mut self) -> bool {
        true
    }

    fn read_device_config8(&mut self, offset: u16) -> u8 {
        CONFIG_REG_BASE.read_with_offset(&mut self.mmio, offset as usize)
    }

    fn read_isr_status(&mut self) -> IsrStatus {
        IsrStatus(INTERRUPT_STATUS_REG.read(&mut self.mmio) as u8)
    }

    fn ack_interrupt(&mut self, status: IsrStatus) {
        INTERRUPT_ACK_REG.write(&mut self.mmio, status.0 as u32);
    }

    fn read_device_status(&mut self) -> u8 {
        DEVICE_STATUS_REG.read(&mut self.mmio) as u8
    }

    fn write_device_status(&mut self, value: u8) {
        DEVICE_STATUS_REG.write(&mut self.mmio, value as u32);
    }

    fn read_device_features(&mut self) -> u64 {
        DEVICE_FEATURES_SEL_REG.write(&mut self.mmio, 0);
        let low = DEVICE_FEATURES_REG.read(&mut self.mmio);
        DEVICE_FEATURES_SEL_REG.write(&mut self.mmio, 1);
        let high = DEVICE_FEATURES_REG.read(&mut self.mmio);
        ((high as u64) << 32) | (low as u64)
    }

    fn write_driver_features(&mut self, value: u64) {
        DRIVER_FEATURES_SEL_REG.write(&mut self.mmio, 0);
        DRIVER_FEATURES_REG.write(&mut self.mmio, (value & 0xffff_ffff) as u32);
        DRIVER_FEATURES_SEL_REG.write(&mut self.mmio, 1);
        DRIVER_FEATURES_REG.write(&mut self.mmio, (value >> 32) as u32);
    }

    fn select_queue(&mut self, index: u16) {
        QUEUE_SEL_REG.write(&mut self.mmio, index as u32);
    }

    fn queue_max_size(&mut self) -> u16 {
        QUEUE_NUM_MAX_REG.read(&mut self.mmio) as u16
    }

    fn set_queue_size(&mut self, queue_size: u16) {
        QUEUE_NUM_REG.write(&mut self.mmio, queue_size as u32);
    }

    fn notify_queue(&mut self, index: u16) {
        QUEUE_NOTIFY_REG.write(&mut self.mmio, index as u32);
    }

    fn enable_queue(&mut self) {
        QUEUE_READY_REG.write(&mut self.mmio, 1);
    }

    fn set_queue_desc_paddr(&mut self, daddr: DAddr) {
        QUEUE_DESC_LOW_REG.write(&mut self.mmio, (daddr.as_usize() & 0xffff_ffff) as u32);
        QUEUE_DESC_HIGH_REG.write(&mut self.mmio, (daddr.as_usize() >> 32) as u32);
    }

    fn set_queue_driver_paddr(&mut self, daddr: DAddr) {
        QUEUE_DRIVER_LOW_REG.write(&mut self.mmio, (daddr.as_usize() & 0xffff_ffff) as u32);
        QUEUE_DRIVER_HIGH_REG.write(&mut self.mmio, (daddr.as_usize() >> 32) as u32);
    }

    fn set_queue_device_paddr(&mut self, daddr: DAddr) {
        QUEUE_DEVICE_LOW_REG.write(&mut self.mmio, (daddr.as_usize() & 0xffff_ffff) as u32);
        QUEUE_DEVICE_HIGH_REG.write(&mut self.mmio, (daddr.as_usize() >> 32) as u32);
    }
}
```
## libs/rust/virtio/transports/mod.rs
```
use starina::address::DAddr;
use starina::iobus::IoBus;
use starina::prelude::*;

use super::DeviceType;
use crate::VirtioAttachError;
use crate::virtqueue::VirtQueue;

pub mod mmio;

const VIRTIO_STATUS_ACK: u8 = 1;
const VIRTIO_STATUS_DRIVER: u8 = 2;
const VIRTIO_STATUS_DRIVER_OK: u8 = 4;
const VIRTIO_STATUS_FEAT_OK: u8 = 8;
// const VIRTIO_F_VERSION_1: u64 = 1 << 32;

#[derive(Debug, Copy, Clone)]
#[repr(transparent)]
pub struct IsrStatus(pub u8);

const QUEUE_INTR: u8 = 1 << 0;
const DEVICE_CONFIG_INTR: u8 = 1 << 1;

impl IsrStatus {
    pub fn queue_intr(&self) -> bool {
        (self.0 & QUEUE_INTR) != 0
    }

    pub fn device_config_intr(&self) -> bool {
        (self.0 & DEVICE_CONFIG_INTR) != 0
    }
}

pub trait VirtioTransport: Send + Sync {
    fn probe(&mut self) -> Option<DeviceType>;
    fn is_modern(&mut self) -> bool;
    fn read_device_config8(&mut self, offset: u16) -> u8;
    fn read_isr_status(&mut self) -> IsrStatus;
    fn ack_interrupt(&mut self, status: IsrStatus);
    fn read_device_status(&mut self) -> u8;
    fn write_device_status(&mut self, value: u8);
    fn read_device_features(&mut self) -> u64;
    fn write_driver_features(&mut self, value: u64);
    fn select_queue(&mut self, index: u16);
    fn queue_max_size(&mut self) -> u16;
    fn set_queue_size(&mut self, queue_size: u16);
    fn notify_queue(&mut self, index: u16);
    fn enable_queue(&mut self);
    fn set_queue_desc_paddr(&mut self, paddr: DAddr);
    fn set_queue_driver_paddr(&mut self, paddr: DAddr);
    fn set_queue_device_paddr(&mut self, paddr: DAddr);
}

impl dyn VirtioTransport {
    fn set_device_status_bit(&mut self, new_bits: u8) {
        let status = self.read_device_status();
        self.write_device_status(status | new_bits);
    }

    pub fn initialize(
        &mut self,
        iobus: &IoBus,
        features: u64,
        num_virtqueues: u16,
    ) -> Result<Vec<VirtQueue>, VirtioAttachError> {
        // "3.1.1 Driver Requirements: Device Initialization"
        self.write_device_status(0); // Reset the device.
        self.set_device_status_bit(VIRTIO_STATUS_ACK);
        self.set_device_status_bit(VIRTIO_STATUS_DRIVER);
        let device_features = self.read_device_features();
        if (device_features & features) != features {
            warn!(
                "virtio: feature negotiation failure: driver={:x}, device={:x}, unspported={:x}",
                features,
                device_features,
                features & !device_features
            );
            return Err(VirtioAttachError::MissingFeatures);
        }

        self.write_driver_features(features);
        self.set_device_status_bit(VIRTIO_STATUS_FEAT_OK);

        if (self.read_device_status() & VIRTIO_STATUS_FEAT_OK) == 0 {
            return Err(VirtioAttachError::FeatureNegotiationFailure);
        }

        // Initialize virtqueues.
        let mut virtqueues = Vec::new();
        for index in 0..num_virtqueues {
            virtqueues.push(VirtQueue::new(iobus, index, self));
        }

        self.set_device_status_bit(VIRTIO_STATUS_DRIVER_OK);

        Ok(virtqueues)
    }
}
```
## libs/rust/virtio/virtqueue.rs
```
use core::fmt;
use core::mem::size_of;
use core::sync::atomic;
use core::sync::atomic::Ordering;

use starina::address::DAddr;
use starina::folio::MmioFolio;
use starina::folio::page_size;
use starina::iobus::IoBus;
use starina::prelude::*;
use starina_utils::alignment::align_up;

use super::transports::VirtioTransport;

const VIRTQ_DESC_F_NEXT: u16 = 1;
const VIRTQ_DESC_F_WRITE: u16 = 2;

#[derive(Debug, Copy, Clone)]
#[repr(C, packed)]
pub struct VirtqDesc {
    pub addr: u64,
    pub len: u32,
    pub flags: u16,
    pub next: u16,
}

impl VirtqDesc {
    pub fn is_writable(&self) -> bool {
        self.flags & VIRTQ_DESC_F_WRITE != 0
    }

    pub fn has_next(&self) -> bool {
        self.flags & VIRTQ_DESC_F_NEXT != 0
    }
}

#[derive(Debug, Copy, Clone)]
#[repr(C, packed)]
struct VirtqAvail {
    flags: u16,
    index: u16,
    // The rings (an array of descriptor indices) immediately follows here.
}

#[derive(Debug, Copy, Clone)]
#[repr(C, packed)]
pub struct VirtqUsedElem {
    id: u32,
    len: u32,
}

#[derive(Debug, Copy, Clone)]
#[repr(C, packed)]
struct VirtqUsed {
    flags: u16,
    index: u16,
    // The rings (an array of VirtqUsedElem) immediately follows here.
}

#[derive(Debug)]
pub enum VirtqDescBuffer {
    ReadOnlyFromDevice { daddr: DAddr, len: usize },
    WritableFromDevice { daddr: DAddr, len: usize },
}

pub struct VirtqUsedChain {
    pub descs: Vec<VirtqDescBuffer>,
    pub total_len: usize,
}

/// A virtqueue.
pub struct VirtQueue {
    #[allow(dead_code)]
    folio: MmioFolio,
    index: u16,
    num_descs: u16,
    last_used_index: u16,
    free_head: u16,
    num_free_descs: u16,
    avail_ring_off: usize,
    used_ring_off: usize,
}

impl VirtQueue {
    pub fn new(iobus: &IoBus, index: u16, transport: &mut dyn VirtioTransport) -> VirtQueue {
        transport.select_queue(index);

        let num_descs = transport.queue_max_size();
        transport.set_queue_size(num_descs);

        let avail_ring_off = size_of::<VirtqDesc>() * (num_descs as usize);
        let avail_ring_size: usize = size_of::<u16>() * (3 + (num_descs as usize));
        let used_ring_off = align_up(avail_ring_off + avail_ring_size, page_size());
        let used_ring_size =
            size_of::<u16>() * 3 + size_of::<VirtqUsedElem>() * (num_descs as usize);
        let virtq_size = used_ring_off + align_up(used_ring_size, page_size());

        let folio = MmioFolio::create(iobus, virtq_size).expect("failed to allocate virtuqeue");
        let descs = folio.daddr();
        let avail = folio.daddr().add(avail_ring_off);
        let used = folio.daddr().add(used_ring_off);

        transport.set_queue_desc_paddr(descs);
        transport.set_queue_driver_paddr(avail);
        transport.set_queue_device_paddr(used);
        transport.enable_queue();

        let mut this = VirtQueue {
            folio,
            index,
            num_descs,
            last_used_index: 0,
            free_head: 0,
            num_free_descs: num_descs,
            avail_ring_off,
            used_ring_off,
        };

        // Add descriptors into the free list.
        for i in 0..num_descs {
            this.desc_mut(i).next = if i == num_descs - 1 { 0 } else { i + 1 };
        }

        this
    }

    /// Enqueues a request to the device. A request is a chain of descriptors
    /// (e.g. `struct virtio_blk_req` as defined in the spec).
    ///
    /// Once you've enqueued all requests, you need to notify the device through
    /// the `notify` method.
    pub fn enqueue(&mut self, chain: &[VirtqDescBuffer]) {
        debug_assert!(!chain.is_empty());

        // Try freeing used descriptors.
        if (self.num_free_descs as usize) < chain.len() {
            while self.last_used_index != self.used().index {
                let used_elem_index = self.used_elem(self.last_used_index).id as u16;

                // Enqueue the popped chain back into the free list.
                let prev_head = self.free_head;
                self.free_head = used_elem_index;

                // Count the number of descriptors in the chain.
                let mut num_freed = 0;
                let mut next_desc_index = used_elem_index;
                loop {
                    let desc = self.desc_mut(next_desc_index);
                    num_freed += 1;

                    if (desc.flags & VIRTQ_DESC_F_NEXT) == 0 {
                        desc.next = prev_head;
                        break;
                    }

                    next_desc_index = desc.next;
                }

                self.num_free_descs += num_freed;
                self.last_used_index = self.last_used_index.wrapping_add(1);
            }
        }

        // Check if we have the enough number of free descriptors.
        if (self.num_free_descs as usize) < chain.len() {
            panic!("not enough descs for {}!", self.index);
        }

        let head_index = self.free_head;
        let mut desc_index = self.free_head;
        for (i, buffer) in chain.iter().enumerate() {
            let desc = self.desc_mut(desc_index);
            let (addr, len, flags) = match buffer {
                VirtqDescBuffer::ReadOnlyFromDevice { daddr, len } => (daddr, *len, 0),
                VirtqDescBuffer::WritableFromDevice { daddr, len } => {
                    (daddr, *len, VIRTQ_DESC_F_WRITE)
                }
            };

            desc.addr = addr.as_usize() as u64;
            desc.len = len.try_into().unwrap();
            desc.flags = flags;

            if i == chain.len() - 1 {
                let unused_next = desc.next;
                desc.next = 0;
                desc.flags &= !VIRTQ_DESC_F_NEXT;
                self.free_head = unused_next;
                self.num_free_descs -= chain.len() as u16;
            } else {
                desc.flags |= VIRTQ_DESC_F_NEXT;
                desc_index = desc.next;
            }
        }

        let avail_elem_index = self.avail().index & (self.num_descs() - 1);
        *self.avail_elem_mut(avail_elem_index) = head_index;

        let avail = self.avail_mut();
        avail.index = avail.index.wrapping_add(1);
    }

    /// Notifies the device to start processing descriptors.
    pub fn notify(&self, transport: &mut dyn VirtioTransport) {
        atomic::fence(Ordering::Release);
        transport.notify_queue(self.index);
    }

    /// Returns a chain of descriptors processed by the device.
    pub fn pop_used(&mut self) -> Option<VirtqUsedChain> {
        // TODO: Shouldn't we use atomic read here?
        if self.last_used_index == self.used().index {
            return None;
        }

        let head = *self.used_elem(self.last_used_index);
        self.last_used_index = self.last_used_index.wrapping_add(1);

        let mut used_descs = Vec::new();
        let mut next_desc_index = head.id as u16;
        let mut num_descs_in_chain = 1;
        let current_free_head = self.free_head;
        loop {
            let desc = self.desc_mut(next_desc_index);
            used_descs.push(if desc.is_writable() {
                VirtqDescBuffer::WritableFromDevice {
                    daddr: DAddr::new(desc.addr as usize),
                    len: desc.len as usize,
                }
            } else {
                VirtqDescBuffer::ReadOnlyFromDevice {
                    daddr: DAddr::new(desc.addr as usize),
                    len: desc.len as usize,
                }
            });

            if !desc.has_next() {
                // Prepend the popped chain into the free list.
                desc.next = current_free_head;
                self.free_head = head.id as u16;
                self.num_free_descs += num_descs_in_chain;
                break;
            }

            next_desc_index = desc.next;
            num_descs_in_chain += 1;
        }

        Some(VirtqUsedChain {
            total_len: head.len as usize,
            descs: used_descs,
        })
    }

    /// Returns the defined number of descriptors in the virtqueue.
    pub fn num_descs(&self) -> u16 {
        self.num_descs
    }

    fn desc_mut(&mut self, index: u16) -> &mut VirtqDesc {
        let i = (index % self.num_descs) as usize;
        let offset = i * size_of::<VirtqDesc>();
        unsafe { &mut *self.folio.as_mut(offset) }
    }

    fn avail(&self) -> &VirtqAvail {
        unsafe { &*self.folio.as_ref(self.avail_ring_off) }
    }

    fn avail_mut(&mut self) -> &mut VirtqAvail {
        unsafe { &mut *self.folio.as_mut(self.avail_ring_off) }
    }

    fn avail_elem_mut(&mut self, index: u16) -> &mut u16 {
        let i = (index % self.num_descs) as usize;
        let offset = self.avail_ring_off + size_of::<VirtqAvail>() + i * size_of::<u16>();
        unsafe { &mut *self.folio.as_mut(offset) }
    }

    fn used(&self) -> &VirtqUsed {
        unsafe { &*self.folio.as_ref(self.used_ring_off) }
    }

    fn used_elem(&self, index: u16) -> &VirtqUsedElem {
        let i = (index % self.num_descs) as usize;
        let offset = self.used_ring_off + size_of::<VirtqUsed>() + i * size_of::<VirtqUsedElem>();
        unsafe { &*self.folio.as_ref(offset) }
    }
}

impl fmt::Debug for VirtQueue {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("VirtQueue")
            .field("index", &self.index)
            .finish()
    }
}
```
## run.sh
```
#!/bin/bash
set -eu

QEMU=${QEMU:-qemu-system-riscv64}

export CARGO_TERM_HYPERLINKS=false
cargo build \
  ${RELEASE:+--release} \
  -Z build-std=core,alloc \
  -Z build-std-features=compiler-builtins-mem \
  --target kernel/arch/riscv64/kernel.json \
  --manifest-path kernel/Cargo.toml

if [[ -n ${RELEASE:-} ]]; then
  cp target/kernel/release/kernel starina.elf
else
  cp target/kernel/debug/kernel starina.elf
fi


if [[ -n ${REPLAY:-} ]]; then
  RR_MODE=replay
else
  RR_MODE=record
fi

if [[ -n ${BUILD_ONLY:-} ]]; then
  exit 0
fi

echo -e "\nStarting QEMU..."
$QEMU -machine virt -m 256 -bios default \
  -kernel starina.elf \
  -nographic -serial mon:stdio --no-reboot \
  -global virtio-mmio.force-legacy=false \
  -device virtio-net-device,netdev=net0,bus=virtio-mmio-bus.0 \
  -object filter-dump,id=fiter0,netdev=net0,file=virtio-net.pcap \
  -netdev user,id=net0,hostfwd=tcp:127.0.0.1:1234-:80 \
  -d cpu_reset,unimp,guest_errors,int -D qemu.log \
  -icount shift=auto,rr=${RR_MODE},rrfile=qemu-replay.bin \
  -gdb tcp::7778 ${WAIT_FOR_GDB:+-S}
